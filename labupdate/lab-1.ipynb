{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60e072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.signal import savgol_filter\n",
    "from geopy.distance import geodesic\n",
    "import warnings\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db0d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logging system and set constants\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "GRAVITY = 9.81          \n",
    "MAX_TIME_DIFF = 1000   \n",
    "MAX_SAMPLES = 10000     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9683c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse raw sensor CSV into individual DataFrames\n",
    "def parse_data(file_path: str):\n",
    "\n",
    "    gps_rows, acc_rows, gyro_rows, rot_rows = [], [], [], []\n",
    "    total_rows = 0\n",
    "\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            for line_num, line in enumerate(file):\n",
    "                values = line.strip().split(\",\")\n",
    "                if len(values) < 2:\n",
    "                    logger.warning(f\"Line {line_num+1}: too few columns → {line}\")\n",
    "                    continue\n",
    "                try:\n",
    "                    data_type = int(values[0])\n",
    "                except ValueError:\n",
    "                    logger.warning(f\"Line {line_num+1}: bad data_type → {values[0]}\")\n",
    "                    continue\n",
    "\n",
    "                if data_type == 0 and len(values) == 7:\n",
    "                    gps_rows.append(values)\n",
    "                elif data_type == 1 and len(values) == 6:\n",
    "                    acc_rows.append(values)\n",
    "                elif data_type == 2 and len(values) == 6:\n",
    "                    gyro_rows.append(values)\n",
    "                elif data_type == 3 and len(values) == 7:\n",
    "                    rot_rows.append(values)\n",
    "                else:\n",
    "                    logger.warning(f\"Line {line_num+1}: unknown/invalid format → {values}\")\n",
    "\n",
    "                total_rows += 1\n",
    "                if total_rows >= MAX_SAMPLES:\n",
    "                    logger.warning(\"Reached sample cap, stop reading further lines.\")\n",
    "                    break\n",
    "        logger.info(f\"Parsed {total_rows} lines from {file_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error reading file: {e}\")\n",
    "        # return empty dfs on failure\n",
    "        return {k: pd.DataFrame() for k in (\"gps\", \"acc\", \"gyro\", \"rot\")}\n",
    "\n",
    "    # 1.1 GPS \n",
    "    gps_df = pd.DataFrame()\n",
    "    if gps_rows:\n",
    "        gps_df = pd.DataFrame(gps_rows,\n",
    "                              columns=[\"data_type\", \"timestamp\", \"latitude\", \"longitude\",\n",
    "                                       \"altitude\", \"speed_kmh\", \"satellites\"])\n",
    "        \n",
    "        gps_df = gps_df.astype({\n",
    "            \"data_type\": int,\n",
    "            \"timestamp\": int,\n",
    "            \"latitude\": float,\n",
    "            \"longitude\": float,\n",
    "            \"altitude\": float,\n",
    "            \"speed_kmh\": float,\n",
    "            \"satellites\": int,\n",
    "        })\n",
    "\n",
    "        gps_df[\"speed\"] = gps_df[\"speed_kmh\"] / 3.6   \n",
    "        gps_df[\"speed_ms\"] = gps_df[\"speed\"]           \n",
    "\n",
    "        invalid_lat = (~gps_df[\"latitude\"].between(-90, 90)).sum()\n",
    "        invalid_lon = (~gps_df[\"longitude\"].between(-180, 180)).sum()\n",
    "        if invalid_lat or invalid_lon:\n",
    "            logger.warning(f\"GPS invalid lat: {invalid_lat}, lon: {invalid_lon}\")\n",
    "\n",
    "        extreme_speed = (gps_df[\"speed_kmh\"] > 360).sum()\n",
    "        if extreme_speed:\n",
    "            logger.warning(f\"{extreme_speed} GPS points >360 km/h detected\")\n",
    "\n",
    "    # 1.2 Accelerometer\n",
    "    acc_df = pd.DataFrame()\n",
    "    if acc_rows:\n",
    "        acc_df = pd.DataFrame(acc_rows,\n",
    "                              columns=[\"data_type\", \"timestamp\", \"timestamp_us\",\n",
    "                                       \"x\", \"y\", \"z\"])\n",
    "        acc_df = acc_df.astype({\n",
    "            \"data_type\": int,\n",
    "            \"timestamp\": int,\n",
    "            \"timestamp_us\": int,\n",
    "            \"x\": float,\n",
    "            \"y\": float,\n",
    "            \"z\": float,\n",
    "        })\n",
    "\n",
    "        acc_df[\"x_ms2\"] = acc_df[\"x\"]\n",
    "        acc_df[\"y_ms2\"] = acc_df[\"y\"]\n",
    "        acc_df[\"z_ms2\"] = acc_df[\"z\"]\n",
    "        acc_df[\"x_g\"] = acc_df[\"x_ms2\"] / GRAVITY\n",
    "        acc_df[\"y_g\"] = acc_df[\"y_ms2\"] / GRAVITY\n",
    "        acc_df[\"z_g\"] = acc_df[\"z_ms2\"] / GRAVITY\n",
    "\n",
    "        extreme_acc = ((acc_df[[\"x_ms2\", \"y_ms2\", \"z_ms2\"]].abs() > 50).any(axis=1)).sum()\n",
    "        if extreme_acc:\n",
    "            logger.warning(f\"{extreme_acc} accelerometer points >50 m/s² detected\")\n",
    "\n",
    "    # 1.3 Gyroscope \n",
    "    gyro_df = pd.DataFrame()\n",
    "    if gyro_rows:\n",
    "        gyro_df = pd.DataFrame(gyro_rows,\n",
    "                               columns=[\"data_type\", \"timestamp\", \"timestamp_us\",\n",
    "                                        \"x\", \"y\", \"z\"])\n",
    "        gyro_df = gyro_df.astype({\n",
    "            \"data_type\": int,\n",
    "            \"timestamp\": int,\n",
    "            \"timestamp_us\": int,\n",
    "            \"x\": float,\n",
    "            \"y\": float,\n",
    "            \"z\": float,\n",
    "        })\n",
    "        extreme_gyro = ((gyro_df[[\"x\", \"y\", \"z\"]].abs() > 20).any(axis=1)).sum()\n",
    "        if extreme_gyro:\n",
    "            logger.warning(f\"{extreme_gyro} gyro points >20 rad/s detected\")\n",
    "\n",
    "    # 1.4 Rotation vector \n",
    "    rot_df = pd.DataFrame()\n",
    "    if rot_rows:\n",
    "        rot_df = pd.DataFrame(rot_rows,\n",
    "                              columns=[\"data_type\", \"timestamp\", \"timestamp_us\",\n",
    "                                       \"i\", \"j\", \"k\", \"real\"])\n",
    "        rot_df = rot_df.astype({\n",
    "            \"data_type\": int,\n",
    "            \"timestamp\": int,\n",
    "            \"timestamp_us\": int,\n",
    "            \"i\": float,\n",
    "            \"j\": float,\n",
    "            \"k\": float,\n",
    "            \"real\": float,\n",
    "        })\n",
    "        invalid_quat = (~rot_df[[\"i\", \"j\", \"k\", \"real\"]].abs().le(1)).any(axis=1).sum()\n",
    "        if invalid_quat:\n",
    "            logger.warning(f\"{invalid_quat} quaternion rows out of [-1,1] range\")\n",
    "\n",
    "    logger.info(\"Parsed data summary: \"\n",
    "                f\"GPS={len(gps_df)}, ACC={len(acc_df)}, \"\n",
    "                f\"GYRO={len(gyro_df)}, ROT={len(rot_df)}\")\n",
    "\n",
    "    return {\"gps\": gps_df, \"acc\": acc_df, \"gyro\": gyro_df, \"rot\": rot_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d36494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality check\n",
    "def check_missing_values(data_dict):\n",
    "    sep = \"=\" * 50\n",
    "    print(f\"\\n{sep}\\nDETAILED DATA INSPECTION\\n{sep}\")\n",
    "    for name, df in data_dict.items():\n",
    "        print(f\"\\n{'='*20} {name.upper()} DATA {'='*20}\")\n",
    "        if df.empty:\n",
    "            print(\"None\")\n",
    "            continue\n",
    "        print(df.describe(include='all'))\n",
    "    print(f\"\\n{sep}\\nEND OF INSPECTION\\n{sep}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926ad0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction \n",
    "def extract_features(data_dict):\n",
    "    \"\"\"Generate route / behavior / turning features.\"\"\"\n",
    "    features = {}\n",
    "    # — GPS route features —\n",
    "    if not data_dict[\"gps\"].empty:\n",
    "        gps_df = data_dict[\"gps\"].copy()\n",
    "        dist, grad = [], []\n",
    "        for i in range(1, len(gps_df)):\n",
    "            p1 = (gps_df[\"latitude\"].iat[i-1], gps_df[\"longitude\"].iat[i-1])\n",
    "            p2 = (gps_df[\"latitude\"].iat[i],   gps_df[\"longitude\"].iat[i])\n",
    "            try:\n",
    "                d = geodesic(p1, p2).meters\n",
    "            except Exception:\n",
    "                d = 0\n",
    "            dist.append(d)\n",
    "            grad.append((gps_df[\"altitude\"].iat[i] - gps_df[\"altitude\"].iat[i-1]) / d if d else 0)\n",
    "        gps_df.loc[1:, \"distance\"] = dist\n",
    "        gps_df.loc[1:, \"gradient\"] = grad\n",
    "        gps_df[[\"distance\", \"gradient\"]].fillna(0, inplace=True)\n",
    "        # acceleration from speed diff\n",
    "        dt = gps_df[\"timestamp\"].diff().fillna(1) / 1000\n",
    "        gps_df[\"time_diff\"] = dt\n",
    "        gps_df[\"speed_change\"] = gps_df[\"speed\"].diff().fillna(0)\n",
    "        gps_df[\"acceleration\"] = np.where(dt > 0, gps_df[\"speed_change\"] / dt, 0)\n",
    "        gps_df[\"acceleration\"] = gps_df[\"acceleration\"].clip(-10, 10)\n",
    "        features[\"route\"] = gps_df\n",
    "    # — ACC behavior features —\n",
    "    if not data_dict[\"acc\"].empty:\n",
    "        acc_df = data_dict[\"acc\"].copy()\n",
    "        acc_df[\"magnitude\"] = np.linalg.norm(acc_df[[\"x_ms2\", \"y_ms2\", \"z_ms2\"]].values, axis=1)\n",
    "        dt = acc_df[\"timestamp\"].diff().fillna(1) / 1000\n",
    "        acc_df[\"jerk\"] = np.where(dt > 0, acc_df[\"magnitude\"].diff().fillna(0) / dt, 0)\n",
    "        if len(acc_df) > 5:\n",
    "            win = min(21, len(acc_df)//2*2+1)\n",
    "            acc_df[\"jerk_smooth\"] = savgol_filter(acc_df[\"jerk\"], win, 3)\n",
    "        else:\n",
    "            acc_df[\"jerk_smooth\"] = acc_df[\"jerk\"]\n",
    "\n",
    "        acc_df[\"jerk_smooth\"] = acc_df[\"jerk_smooth\"].clip(-10, 10)\n",
    "\n",
    "        features[\"behavior\"] = acc_df\n",
    "    if not data_dict[\"gyro\"].empty:\n",
    "        gyro_df = data_dict[\"gyro\"].copy()\n",
    "        gyro_df[\"turning_rate\"] = gyro_df[\"z\"].abs()\n",
    "        features[\"turning\"] = gyro_df\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783e5c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_energy_consumption(features):\n",
    "    \"\"\"\n",
    "    Model energy consumption based on route and behavior features.\n",
    "    \n",
    "    Args:\n",
    "        features: Dictionary of feature dataframes\n",
    "        \n",
    "    Returns:\n",
    "        Combined dataframe with energy consumption estimates\n",
    "    \"\"\"\n",
    "    logger.info(\"Modeling energy consumption\")\n",
    "    \n",
    "    if 'route' in features and 'behavior' in features:\n",
    "        try:\n",
    "            route_times = features['route']['timestamp'].values\n",
    "            behavior_times = features['behavior']['timestamp'].values\n",
    "            \n",
    "            combined_data = []\n",
    "            sync_errors = 0\n",
    "            \n",
    "            for i, row in features['route'].iterrows():\n",
    "                gps_time = row['timestamp']\n",
    "                \n",
    "                time_diffs = np.abs(behavior_times - gps_time)\n",
    "                closest_acc_idx = np.argmin(time_diffs)\n",
    "                \n",
    "                min_time_diff = time_diffs[closest_acc_idx]\n",
    "                if min_time_diff > MAX_TIME_DIFF:\n",
    "                    sync_errors += 1\n",
    "                    continue\n",
    "                \n",
    "                entry = {\n",
    "                    'timestamp': gps_time,\n",
    "                    'speed': row['speed'],\n",
    "                    'acceleration': row['acceleration'],\n",
    "                    'gradient': row['gradient'],\n",
    "                    'acc_x': features['behavior']['x_ms2'].iloc[closest_acc_idx],\n",
    "                    'acc_y': features['behavior']['y_ms2'].iloc[closest_acc_idx],\n",
    "                    'acc_z': features['behavior']['z_ms2'].iloc[closest_acc_idx],\n",
    "                    'jerk': features['behavior']['jerk_smooth'].iloc[closest_acc_idx]\n",
    "                }\n",
    "                \n",
    "                if 'turning' in features:\n",
    "                    turning_times = features['turning']['timestamp'].values\n",
    "                    closest_turn_idx = np.argmin(np.abs(turning_times - gps_time))\n",
    "                    turn_time_diff = np.abs(turning_times[closest_turn_idx] - gps_time)\n",
    "                    \n",
    "                    if turn_time_diff <= MAX_TIME_DIFF:\n",
    "                        entry['turning_rate'] = features['turning']['turning_rate'].iloc[closest_turn_idx]\n",
    "                    else:\n",
    "                        entry['turning_rate'] = 0\n",
    "                else:\n",
    "                    entry['turning_rate'] = 0\n",
    "                    \n",
    "                combined_data.append(entry)\n",
    "            \n",
    "            if sync_errors > 0:\n",
    "                logger.warning(f\"Skipped {sync_errors} points due to synchronization errors (time diff > {MAX_TIME_DIFF}ms)\")\n",
    "            \n",
    "            combined_df = pd.DataFrame(combined_data)\n",
    "            \n",
    "            combined_df['acceleration'] = combined_df['acceleration'].clip(-5, 5) \n",
    "            combined_df['jerk']         = combined_df['jerk'].clip(-10, 10)\n",
    "\n",
    "            if not combined_df.empty:\n",
    "                # Calculate energy factors\n",
    "                combined_df['energy_factor'] = calculate_energy_factors(combined_df)\n",
    "                logger.info(f\"Successfully created combined data with energy modeling: {len(combined_df)} records\")\n",
    "                return combined_df\n",
    "            else:\n",
    "                logger.warning(\"No synchronized data points found between GPS and accelerometer data\")\n",
    "                return pd.DataFrame()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in energy consumption modeling: {e}\")\n",
    "            return pd.DataFrame()\n",
    "    else:\n",
    "        missing = []\n",
    "        if 'route' not in features:\n",
    "            missing.append('route')\n",
    "        if 'behavior' not in features:\n",
    "            missing.append('behavior')\n",
    "        logger.warning(f\"Cannot model energy consumption: missing required feature types: {', '.join(missing)}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeed9218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_energy_factors(df):\n",
    "    \"\"\"\n",
    "    Return traction power (W)  **always ≥0**  and\n",
    "    attach per-segment energy (J) into df['energy_J'].\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mass = 2500        # kg\n",
    "        g    = 9.81        # m/s²\n",
    "        rho  = 1.225       # kg/m³\n",
    "        Cd   = 0.319\n",
    "        A    = 2.54        # m²\n",
    "        Cr   = 0.013\n",
    "\n",
    "        power_W = np.zeros(len(df))\n",
    "\n",
    "        for i in range(len(df)):\n",
    "            v = max(0.1, df['speed'].iloc[i])                 # m/s\n",
    "            θ = np.arctan(df['gradient'].iloc[i])             # rad\n",
    "\n",
    "            F_roll = Cr * mass * g * np.cos(θ)\n",
    "            F_aero = 0.5 * rho * Cd * A * v**2\n",
    "            F_grad = mass * g * np.sin(θ)\n",
    "            F_acc  = mass * df['acceleration'].iloc[i]\n",
    "\n",
    "            F_total = F_roll + F_aero + F_grad + F_acc\n",
    "            F_traction = max(F_total, 0)                  \n",
    "\n",
    "            power_W[i] = F_traction * v\n",
    "\n",
    "        df['power_W'] = power_W\n",
    "\n",
    "        dt = df['timestamp'].diff().fillna(0) / 1000.0        # s\n",
    "        df['energy_J'] = power_W * dt.values\n",
    "\n",
    "        return power_W\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error calculating energy factors: {e}\")\n",
    "        return np.zeros(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1a8136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_driving_behaviors(combined_data, n_clusters: int = 3):\n",
    "\n",
    "    logger.info(f\"Clustering driving behaviours into {n_clusters} groups\")\n",
    "\n",
    "    required = ['speed', 'acceleration', 'jerk', 'turning_rate', 'energy_J']\n",
    "    for col in required:\n",
    "        if col not in combined_data.columns:\n",
    "            logger.warning(f\"Missing column '{col}', filling 0.\")\n",
    "            combined_data[col] = 0.0\n",
    "\n",
    "    # jerk\n",
    "    combined_data['acceleration'] = combined_data['acceleration'].clip(-5, 5)   # ±0.5 g\n",
    "    combined_data['jerk']         = combined_data['jerk'].clip(-10, 10)\n",
    "\n",
    "    # K-Means\n",
    "    feats = ['speed', 'acceleration', 'jerk', 'turning_rate']\n",
    "    X = combined_data[feats].fillna(0)\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # PCA for plotting\n",
    "    try:\n",
    "        pca = PCA(n_components=2)\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"PCA failed: {e}; using first two dims\")\n",
    "        X_pca = X_scaled[:, :2]\n",
    "        \n",
    "    n_clusters = min(n_clusters, max(1, len(X) - 1))\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    clusters = kmeans.fit_predict(X_scaled)\n",
    "    combined_data['driver_cluster'] = clusters\n",
    "\n",
    "    # profile（kWh / 100 km）\n",
    "    cluster_profiles = {}\n",
    "    for cid in range(n_clusters):\n",
    "        data_c = combined_data[combined_data['driver_cluster'] == cid]\n",
    "        if data_c.empty:\n",
    "            cluster_profiles[cid] = {'size': 0, 'driver_type': 'unknown'}\n",
    "            continue\n",
    "\n",
    "        dt = data_c['timestamp'].diff().fillna(0) / 1000.0        # s\n",
    "        dist_km = (data_c['speed'] * dt).sum() / 1000.0\n",
    "\n",
    "        energy_kWh = data_c['energy_J'].sum() / 3.6e6\n",
    "\n",
    "        energy_eff = energy_kWh / dist_km * 100 if dist_km > 0 else 0.0\n",
    "\n",
    "        profile = {\n",
    "            'size': len(data_c),\n",
    "            'avg_speed': data_c['speed'].mean(),\n",
    "            'std_speed': data_c['speed'].std(),\n",
    "            'avg_acceleration': data_c['acceleration'].mean(),\n",
    "            'std_acceleration': data_c['acceleration'].std(),\n",
    "            'avg_jerk': data_c['jerk'].mean(),\n",
    "            'std_jerk': data_c['jerk'].std(),\n",
    "            'avg_turning_rate': data_c['turning_rate'].mean(),\n",
    "            'std_turning_rate': data_c['turning_rate'].std(),\n",
    "            'energy_efficiency': energy_eff,          # kWh / 100 km\n",
    "        }\n",
    "\n",
    "        if profile['avg_jerk'] > 2:\n",
    "            profile['driver_type'] = 'aggressive'\n",
    "        elif abs(profile['avg_acceleration']) > 3:     # ≈0.3 g\n",
    "            profile['driver_type'] = 'dynamic'\n",
    "        elif profile['avg_turning_rate'] > 0.3:\n",
    "            profile['driver_type'] = 'cornering'\n",
    "        else:\n",
    "            profile['driver_type'] = 'efficient'\n",
    "\n",
    "        cluster_profiles[cid] = profile\n",
    "\n",
    "    logger.info(f\"Created {n_clusters} driver clusters.\")\n",
    "    return combined_data, cluster_profiles, X_pca, clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9642cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def develop_control_strategy(combined_data, cluster_profiles):\n",
    "    \"\"\"\n",
    "    Develop adaptive control strategies based on driver clusters\n",
    "    \n",
    "    Args:\n",
    "        combined_data: Dataframe with combined sensor data and features\n",
    "        cluster_profiles: Dictionary with statistical profiles for each cluster\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (model, feature_importance, control_strategies, feature_names)\n",
    "    \"\"\"\n",
    "    logger.info(\"Developing control strategies based on driver clusters\")\n",
    "    \n",
    "    features = ['speed', 'acceleration', 'gradient', 'turning_rate', 'driver_cluster']\n",
    "    \n",
    "    for feature in features:\n",
    "        if feature not in combined_data.columns:\n",
    "            logger.warning(f\"Feature '{feature}' not found in data. Adding with default value.\")\n",
    "            if feature == 'driver_cluster':\n",
    "                combined_data[feature] = 0\n",
    "            else:\n",
    "                combined_data[feature] = 0.0\n",
    "    \n",
    "    if 'energy_factor' not in combined_data.columns:\n",
    "        logger.warning(\"'energy_factor' column not found. Adding with default values.\")\n",
    "        combined_data['energy_factor'] = 10.0\n",
    "    \n",
    "    for col in combined_data.columns:\n",
    "        if combined_data[col].isna().any():\n",
    "            logger.warning(f\"Filling missing values in '{col}' column\")\n",
    "            if col == 'driver_cluster':\n",
    "                combined_data[col] = combined_data[col].fillna(0).astype(int)\n",
    "            else:\n",
    "                mean_val = combined_data[col].mean() if combined_data[col].notna().any() else 0.0\n",
    "                combined_data[col] = combined_data[col].fillna(mean_val)\n",
    "    \n",
    "    X = pd.get_dummies(combined_data[features], columns=['driver_cluster'])\n",
    "    y = combined_data['energy_factor']\n",
    "    \n",
    "    feature_names = list(X.columns)\n",
    "    \n",
    "    try:\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        model.fit(X, y)\n",
    "        \n",
    "        feature_importance = dict(zip(X.columns, model.feature_importances_))\n",
    "        \n",
    "        control_strategies = {}\n",
    "        \n",
    "        for cluster, profile in cluster_profiles.items():\n",
    "            avg_jerk = profile.get('avg_jerk', 0.0)\n",
    "            avg_acceleration = profile.get('avg_acceleration', 0.0)\n",
    "            avg_turning_rate = profile.get('avg_turning_rate', 0.0)\n",
    "            avg_speed = profile.get('avg_speed', 30.0)\n",
    "            driver_type = profile.get('driver_type', 'default')\n",
    "            \n",
    "            if driver_type == 'aggressive' or avg_jerk > 0.5:\n",
    "                strategy = {\n",
    "                    'driver_type': 'aggressive',\n",
    "                    'acceleration_smoothing': True,\n",
    "                    'smooth_factor': min(1.0, avg_jerk / 2) if avg_jerk > 0 else 0.5,\n",
    "                    'anticipation_distance': 100 + (avg_speed * 5),\n",
    "                    'eco_mode_bias': 0.7,\n",
    "                    'description': 'Smooth out aggressive acceleration and deceleration'\n",
    "                }\n",
    "            elif driver_type == 'dynamic' or avg_acceleration > 1.0:\n",
    "                strategy = {\n",
    "                    'driver_type': 'dynamic',\n",
    "                    'acceleration_smoothing': True,\n",
    "                    'smooth_factor': 0.4,\n",
    "                    'anticipation_distance': 80 + (avg_speed * 3),\n",
    "                    'eco_mode_bias': 0.8,\n",
    "                    'description': 'Moderate dynamic driving with gentler transitions'\n",
    "                }\n",
    "            elif driver_type == 'cornering' or avg_turning_rate > 0.3:\n",
    "                strategy = {\n",
    "                    'driver_type': 'cornering',\n",
    "                    'acceleration_smoothing': False,\n",
    "                    'smooth_factor': 0.2,\n",
    "                    'anticipation_distance': 120 + (avg_speed * 4),\n",
    "                    'eco_mode_bias': 0.5,\n",
    "                    'description': 'Optimize for cornering with better anticipation'\n",
    "                }\n",
    "            else:\n",
    "                strategy = {\n",
    "                    'driver_type': 'efficient',\n",
    "                    'acceleration_smoothing': False,\n",
    "                    'smooth_factor': 0.1,\n",
    "                    'anticipation_distance': 60 + (avg_speed * 2),\n",
    "                    'eco_mode_bias': 0.3,\n",
    "                    'description': 'Maintain already efficient driving style'\n",
    "                }\n",
    "            \n",
    "            control_strategies[cluster] = strategy\n",
    "        \n",
    "        logger.info(f\"Successfully developed control strategies for {len(control_strategies)} driver clusters\")\n",
    "        return model, feature_importance, control_strategies, feature_names\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error developing control strategies: {e}\")\n",
    "        \n",
    "        # Return fallback default strategy\n",
    "        default_strategy = {\n",
    "            0: {\n",
    "                'driver_type': 'default',\n",
    "                'acceleration_smoothing': True,\n",
    "                'smooth_factor': 0.3,\n",
    "                'anticipation_distance': 80,\n",
    "                'eco_mode_bias': 0.5,\n",
    "                'description': 'Default balanced strategy'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        dummy_model = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "        dummy_X = np.zeros((len(combined_data), 1))\n",
    "        dummy_y = combined_data['energy_factor'] if 'energy_factor' in combined_data.columns else np.zeros(len(combined_data))\n",
    "        dummy_model.fit(dummy_X, dummy_y)\n",
    "        \n",
    "        dummy_importance = {'fallback_feature': 1.0}\n",
    "        \n",
    "        return dummy_model, dummy_importance, default_strategy, ['fallback_feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e02bd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(results):\n",
    "    \"\"\"\n",
    "    Visualize the results of the eco-driving analysis with simplified plots.\n",
    "    Args:\n",
    "        results: Dictionary with analysis results\n",
    "    \"\"\"\n",
    "    if isinstance(results, str):\n",
    "        print(f\"Cannot visualize results: {results}\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nVisualization diagnostics:\")\n",
    "    print(f\"Energy factor range: {results['data']['energy_factor'].min()} - {results['data']['energy_factor'].max()}\")\n",
    "    if 'feature_importance' in results:\n",
    "        print(\"Top 5 feature importance values:\")\n",
    "        for feature, importance in sorted(results['feature_importance'].items(), \n",
    "                                         key=lambda x: x[1], reverse=True)[:5]:\n",
    "            print(f\"  {feature}: {importance:.6f}\")\n",
    "\n",
    "    plt.figure(figsize=(16, 12))\n",
    "\n",
    "    # left up\n",
    "    plt.subplot(2, 2, 1)\n",
    "    scatter = plt.scatter(results['pca_data'][:, 0], results['pca_data'][:, 1], \n",
    "                         c=results['clusters'], cmap='viridis', alpha=0.8)\n",
    "    plt.title('Driver Behavior Clusters')\n",
    "    plt.xlabel('PCA Component 1')\n",
    "    plt.ylabel('PCA Component 2')\n",
    "    plt.colorbar(scatter, label='Cluster')\n",
    "\n",
    "    # right up\n",
    "    plt.subplot(2, 2, 2)\n",
    "    energy_by_cluster = results['data'].groupby('driver_cluster')['energy_factor'].mean()\n",
    "    plt.bar(range(len(energy_by_cluster)), energy_by_cluster.values)\n",
    "\n",
    "    plt.yscale('log') \n",
    "    plt.title('Average Energy Consumption by Cluster')\n",
    "    plt.xlabel('Cluster')\n",
    "    plt.ylabel('Energy Factor')\n",
    "    plt.xticks(range(len(energy_by_cluster)), [f'Cluster {i}' for i in energy_by_cluster.index])\n",
    "    \n",
    "    for i, v in enumerate(energy_by_cluster.values):\n",
    "        plt.text(i, v + v*0.01, f\"{v:.2f}\", ha='center')\n",
    "\n",
    "    # left down\n",
    "    plt.subplot(2, 2, 3)\n",
    "    if results['feature_importance'] and len(results['feature_importance']) > 0:\n",
    "        filtered_importance = {k: v for k, v in results['feature_importance'].items() if v > 0.001}\n",
    "        \n",
    "        if filtered_importance:\n",
    "            sorted_features = sorted(filtered_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "            features = [item[0] for item in sorted_features]\n",
    "            importances = [item[1] for item in sorted_features]\n",
    "            \n",
    "            max_features = min(10, len(features))\n",
    "            features = features[:max_features]\n",
    "            importances = importances[:max_features]\n",
    "            \n",
    "            plt.bar(range(len(features)), importances, color='coral')\n",
    "            plt.title('Feature Importance for Energy Consumption')\n",
    "            plt.xlabel('Feature')\n",
    "            plt.ylabel('Importance')\n",
    "            \n",
    "            readable_features = []\n",
    "            for f in features:\n",
    "                if 'driver_cluster' in f:\n",
    "                    readable_features.append(f.replace('driver_cluster_', 'Cluster '))\n",
    "                else:\n",
    "                    readable_features.append(f)\n",
    "                    \n",
    "            plt.xticks(range(len(features)), readable_features, rotation=45, ha='right')\n",
    "            \n",
    "            for i, v in enumerate(importances):\n",
    "                plt.text(i, v + v*0.01, f\"{v:.4f}\", ha='center')\n",
    "        else:\n",
    "            plt.text(0.5, 0.5, 'No significant feature importance values', \n",
    "                    horizontalalignment='center', verticalalignment='center')\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'No feature importance data available', \n",
    "                horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    try:\n",
    "        if len(results['data']) > 1000:\n",
    "            sample_size = min(1000, len(results['data']))\n",
    "            sample = results['data'].sample(sample_size).sort_values('timestamp')\n",
    "        else:\n",
    "            sample = results['data'].sort_values('timestamp')\n",
    "            \n",
    "        if sample['energy_factor'].max() > 1000:\n",
    "                plt.scatter(range(len(sample)),\n",
    "                np.log10(sample['energy_factor'].values),\n",
    "                s=30)                    \n",
    "                plt.title('Energy Factor Over Time (Log Scale)')\n",
    "                plt.ylabel('Log10(Energy Factor)')\n",
    "        else:\n",
    "                plt.scatter(range(len(sample)),\n",
    "                sample['energy_factor'].values,\n",
    "                s=30)\n",
    "                plt.title('Energy Factor Over Time')\n",
    "                plt.ylabel('Energy Factor')\n",
    "            \n",
    "        plt.xlabel('Sample Index')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    except Exception as e:\n",
    "        plt.text(0.5, 0.5, f'Error plotting energy time series: {str(e)}',\n",
    "                horizontalalignment='center', verticalalignment='center')\n",
    "        print(f\"Error plotting energy time series: {e}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('eco_driving_results.png')\n",
    "    print(\"Saved main visualization to 'eco_driving_results.png'\")\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    strategies = results['control_strategies']\n",
    "    \n",
    "    if strategies and len(strategies) > 0:\n",
    "        plt.subplot(1, 2, 1)\n",
    "        try:\n",
    "            clusters = list(strategies.keys())\n",
    "            cluster_labels = [f'Cluster {c}' for c in clusters]\n",
    "            \n",
    "            metrics = ['smooth_factor', 'eco_mode_bias']\n",
    "            metric_names = ['Smooth Factor', 'Eco Mode Bias']\n",
    "            \n",
    "            bar_width = 0.35\n",
    "            index = np.arange(len(clusters))\n",
    "            \n",
    "            for i, (metric, name) in enumerate(zip(metrics, metric_names)):\n",
    "                values = []\n",
    "                for c in clusters:\n",
    "                    values.append(strategies[c].get(metric, 0))\n",
    "                \n",
    "                plt.bar(index + i*bar_width, values, bar_width, \n",
    "                        label=name, alpha=0.7)\n",
    "                \n",
    "                # 添加数值标签\n",
    "                for j, v in enumerate(values):\n",
    "                    plt.text(j + i*bar_width, v + 0.01, f\"{v:.2f}\", ha='center')\n",
    "            \n",
    "            plt.xlabel('Driver Cluster')\n",
    "            plt.ylabel('Parameter Value')\n",
    "            plt.title('Control Strategy Parameters')\n",
    "            plt.xticks(index + bar_width/2, cluster_labels)\n",
    "            plt.legend()\n",
    "            plt.grid(True, linestyle='--', alpha=0.4)\n",
    "            \n",
    "        except Exception as e:\n",
    "            plt.text(0.5, 0.5, f'Error plotting control metrics: {str(e)}',\n",
    "                    horizontalalignment='center', verticalalignment='center')\n",
    "            print(f\"Error plotting control metrics: {e}\")\n",
    "        \n",
    "        # bar plot for driver types\n",
    "        plt.subplot(1, 2, 2)\n",
    "        try:\n",
    "            driver_types = []\n",
    "            for c in clusters:\n",
    "                driver_types.append(strategies[c].get('driver_type', 'unknown'))\n",
    "                \n",
    "            driver_type_counts = {}\n",
    "            for dtype in driver_types:\n",
    "                if dtype in driver_type_counts:\n",
    "                    driver_type_counts[dtype] += 1\n",
    "                else:\n",
    "                    driver_type_counts[dtype] = 1\n",
    "                    \n",
    "            labels = list(driver_type_counts.keys())\n",
    "            sizes = list(driver_type_counts.values())\n",
    "            \n",
    "            colors = {\n",
    "                'aggressive': 'red',\n",
    "                'dynamic': 'orange',\n",
    "                'cornering': 'purple',\n",
    "                'efficient': 'green',\n",
    "                'unknown': 'gray'\n",
    "            }\n",
    "            \n",
    "            pie_colors = [colors.get(dtype, 'blue') for dtype in labels]\n",
    "            \n",
    "            plt.pie(sizes, labels=labels, colors=pie_colors, autopct='%1.1f%%',\n",
    "                    startangle=90, shadow=True)\n",
    "            plt.axis('equal')  \n",
    "            plt.title('Driver Type Distribution')\n",
    "            \n",
    "        except Exception as e:\n",
    "            plt.text(0.5, 0.5, f'Error plotting driver types: {str(e)}',\n",
    "                    horizontalalignment='center', verticalalignment='center')\n",
    "            print(f\"Error plotting driver types: {e}\")\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'No control strategy data available', \n",
    "                horizontalalignment='center', verticalalignment='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('control_strategies.png')\n",
    "    print(\"Saved control strategies visualization to 'control_strategies.png'\")\n",
    "    \n",
    "    plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    if not results['data'].empty:\n",
    "        plt.subplot(2, 2, 1)\n",
    "        try:\n",
    "            if 'speed' in results['data'].columns and 'acceleration' in results['data'].columns:\n",
    "                scatter = plt.scatter(results['data']['speed'], results['data']['acceleration'], \n",
    "                                    c=results['data']['driver_cluster'], cmap='viridis', \n",
    "                                    alpha=0.7, s=40)\n",
    "                plt.title('Speed vs. Acceleration by Cluster')\n",
    "                plt.xlabel('Speed (m/s)')\n",
    "                plt.ylabel('Acceleration (m/s²)')\n",
    "                plt.colorbar(scatter, label='Cluster')\n",
    "                plt.grid(True, linestyle='--', alpha=0.5)\n",
    "            else:\n",
    "                plt.text(0.5, 0.5, 'Speed or acceleration data not available',\n",
    "                        horizontalalignment='center', verticalalignment='center')\n",
    "        except Exception as e:\n",
    "            plt.text(0.5, 0.5, f'Error plotting speed vs acceleration: {str(e)}',\n",
    "                    horizontalalignment='center', verticalalignment='center')\n",
    "            print(f\"Error plotting speed vs acceleration: {e}\")\n",
    "        \n",
    "        plt.subplot(2, 2, 2)\n",
    "        try:\n",
    "            if 'jerk' in results['data'].columns:\n",
    "                for cluster in range(len(results['cluster_profiles'])):\n",
    "                    cluster_data = results['data'][results['data']['driver_cluster'] == cluster]\n",
    "                    if not cluster_data.empty:\n",
    "                        plt.hist(cluster_data['jerk'], bins=20, alpha=0.5, \n",
    "                                label=f'Cluster {cluster}')\n",
    "                \n",
    "                plt.title('Jerk Distribution by Cluster')\n",
    "                plt.xlabel('Jerk (m/s³)')\n",
    "                plt.ylabel('Frequency')\n",
    "                plt.legend()\n",
    "                plt.grid(True, linestyle='--', alpha=0.7)\n",
    "            else:\n",
    "                plt.text(0.5, 0.5, 'Jerk data not available',\n",
    "                        horizontalalignment='center', verticalalignment='center')\n",
    "        except Exception as e:\n",
    "            plt.text(0.5, 0.5, f'Error plotting jerk distribution: {str(e)}',\n",
    "                    horizontalalignment='center', verticalalignment='center')\n",
    "            print(f\"Error plotting jerk distribution: {e}\")\n",
    "        \n",
    "        plt.subplot(2, 2, 3)\n",
    "        try:\n",
    "            if 'speed' in results['data'].columns:\n",
    "                for cluster in range(len(results['cluster_profiles'])):\n",
    "                    cluster_data = results['data'][results['data']['driver_cluster'] == cluster]\n",
    "                    if not cluster_data.empty:\n",
    "                        plt.hist(cluster_data['speed'], bins=20, alpha=0.5,\n",
    "                                label=f'Cluster {cluster}')\n",
    "                \n",
    "                plt.title('Speed Distribution by Cluster')\n",
    "                plt.xlabel('Speed (m/s)')\n",
    "                plt.ylabel('Frequency')\n",
    "                plt.legend()\n",
    "                plt.grid(True, linestyle='--', alpha=0.7)\n",
    "            else:\n",
    "                plt.text(0.5, 0.5, 'Speed data not available',\n",
    "                        horizontalalignment='center', verticalalignment='center')\n",
    "        except Exception as e:\n",
    "            plt.text(0.5, 0.5, f'Error plotting speed distribution: {str(e)}',\n",
    "                    horizontalalignment='center', verticalalignment='center')\n",
    "            print(f\"Error plotting speed distribution: {e}\")\n",
    "        \n",
    "        plt.subplot(2, 2, 4)\n",
    "        try:\n",
    "            if 'gradient' in results['data'].columns and 'energy_factor' in results['data'].columns:\n",
    "                if results['data']['energy_factor'].max() > 1000:\n",
    "                    scatter = plt.scatter(results['data']['gradient'], \n",
    "                                        np.log10(results['data']['energy_factor']),\n",
    "                                        c=results['data']['speed'], cmap='plasma', \n",
    "                                        alpha=0.7, s=40)\n",
    "                    plt.title('Log(Energy Factor) vs. Road Gradient')\n",
    "                    plt.ylabel('Log10(Energy Factor)')\n",
    "                else:\n",
    "                    scatter = plt.scatter(results['data']['gradient'], results['data']['energy_factor'],\n",
    "                                        c=results['data']['speed'], cmap='plasma', \n",
    "                                        alpha=0.7, s=40)\n",
    "                    plt.title('Energy Factor vs. Road Gradient')\n",
    "                    plt.ylabel('Energy Factor')\n",
    "                \n",
    "                plt.xlabel('Gradient')\n",
    "                plt.colorbar(scatter, label='Speed (m/s)')\n",
    "                plt.grid(True, linestyle='--', alpha=0.7)\n",
    "            else:\n",
    "                plt.text(0.5, 0.5, 'Gradient or energy_factor data not available',\n",
    "                        horizontalalignment='center', verticalalignment='center')\n",
    "        except Exception as e:\n",
    "            plt.text(0.5, 0.5, f'Error plotting energy vs gradient: {str(e)}',\n",
    "                    horizontalalignment='center', verticalalignment='center')\n",
    "            print(f\"Error plotting energy vs gradient: {e}\")\n",
    "    else:\n",
    "        for i in range(1, 5):\n",
    "            plt.subplot(2, 2, i)\n",
    "            plt.text(0.5, 0.5, 'No data available for visualization',\n",
    "                    horizontalalignment='center', verticalalignment='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('driver_behavior_analysis.png')\n",
    "    print(\"Saved driver behavior analysis visualization to 'driver_behavior_analysis.png'\")\n",
    "    \n",
    "    try:\n",
    "        results['data'].to_csv('eco_driving_data.csv', index=False)\n",
    "        print(\"Saved processed data to 'eco_driving_data.csv'\")\n",
    "        \n",
    "        with open('cluster_profiles.txt', 'w') as f:\n",
    "            f.write(\"=\" * 50 + \"\\n\")\n",
    "            f.write(\"ECO-DRIVING CLUSTER PROFILES\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "    \n",
    "            for cluster, profile in results['cluster_profiles'].items():\n",
    "                f.write(f\"Cluster {cluster}:\\n\")\n",
    "                f.write(\"-\" * 30 + \"\\n\")\n",
    "                for key, value in profile.items():\n",
    "                  if isinstance(value, float):\n",
    "                    if key == 'avg_acceleration':\n",
    "                      f.write(f\"  {key}: {value/9.81:.4f} g)\\n\")\n",
    "                    elif key == 'std_acceleration':\n",
    "                      f.write(f\"  {key}: {value/9.81:.4f} g)\\n\")\n",
    "                    elif key == 'avg_speed':\n",
    "                      f.write(f\"  {key}: {value*3.6:.4f} m/s\\n\")\n",
    "                    elif key == 'std_speed':\n",
    "                      f.write(f\"  {key}: {value*3.6:.4f} m/s\\n\")\n",
    "                    else:\n",
    "                      f.write(f\"  {key}: {value:.4f}\\n\")\n",
    "                  else:\n",
    "                   f.write(f\"  {key}: {value}\\n\")\n",
    "                f.write(\"\\n\")\n",
    "            \n",
    "        print(\"Saved cluster profiles to 'cluster_profiles.txt'\")\n",
    "        \n",
    "        # save control strategies\n",
    "        with open('control_strategies.txt', 'w') as f:\n",
    "            f.write(\"=\" * 50 + \"\\n\")\n",
    "            f.write(\"ECO-DRIVING CONTROL STRATEGIES\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "            \n",
    "            for cluster, strategy in results['control_strategies'].items():\n",
    "                f.write(f\"Cluster {cluster}:\\n\")\n",
    "                f.write(\"-\" * 30 + \"\\n\")\n",
    "                for key, value in strategy.items():\n",
    "                    if isinstance(value, float):\n",
    "                        f.write(f\"  {key}: {value:.4f}\\n\")\n",
    "                    else:\n",
    "                        f.write(f\"  {key}: {value}\\n\")\n",
    "                f.write(\"\\n\")\n",
    "                \n",
    "            f.write(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "            f.write(\"END OF CONTROL STRATEGIES\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\")\n",
    "            \n",
    "        print(\"Saved control strategies to 'control_strategies.txt'\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving data to files: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395fcefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveEcoDrivingController:\n",
    "    \"\"\"\n",
    "    Controller that provides real-time eco-driving recommendations based on driver behavior\n",
    "    \"\"\"\n",
    "    def __init__(self, energy_model, control_strategies, feature_names=None):\n",
    "        \"\"\"\n",
    "        Initialize the controller with trained model and strategies\n",
    "        \n",
    "        Args:\n",
    "            energy_model: Trained energy consumption prediction model\n",
    "            control_strategies: Dictionary of control strategies for each driver cluster\n",
    "            feature_names: List of feature names required by the model\n",
    "        \"\"\"\n",
    "        self.energy_model = energy_model\n",
    "        self.control_strategies = control_strategies\n",
    "        self.feature_names = feature_names\n",
    "        self.current_cluster = None\n",
    "        self.driver_history = []\n",
    "        self.strategy = None\n",
    "        logger.info(\"Initialized AdaptiveEcoDrivingController\")\n",
    "    \n",
    "    def update_driver_profile(self, recent_driving_data):\n",
    "        \"\"\"\n",
    "        Update driver profile based on recent driving data\n",
    "        \n",
    "        Args:\n",
    "            recent_driving_data: Dataframe with recent driving data\n",
    "            \n",
    "        Returns:\n",
    "            Current assigned driver cluster\n",
    "        \"\"\"\n",
    "        logger.info(\"Updating driver profile based on recent data\")\n",
    "        try:\n",
    "            features = ['speed', 'acceleration', 'jerk', 'turning_rate']\n",
    "            for feature in features:\n",
    "                if feature not in recent_driving_data.columns:\n",
    "                    logger.warning(f\"Feature '{feature}' missing from driver data. Using default value 0.\")\n",
    "                    recent_driving_data[feature] = 0.0\n",
    "            \n",
    "            X = recent_driving_data[features]\n",
    "            \n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X)\n",
    "            \n",
    "            kmeans = KMeans(n_clusters=len(self.control_strategies), random_state=42)\n",
    "            kmeans.fit(X_scaled)\n",
    "            \n",
    "            clusters = kmeans.predict(X_scaled)\n",
    "            \n",
    "            self.current_cluster = np.bincount(clusters).argmax()\n",
    "            \n",
    "            if self.current_cluster in self.control_strategies:\n",
    "                self.strategy = self.control_strategies[self.current_cluster]\n",
    "                logger.info(f\"Driver classified as cluster {self.current_cluster} ({self.strategy.get('driver_type', 'unknown')})\")\n",
    "            else:\n",
    "                first_cluster = list(self.control_strategies.keys())[0]\n",
    "                self.strategy = self.control_strategies[first_cluster]\n",
    "                logger.warning(f\"Cluster {self.current_cluster} not found in strategies, using default\")\n",
    "            \n",
    "            return self.current_cluster\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error updating driver profile: {e}\")\n",
    "            if self.control_strategies:\n",
    "                first_cluster = list(self.control_strategies.keys())[0]\n",
    "                self.current_cluster = first_cluster\n",
    "                self.strategy = self.control_strategies[first_cluster]\n",
    "            return self.current_cluster\n",
    "    \n",
    "    def recommend_actions(self, current_state):\n",
    "        \"\"\"\n",
    "        Provide eco-driving recommendations based on current vehicle state\n",
    "        \n",
    "        Args:\n",
    "            current_state: Dictionary with current vehicle state parameters\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with recommended actions\n",
    "        \"\"\"\n",
    "        logger.info(\"Generating eco-driving recommendations\")\n",
    "        try:\n",
    "            if self.strategy is None:\n",
    "                logger.warning(\"No active strategy, cannot recommend actions\")\n",
    "                return None\n",
    "            \n",
    "            state = {\n",
    "                'speed': current_state.get('speed', 0),\n",
    "                'gradient': current_state.get('gradient', 0),\n",
    "                'turning_rate': current_state.get('turning_rate', 0),\n",
    "                'acceleration': current_state.get('acceleration', 0)\n",
    "            }\n",
    "            \n",
    "            actions = {}\n",
    "            \n",
    "            target_acceleration = state['acceleration']\n",
    "            if self.strategy['acceleration_smoothing']:\n",
    "                if target_acceleration > 0:\n",
    "                    target_acceleration *= (1 - self.strategy['smooth_factor'])\n",
    "            \n",
    "            actions['target_acceleration'] = target_acceleration\n",
    "            \n",
    "            if state['gradient'] > 0.03:  \n",
    "                actions['speed_adjustment'] = -max(0, state['speed'] * 0.1 * self.strategy['eco_mode_bias'])\n",
    "            elif state['gradient'] < -0.03: \n",
    "                actions['speed_adjustment'] = min(5, state['speed'] * 0.05 * (1 - self.strategy['eco_mode_bias']))\n",
    "            else:  # Flat road\n",
    "                actions['speed_adjustment'] = 0\n",
    "            \n",
    "            if state['turning_rate'] > 0.2:\n",
    "                actions['speed_adjustment'] -= state['turning_rate'] * 5 * self.strategy['smooth_factor']\n",
    "            \n",
    "            base_energy = self.predict_energy_consumption(state)\n",
    "            adjusted_state = state.copy()\n",
    "            adjusted_state['acceleration'] = target_acceleration\n",
    "            adjusted_state['speed'] += actions['speed_adjustment']\n",
    "            adjusted_energy = self.predict_energy_consumption(adjusted_state)\n",
    "            \n",
    "            actions['expected_energy_saving'] = max(0, base_energy - adjusted_energy)\n",
    "            actions['driver_type'] = self.strategy.get('driver_type', 'unknown')\n",
    "            actions['strategy_description'] = self.strategy.get('description', '')\n",
    "            \n",
    "            logger.info(f\"Generated recommendations with expected energy saving: {actions['expected_energy_saving']:.2f}\")\n",
    "            return actions\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error recommending actions: {e}\")\n",
    "            return {\n",
    "                'target_acceleration': current_state.get('acceleration', 0),\n",
    "                'speed_adjustment': 0,\n",
    "                'expected_energy_saving': 0,\n",
    "                'error': str(e)\n",
    "            }\n",
    "    \n",
    "    def predict_energy_consumption(self, state):\n",
    "        \"\"\"\n",
    "        Predict energy consumption for a given vehicle state\n",
    "        \n",
    "        Args:\n",
    "            state: Dictionary with vehicle state parameters\n",
    "            \n",
    "        Returns:\n",
    "            Predicted energy consumption\n",
    "        \"\"\"\n",
    "        try:\n",
    "            X = pd.DataFrame([state])\n",
    "            \n",
    "            if self.current_cluster is not None:\n",
    "                for i in range(len(self.control_strategies)):\n",
    "                    X[f'driver_cluster_{i}'] = 1 if i == self.current_cluster else 0\n",
    "            \n",
    "            if self.feature_names:\n",
    "                for feature in self.feature_names:\n",
    "                    if feature not in X.columns:\n",
    "                        X[feature] = 0\n",
    "                \n",
    "                X = X[self.feature_names]\n",
    "            \n",
    "            energy = self.energy_model.predict(X)[0]\n",
    "            return energy\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error predicting energy consumption: {e}\")\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc65d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eco_driving_analysis(data_file):\n",
    "    \"\"\"\n",
    "    Run the complete eco-driving analysis pipeline\n",
    "    Args:\n",
    "        data_file: Path to the input data file\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with analysis results or error message\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Starting eco-driving analysis for file: {data_file}\")\n",
    "        \n",
    "        data_dict = parse_data(data_file)\n",
    "        \n",
    "        has_data = any(not df.empty for df in data_dict.values())\n",
    "        if not has_data:\n",
    "            return \"No valid data found in file\"\n",
    "        \n",
    "        check_missing_values(data_dict)\n",
    "        \n",
    "        features = extract_features(data_dict)\n",
    "        \n",
    "        if not features:\n",
    "            return \"Failed to extract features from data\"\n",
    "        \n",
    "        combined_data = model_energy_consumption(features)\n",
    "        \n",
    "        if combined_data.empty:\n",
    "            logger.warning(\"Empty combined data. Attempting to use partial data...\")\n",
    "            if 'route' in features and not features['route'].empty:\n",
    "                combined_data = features['route'].copy()\n",
    "                for col in ['acceleration', 'jerk', 'turning_rate', 'energy_factor']:\n",
    "                    if col not in combined_data.columns:\n",
    "                        combined_data[col] = 0.0\n",
    "            elif 'behavior' in features and not features['behavior'].empty:\n",
    "                combined_data = features['behavior'].copy()\n",
    "                combined_data['speed'] = combined_data.get('speed', 30.0)\n",
    "                combined_data['acceleration'] = combined_data.get('acceleration', 0.0)\n",
    "                combined_data['gradient'] = 0.0\n",
    "                combined_data['turning_rate'] = 0.0\n",
    "                combined_data['energy_factor'] = combined_data.get('magnitude', 10.0)\n",
    "        \n",
    "        if combined_data.empty:\n",
    "            return \"Insufficient data for analysis\"\n",
    "        \n",
    "        for col in ['speed', 'acceleration', 'jerk', 'turning_rate', 'energy_factor']:\n",
    "            if col not in combined_data.columns:\n",
    "                logger.warning(f\"Adding missing column '{col}' with default values\")\n",
    "                combined_data[col] = 0.0\n",
    "        \n",
    "        for col in combined_data.columns:\n",
    "            if combined_data[col].isna().any():\n",
    "                logger.warning(f\"Filling missing values in '{col}' column\")\n",
    "                fill_value = combined_data[col].mean() if combined_data[col].notna().any() else 0.0\n",
    "                combined_data[col] = combined_data[col].fillna(fill_value)\n",
    "        \n",
    "        n_clusters = min(3, max(1, len(combined_data) // 10))\n",
    "        logger.info(f\"Clustering data into {n_clusters} groups\")\n",
    "        \n",
    "        clustered_data, cluster_profiles, X_pca, clusters = cluster_driving_behaviors(combined_data, n_clusters)\n",
    "        \n",
    "        model, feature_importance, control_strategies, feature_names = develop_control_strategy(clustered_data, cluster_profiles)\n",
    "        \n",
    "        results = {\n",
    "            'data': clustered_data,\n",
    "            'cluster_profiles': cluster_profiles,\n",
    "            'pca_data': X_pca,\n",
    "            'clusters': clusters,\n",
    "            'energy_model': model,\n",
    "            'feature_importance': feature_importance,\n",
    "            'control_strategies': control_strategies,\n",
    "            'feature_names': feature_names,\n",
    "            'n_clusters': n_clusters\n",
    "        }\n",
    "        \n",
    "        logger.info(\"Eco-driving analysis completed successfully\")\n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in eco-driving analysis: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return f\"Analysis error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbcbb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    data_file = \"ts_1747221572.csv\" \n",
    "    \n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    \n",
    "    print(f\"Processing file: {data_file}\")\n",
    "    \n",
    "    results = run_eco_driving_analysis(data_file)\n",
    "    \n",
    "    if isinstance(results, str):\n",
    "        print(f\"Analysis error: {results}\")\n",
    "    else:\n",
    "        print(\"Analysis completed successfully. Visualizing results...\")\n",
    "        try:\n",
    "            visualize_results(results)\n",
    "            \n",
    "            controller = AdaptiveEcoDrivingController(\n",
    "                results['energy_model'],\n",
    "                results['control_strategies'],\n",
    "                results.get('feature_names')\n",
    "            )\n",
    "            \n",
    "            sample_state = {\n",
    "                'speed': 60,       \n",
    "                'gradient': 0.02,   \n",
    "                'turning_rate': 0.1, \n",
    "                'acceleration': 1.2  \n",
    "            }\n",
    "            \n",
    "            sample_recent_data = results['data'].tail(min(100, len(results['data'])))\n",
    "            driver_cluster = controller.update_driver_profile(sample_recent_data)\n",
    "            \n",
    "            actions = controller.recommend_actions(sample_state)\n",
    "            \n",
    "            print(\"\\nSample Eco-Driving Recommendations:\")\n",
    "            print(f\"Driver Cluster: {driver_cluster}\")\n",
    "            print(f\"Driver Type: {actions.get('driver_type', 'unknown')}\")\n",
    "            print(f\"Description: {actions.get('strategy_description', '')}\")\n",
    "            print(f\"Recommended target acceleration: {actions['target_acceleration']:.2f} m/s²\")\n",
    "            print(f\"Recommended speed adjustment: {actions['speed_adjustment']:.2f} m/s\")\n",
    "            print(f\"Expected energy saving: {actions['expected_energy_saving']:.2f}\")\n",
    "            \n",
    "            print(\"\\nEco-Driving Analysis Summary:\")\n",
    "            energy_data = results['data']['energy_factor']\n",
    "            print(f\"  Average Energy Factor: {energy_data.mean():.2f}\")\n",
    "            print(f\"  Energy Factor Range: {energy_data.min():.2f} - {energy_data.max():.2f}\")\n",
    "            \n",
    "            print(\"\\nDriver Behavior Clusters:\")\n",
    "            for cluster, profile in results['cluster_profiles'].items():\n",
    "                print(f\"  Cluster {cluster} ({profile.get('driver_type', 'unknown')}):\")\n",
    "                print(f\"    Size: {profile.get('size', 0)} samples\")\n",
    "                print(f\"    Average Speed: {profile['avg_speed']*9.81*3.6:.2f} m/s\")\n",
    "                print(f\"    Average Acceleration: {profile['avg_acceleration']/9.81:.2f} g\")\n",
    "                print(f\"    Energy Efficiency: {profile['energy_efficiency']:.2f}\")\n",
    "            \n",
    "            print(\"\\nEco-driving analysis and visualization completed successfully!\")\n",
    "            print(\"Results saved to:\")\n",
    "            print(\"  - eco_driving_data.csv\")\n",
    "            print(\"  - cluster_profiles.txt\")\n",
    "            print(\"  - control_strategies.txt\")\n",
    "            print(\"  - eco_driving_results.png\")\n",
    "            print(\"  - control_strategies.png\")\n",
    "            print(\"  - driver_behavior_analysis.png\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during visualization or results processing: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
