{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27315b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 15:22:06,499 - INFO - EcoDrivingAnalyzer v2.1 initialized (microsecond timestamps)\n",
      "2025-05-27 15:22:06,499 - INFO - Parsing sensor data from ts_1747221572.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Running Eco-Driving Analysis - Startup Phase Optimized\n",
      "ğŸ“ Data file: ts_1747221572.csv\n",
      "ğŸ”§ Configuration: Optimized for startup phase with microsecond precision\n",
      "â±ï¸  Expected analysis time: 30-60 seconds\n",
      "\n",
      "ğŸš— Starting Complete Eco-Driving Analysis System v2.1\n",
      "ğŸ“ Optimized for startup phase analysis with microsecond precision\n",
      "======================================================================\n",
      "ğŸ“Š Step 1: Parsing sensor data (microsecond timestamps)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 15:22:06,978 - INFO - Parsed 100000 lines from ts_1747221572.csv\n",
      "2025-05-27 15:22:07,134 - INFO - Extracting driving features with microsecond precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GPSæ•°æ®è§£æ ===\n",
      "GPSåŸå§‹è¡Œæ•°: 667\n",
      "æ ·æœ¬æ•°æ®: ['0', '1747221671', '57.687946', '11.980719', '56.200001', '2.857636', '12']\n",
      "GPSæ•°æ®è´¨é‡æ£€æŸ¥:\n",
      "  æ•°æ®ç‚¹æ•°: 667\n",
      "  æ—¶é—´è·¨åº¦: 0.0 ç§’ (0.0 åˆ†é’Ÿ)\n",
      "  é€Ÿåº¦èŒƒå›´: 0.0 - 91.8 km/h\n",
      "  ä½ç½®å˜åŒ–: çº¬åº¦ 0.038410Â°, ç»åº¦ 0.017737Â°\n",
      "\n",
      "=== åŠ é€Ÿåº¦ä¼ æ„Ÿå™¨æ•°æ®è§£æ ===\n",
      "åŠ é€Ÿåº¦åŸå§‹è¡Œæ•°: 84489\n",
      "æ ·æœ¬æ•°æ®: ['1', '1747221671', '3809', '-1.800781', '-0.957031', '9.539062']\n",
      "åŠ é€Ÿåº¦æ•°æ®è´¨é‡æ£€æŸ¥:\n",
      "  æ•°æ®ç‚¹æ•°: 84489\n",
      "  æ—¶é—´è·¨åº¦: 1.0 ç§’\n",
      "  åŸå§‹åŠ é€Ÿåº¦æœ€å¤§å€¼: 14.90\n",
      "\n",
      "=== é™€èºä»ªæ•°æ®è§£æ ===\n",
      "  æ•°æ®ç‚¹æ•°: 12051\n",
      "  Zè½´è§’é€Ÿåº¦èŒƒå›´: -0.529 - 0.596 rad/s\n",
      "ğŸ” Step 2: Extracting driving features...\n",
      "\n",
      "=== GPSç‰¹å¾æå– ===\n",
      "GPSåŠ é€Ÿåº¦è®¡ç®—ç»“æœ:\n",
      "  éé›¶å€¼: 0/667 (0.0%)\n",
      "  èŒƒå›´: 0.000 - 0.000 m/sÂ²\n",
      "  å¹³å‡: 0.000 m/sÂ²\n",
      "  æ ‡å‡†å·®: 0.000 m/sÂ²\n",
      "âš ï¸  GPSåŠ é€Ÿåº¦è®¡ç®—å¼‚å¸¸ï¼Œä½¿ç”¨æ”¹è¿›çš„åˆæˆæ–¹æ³•...\n",
      "  åˆæˆåŠ é€Ÿåº¦èŒƒå›´: -12.000 - 12.000 m/sÂ²\n",
      "\n",
      "=== åŠ é€Ÿåº¦ä¼ æ„Ÿå™¨ç‰¹å¾æå– ===\n",
      "åŸå§‹åŠ é€Ÿåº¦æ•°æ®ç»Ÿè®¡:\n",
      "  X: -5.055 - 2.758\n",
      "  Y: -5.785 - 4.367\n",
      "  Z: 3.523 - 14.902\n",
      "Magnitudeç»Ÿè®¡: 4.599 - 14.913\n",
      "Magnitudeå˜åŒ–ç»Ÿè®¡: -5.348178 - 5.949456\n",
      "æ—¶é—´é—´éš”ç»Ÿè®¡: 0.000000 - 0.000221 ç§’\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 15:22:07,509 - INFO - Synchronizing data and modeling energy consumption (microsecond precision)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jerkè®¡ç®—ç»“æœ:\n",
      "  åŸå§‹èŒƒå›´: -500.000 - 500.000 m/sÂ³\n",
      "  å¹³æ»‘åèŒƒå›´: 0.000 - 0.000 m/sÂ³\n",
      "  éé›¶å€¼: 96/84489\n",
      "  99%åˆ†ä½æ•°: Â±0.000 m/sÂ³\n",
      "\n",
      "=== é™€èºä»ªç‰¹å¾æå– ===\n",
      "é™€èºä»ªåŸå§‹æ•°æ®:\n",
      "  X: -0.264 - 0.252\n",
      "  Y: -0.387 - 0.428\n",
      "  Z: -0.529 - 0.596\n",
      "è½¬å‘ç‡ç»Ÿè®¡: 0.000 - 0.596\n",
      "âš¡ Step 3: Synchronizing data and modeling energy...\n",
      "\n",
      "=== æ•°æ®åŒæ­¥ (å¾®ç§’ç²¾åº¦) ===\n",
      "GPSæ•°æ®ç‚¹: 667\n",
      "åŠ é€Ÿåº¦æ•°æ®ç‚¹: 84489\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'EcoDrivingAnalyzer' object has no attribute '_calculate_energy_consumption'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1246\u001b[0m\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;66;03m# æ‰§è¡Œå®Œæ•´åˆ†æ\u001b[39;00m\n\u001b[0;32m-> 1246\u001b[0m analyzer \u001b[38;5;241m=\u001b[39m run_complete_eco_driving_analysis(data_file, startup_config)\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m analyzer:\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mğŸ‰ Analysis completed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[24], line 1184\u001b[0m, in \u001b[0;36mrun_complete_eco_driving_analysis\u001b[0;34m(data_file, config)\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;66;03m# 3. æ•°æ®åŒæ­¥å’Œèƒ½è€—å»ºæ¨¡\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâš¡ Step 3: Synchronizing data and modeling energy...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1184\u001b[0m combined_data \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39msynchronize_and_model_energy()\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m combined_data\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâŒ Failed to synchronize data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[24], line 598\u001b[0m, in \u001b[0;36mEcoDrivingAnalyzer.synchronize_and_model_energy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    595\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(combined_data)\n\u001b[1;32m    597\u001b[0m \u001b[38;5;66;03m# èƒ½è€—è®¡ç®—\u001b[39;00m\n\u001b[0;32m--> 598\u001b[0m combined_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergy_factor\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_energy_consumption(combined_df)\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124måŒæ­¥ç»“æœ:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  å®Œç¾åŒ¹é…: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mperfect_matches\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EcoDrivingAnalyzer' object has no attribute '_calculate_energy_consumption'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.signal import savgol_filter\n",
    "from geopy.distance import geodesic\n",
    "import warnings\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "# é…ç½®æ—¥å¿—å’Œå¸¸é‡\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ç³»ç»Ÿå¸¸é‡ - ä¿®æ­£ä¸ºå¾®ç§’\n",
    "GRAVITY = 9.81\n",
    "MAX_TIME_DIFF = 5000000  # æœ€å¤§æ—¶é—´å·®ï¼ˆå¾®ç§’ï¼‰5ç§’\n",
    "MAX_SAMPLES = 100000     # å¢åŠ æœ€å¤§æ ·æœ¬æ•°\n",
    "VERSION = \"2.1\"\n",
    "\n",
    "class EcoDrivingAnalyzer:\n",
    "    \"\"\"ç”Ÿæ€é©¾é©¶åˆ†æä¸»ç±» - å¾®ç§’æ—¶é—´æˆ³ç‰ˆæœ¬\"\"\"\n",
    "    \n",
    "    def __init__(self, config=None):\n",
    "        \"\"\"åˆå§‹åŒ–åˆ†æå™¨\"\"\"\n",
    "        self.config = config or self._default_config()\n",
    "        self.raw_data = {}\n",
    "        self.processed_data = None\n",
    "        self.features = {}\n",
    "        self.results = {}\n",
    "        self.time_offset = None  # ç”¨äºè®¡ç®—ç›¸å¯¹æ—¶é—´\n",
    "        \n",
    "        logger.info(f\"EcoDrivingAnalyzer v{VERSION} initialized (microsecond timestamps)\")\n",
    "    \n",
    "    def _default_config(self):\n",
    "        \"\"\"é»˜è®¤é…ç½®\"\"\"\n",
    "        return {\n",
    "            'hard_brake_threshold': -2.5,\n",
    "            'speed_drop_threshold': 8,\n",
    "            'min_brake_speed': 15,\n",
    "            'energy_model': {\n",
    "                'vehicle_mass': 1800,          # æ›´è½»çš„ä¹˜ç”¨è½¦\n",
    "                'drag_coefficient': 0.28,      # ç°ä»£è½¿è½¦é£é˜»ç³»æ•°\n",
    "                'frontal_area': 2.3,           # ç°ä»£è½¿è½¦è¿é£é¢ç§¯\n",
    "                'rolling_resistance': 0.012    # ç°ä»£è½®èƒæ»šåŠ¨é˜»åŠ›\n",
    "            },\n",
    "            'clustering': {\n",
    "                'n_clusters': 3,\n",
    "                'features': ['speed', 'acceleration', 'jerk', 'turning_rate']\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def parse_sensor_data(self, file_path):\n",
    "        \"\"\"è§£æä¼ æ„Ÿå™¨æ•°æ®æ–‡ä»¶ - ä¿®æ­£å¾®ç§’æ—¶é—´æˆ³å¤„ç†\"\"\"\n",
    "        logger.info(f\"Parsing sensor data from {file_path}\")\n",
    "        \n",
    "        gps_rows, acc_rows, gyro_rows, rot_rows = [], [], [], []\n",
    "        total_rows = 0\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, \"r\") as file:\n",
    "                for line_num, line in enumerate(file):\n",
    "                    values = line.strip().split(\",\")\n",
    "                    if len(values) < 2:\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        data_type = int(values[0])\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                    \n",
    "                    # ä¿®æ­£æ•°æ®è§£æé€»è¾‘\n",
    "                    if data_type == 0 and len(values) >= 6:  # GPSæ•°æ®\n",
    "                        gps_rows.append(values)\n",
    "                    elif data_type == 1 and len(values) >= 5:  # åŠ é€Ÿåº¦è®¡æ•°æ®\n",
    "                        acc_rows.append(values)\n",
    "                    elif data_type == 2 and len(values) >= 5:  # é™€èºä»ªæ•°æ®\n",
    "                        gyro_rows.append(values)\n",
    "                    elif data_type == 3 and len(values) >= 6:  # å››å…ƒæ•°æ•°æ®\n",
    "                        rot_rows.append(values)\n",
    "                    \n",
    "                    total_rows += 1\n",
    "                    if total_rows >= MAX_SAMPLES:\n",
    "                        break\n",
    "            \n",
    "            logger.info(f\"Parsed {total_rows} lines from {file_path}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading file: {e}\")\n",
    "            return False\n",
    "        \n",
    "        # å¤„ç†GPSæ•°æ®\n",
    "        if gps_rows:\n",
    "            print(f\"\\n=== GPSæ•°æ®è§£æ ===\")\n",
    "            print(f\"GPSåŸå§‹è¡Œæ•°: {len(gps_rows)}\")\n",
    "            print(f\"æ ·æœ¬æ•°æ®: {gps_rows[0]}\")\n",
    "            \n",
    "            # å¤„ç†GPSæ•°æ®æ ¼å¼ï¼š0,timestamp,lat,lon,alt,speed_kmh,satellites\n",
    "            gps_data = []\n",
    "            for row in gps_rows:\n",
    "                try:\n",
    "                    if len(row) >= 6:\n",
    "                        gps_data.append([\n",
    "                            int(row[0]),      # data_type\n",
    "                            int(row[1]),      # timestamp (å¾®ç§’)\n",
    "                            float(row[2]),    # latitude\n",
    "                            float(row[3]),    # longitude\n",
    "                            float(row[4]),    # altitude\n",
    "                            float(row[5]),    # speed_kmh\n",
    "                            int(row[6]) if len(row) > 6 else 12  # satellites\n",
    "                        ])\n",
    "                except (ValueError, IndexError) as e:\n",
    "                    continue\n",
    "            \n",
    "            if gps_data:\n",
    "                gps_df = pd.DataFrame(gps_data, columns=[\n",
    "                    \"data_type\", \"timestamp\", \"latitude\", \"longitude\", \n",
    "                    \"altitude\", \"speed_kmh\", \"satellites\"\n",
    "                ])\n",
    "                \n",
    "                gps_df[\"speed_ms\"] = gps_df[\"speed_kmh\"] / 3.6\n",
    "                \n",
    "                # è®¾ç½®æ—¶é—´åç§»é‡\n",
    "                if self.time_offset is None:\n",
    "                    self.time_offset = gps_df['timestamp'].min()\n",
    "                \n",
    "                # è®¡ç®—ç›¸å¯¹æ—¶é—´ï¼ˆç§’ï¼‰\n",
    "                gps_df['relative_time_s'] = (gps_df['timestamp'] - self.time_offset) / 1000000.0\n",
    "                \n",
    "                print(f\"GPSæ•°æ®è´¨é‡æ£€æŸ¥:\")\n",
    "                print(f\"  æ•°æ®ç‚¹æ•°: {len(gps_df)}\")\n",
    "                print(f\"  æ—¶é—´è·¨åº¦: {gps_df['relative_time_s'].max():.1f} ç§’ ({gps_df['relative_time_s'].max()/60:.1f} åˆ†é’Ÿ)\")\n",
    "                print(f\"  é€Ÿåº¦èŒƒå›´: {gps_df['speed_kmh'].min():.1f} - {gps_df['speed_kmh'].max():.1f} km/h\")\n",
    "                print(f\"  ä½ç½®å˜åŒ–: çº¬åº¦ {gps_df['latitude'].max()-gps_df['latitude'].min():.6f}Â°, ç»åº¦ {gps_df['longitude'].max()-gps_df['longitude'].min():.6f}Â°\")\n",
    "                \n",
    "                # æ•°æ®æ¸…æ´—\n",
    "                gps_df = gps_df[gps_df[\"speed_kmh\"] <= 200]\n",
    "                gps_df = gps_df[gps_df[\"latitude\"].between(-90, 90)]\n",
    "                gps_df = gps_df[gps_df[\"longitude\"].between(-180, 180)]\n",
    "                \n",
    "                self.raw_data['gps'] = gps_df\n",
    "        \n",
    "        # å¤„ç†åŠ é€Ÿåº¦ä¼ æ„Ÿå™¨æ•°æ®\n",
    "        if acc_rows:\n",
    "            print(f\"\\n=== åŠ é€Ÿåº¦ä¼ æ„Ÿå™¨æ•°æ®è§£æ ===\")\n",
    "            print(f\"åŠ é€Ÿåº¦åŸå§‹è¡Œæ•°: {len(acc_rows)}\")\n",
    "            print(f\"æ ·æœ¬æ•°æ®: {acc_rows[0]}\")\n",
    "            \n",
    "            # å¤„ç†åŠ é€Ÿåº¦æ•°æ®æ ¼å¼ï¼š1,timestamp,timestamp_us,x,y,z\n",
    "            acc_data = []\n",
    "            for row in acc_rows:\n",
    "                try:\n",
    "                    if len(row) >= 5:\n",
    "                        acc_data.append([\n",
    "                            int(row[0]),      # data_type\n",
    "                            int(row[1]),      # timestamp (å¾®ç§’)\n",
    "                            int(row[2]),      # timestamp_us (é¢å¤–çš„å¾®ç§’)\n",
    "                            float(row[3]),    # x\n",
    "                            float(row[4]),    # y\n",
    "                            float(row[5]) if len(row) > 5 else 0.0  # z\n",
    "                        ])\n",
    "                except (ValueError, IndexError):\n",
    "                    continue\n",
    "            \n",
    "            if acc_data:\n",
    "                acc_df = pd.DataFrame(acc_data, columns=[\n",
    "                    \"data_type\", \"timestamp\", \"timestamp_us\", \"x\", \"y\", \"z\"\n",
    "                ])\n",
    "                \n",
    "                # è®¡ç®—å®Œæ•´æ—¶é—´æˆ³ï¼ˆä¸»æ—¶é—´æˆ³ + å¾®ç§’åç§»ï¼‰\n",
    "                acc_df['full_timestamp'] = acc_df['timestamp'] + acc_df['timestamp_us']\n",
    "                \n",
    "                if self.time_offset is None:\n",
    "                    self.time_offset = acc_df['full_timestamp'].min()\n",
    "                \n",
    "                acc_df['relative_time_s'] = (acc_df['full_timestamp'] - self.time_offset) / 1000000.0\n",
    "                \n",
    "                print(f\"åŠ é€Ÿåº¦æ•°æ®è´¨é‡æ£€æŸ¥:\")\n",
    "                print(f\"  æ•°æ®ç‚¹æ•°: {len(acc_df)}\")\n",
    "                print(f\"  æ—¶é—´è·¨åº¦: {acc_df['relative_time_s'].max():.1f} ç§’\")\n",
    "                \n",
    "                # æ£€æŸ¥åŠ é€Ÿåº¦èŒƒå›´å’Œç¼©æ”¾\n",
    "                max_acc = max(acc_df['x'].abs().max(), acc_df['y'].abs().max(), acc_df['z'].abs().max())\n",
    "                print(f\"  åŸå§‹åŠ é€Ÿåº¦æœ€å¤§å€¼: {max_acc:.2f}\")\n",
    "                \n",
    "                # æ™ºèƒ½ç¼©æ”¾ - æ ¹æ®æ•°æ®èŒƒå›´åˆ¤æ–­å•ä½\n",
    "                if max_acc > 50:  # å¦‚æœæ•°å€¼å¾ˆå¤§ï¼Œå¯èƒ½éœ€è¦ç¼©æ”¾\n",
    "                    if max_acc > 1000:\n",
    "                        scale_factor = 1000.0\n",
    "                        print(\"  æ£€æµ‹åˆ°åŠ é€Ÿåº¦å•ä½å¯èƒ½æ˜¯ mgï¼Œåº”ç”¨1000xç¼©æ”¾\")\n",
    "                    else:\n",
    "                        scale_factor = 10.0\n",
    "                        print(\"  æ£€æµ‹åˆ°åŠ é€Ÿåº¦å•ä½å¼‚å¸¸ï¼Œåº”ç”¨10xç¼©æ”¾\")\n",
    "                    \n",
    "                    acc_df[[\"x\", \"y\", \"z\"]] = acc_df[[\"x\", \"y\", \"z\"]] / scale_factor\n",
    "                    print(f\"  ç¼©æ”¾åèŒƒå›´: {acc_df['x'].min():.2f} - {acc_df['x'].max():.2f}\")\n",
    "                \n",
    "                acc_df[\"magnitude\"] = np.sqrt(acc_df[\"x\"]**2 + acc_df[\"y\"]**2 + acc_df[\"z\"]**2)\n",
    "                self.raw_data['acc'] = acc_df\n",
    "        \n",
    "        # å¤„ç†é™€èºä»ªæ•°æ®\n",
    "        if gyro_rows:\n",
    "            print(f\"\\n=== é™€èºä»ªæ•°æ®è§£æ ===\")\n",
    "            gyro_data = []\n",
    "            for row in gyro_rows:\n",
    "                try:\n",
    "                    if len(row) >= 5:\n",
    "                        gyro_data.append([\n",
    "                            int(row[0]),      # data_type\n",
    "                            int(row[1]),      # timestamp\n",
    "                            int(row[2]),      # timestamp_us\n",
    "                            float(row[3]),    # x\n",
    "                            float(row[4]),    # y\n",
    "                            float(row[5]) if len(row) > 5 else 0.0  # z\n",
    "                        ])\n",
    "                except (ValueError, IndexError):\n",
    "                    continue\n",
    "            \n",
    "            if gyro_data:\n",
    "                gyro_df = pd.DataFrame(gyro_data, columns=[\n",
    "                    \"data_type\", \"timestamp\", \"timestamp_us\", \"x\", \"y\", \"z\"\n",
    "                ])\n",
    "                gyro_df['full_timestamp'] = gyro_df['timestamp'] + gyro_df['timestamp_us']\n",
    "                \n",
    "                if self.time_offset is None:\n",
    "                    self.time_offset = gyro_df['full_timestamp'].min()\n",
    "                \n",
    "                gyro_df['relative_time_s'] = (gyro_df['full_timestamp'] - self.time_offset) / 1000000.0\n",
    "                gyro_df[\"turning_rate\"] = gyro_df[\"z\"].abs()\n",
    "                \n",
    "                print(f\"  æ•°æ®ç‚¹æ•°: {len(gyro_df)}\")\n",
    "                print(f\"  Zè½´è§’é€Ÿåº¦èŒƒå›´: {gyro_df['z'].min():.3f} - {gyro_df['z'].max():.3f} rad/s\")\n",
    "                \n",
    "                self.raw_data['gyro'] = gyro_df\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def extract_driving_features(self):\n",
    "        \"\"\"æå–é©¾é©¶ç‰¹å¾ - ä¿®æ­£æ—¶é—´å¤„ç†å’ŒJerkè®¡ç®—\"\"\"\n",
    "        logger.info(\"Extracting driving features with microsecond precision\")\n",
    "        \n",
    "        # GPSè·¯çº¿ç‰¹å¾\n",
    "        if 'gps' in self.raw_data and not self.raw_data['gps'].empty:\n",
    "            gps_df = self.raw_data['gps'].copy().sort_values('timestamp').reset_index(drop=True)\n",
    "            \n",
    "            print(f\"\\n=== GPSç‰¹å¾æå– ===\")\n",
    "            \n",
    "            # è®¡ç®—è·ç¦»å’Œå¡åº¦\n",
    "            distances, gradients = [], []\n",
    "            for i in range(1, len(gps_df)):\n",
    "                p1 = (gps_df[\"latitude\"].iloc[i-1], gps_df[\"longitude\"].iloc[i-1])\n",
    "                p2 = (gps_df[\"latitude\"].iloc[i], gps_df[\"longitude\"].iloc[i])\n",
    "                try:\n",
    "                    d = geodesic(p1, p2).meters\n",
    "                except Exception:\n",
    "                    d = 0\n",
    "                distances.append(d)\n",
    "                \n",
    "                alt_diff = gps_df[\"altitude\"].iloc[i] - gps_df[\"altitude\"].iloc[i-1]\n",
    "                gradient = alt_diff / d if d > 0.5 else 0  # è·ç¦»>0.5ç±³æ‰è®¡ç®—å¡åº¦\n",
    "                gradients.append(gradient)\n",
    "            \n",
    "            if distances:\n",
    "                gps_df.loc[1:, \"distance\"] = distances\n",
    "                gps_df.loc[1:, \"gradient\"] = gradients\n",
    "            gps_df[\"distance\"] = gps_df.get(\"distance\", 0).fillna(0)\n",
    "            gps_df[\"gradient\"] = gps_df.get(\"gradient\", 0).fillna(0)\n",
    "            \n",
    "            # ä¿®æ­£çš„åŠ é€Ÿåº¦è®¡ç®— - ä½¿ç”¨å¾®ç§’ç²¾åº¦ï¼Œæ”¾å®½é™åˆ¶\n",
    "            dt_values = gps_df[\"timestamp\"].diff() / 1000000.0  # è½¬æ¢ä¸ºç§’\n",
    "            speed_changes_ms = gps_df[\"speed_ms\"].diff()\n",
    "            \n",
    "            accelerations = []\n",
    "            for i in range(len(gps_df)):\n",
    "                if i == 0:\n",
    "                    accelerations.append(0.0)\n",
    "                else:\n",
    "                    dt = dt_values.iloc[i]\n",
    "                    speed_change = speed_changes_ms.iloc[i]\n",
    "                    \n",
    "                    # ä¿®æ­£æ—¶é—´èŒƒå›´æ£€æŸ¥ï¼Œæ”¾å®½åŠ é€Ÿåº¦é™åˆ¶\n",
    "                    if 0.01 < dt < 300:  # 10ms åˆ° 5åˆ†é’Ÿ\n",
    "                        acc = speed_change / dt\n",
    "                        acc = max(-15, min(15, acc))  # æ”¾å®½åŠ é€Ÿåº¦èŒƒå›´åˆ°Â±15 m/sÂ²\n",
    "                        accelerations.append(acc)\n",
    "                    else:\n",
    "                        # å¯¹äºå¼‚å¸¸æ—¶é—´é—´éš”ï¼Œä½¿ç”¨å‰ä¸€ä¸ªåŠ é€Ÿåº¦çš„è¡°å‡å€¼\n",
    "                        if i > 1:\n",
    "                            accelerations.append(accelerations[-1] * 0.8)\n",
    "                        else:\n",
    "                            accelerations.append(0.0)\n",
    "            \n",
    "            gps_df[\"acceleration\"] = accelerations\n",
    "            \n",
    "            # æ£€æŸ¥GPSåŠ é€Ÿåº¦è®¡ç®—ç»“æœ\n",
    "            acc_nonzero = (np.array(accelerations) != 0).sum()\n",
    "            acc_range = [min(accelerations), max(accelerations)]\n",
    "            \n",
    "            print(f\"GPSåŠ é€Ÿåº¦è®¡ç®—ç»“æœ:\")\n",
    "            print(f\"  éé›¶å€¼: {acc_nonzero}/{len(accelerations)} ({acc_nonzero/len(accelerations)*100:.1f}%)\")\n",
    "            print(f\"  èŒƒå›´: {acc_range[0]:.3f} - {acc_range[1]:.3f} m/sÂ²\")\n",
    "            print(f\"  å¹³å‡: {np.mean(accelerations):.3f} m/sÂ²\")\n",
    "            print(f\"  æ ‡å‡†å·®: {np.std(accelerations):.3f} m/sÂ²\")\n",
    "            \n",
    "            # å¦‚æœGPSåŠ é€Ÿåº¦ä»ç„¶é—®é¢˜å¾ˆå¤§ï¼Œä½¿ç”¨æ”¹è¿›çš„åˆæˆæ–¹æ³•\n",
    "            if abs(max(accelerations)) < 0.01 or acc_nonzero < len(accelerations) * 0.1:\n",
    "                print(\"âš ï¸  GPSåŠ é€Ÿåº¦è®¡ç®—å¼‚å¸¸ï¼Œä½¿ç”¨æ”¹è¿›çš„åˆæˆæ–¹æ³•...\")\n",
    "                \n",
    "                # ä½¿ç”¨é€Ÿåº¦çš„å˜åŒ–è¶‹åŠ¿ç”Ÿæˆæ›´çœŸå®çš„åŠ é€Ÿåº¦\n",
    "                speed_smooth = gps_df['speed_ms'].rolling(window=3, center=True).mean().fillna(gps_df['speed_ms'])\n",
    "                speed_diff = speed_smooth.diff()\n",
    "                time_diff = gps_df['relative_time_s'].diff()\n",
    "                \n",
    "                synthetic_acc = []\n",
    "                for i in range(len(gps_df)):\n",
    "                    if i == 0:\n",
    "                        synthetic_acc.append(0.0)\n",
    "                    else:\n",
    "                        dt = time_diff.iloc[i]\n",
    "                        if dt > 0:\n",
    "                            acc = speed_diff.iloc[i] / dt\n",
    "                            acc = max(-12, min(12, acc))  # åˆæˆåŠ é€Ÿåº¦é™åˆ¶ç¨å¾®ä¸¥æ ¼ä¸€äº›\n",
    "                            synthetic_acc.append(acc)\n",
    "                        else:\n",
    "                            synthetic_acc.append(0.0)\n",
    "                \n",
    "                gps_df['acceleration'] = synthetic_acc\n",
    "                print(f\"  åˆæˆåŠ é€Ÿåº¦èŒƒå›´: {min(synthetic_acc):.3f} - {max(synthetic_acc):.3f} m/sÂ²\")\n",
    "            \n",
    "            self.features['route'] = gps_df\n",
    "        \n",
    "        # åŠ é€Ÿåº¦ä¼ æ„Ÿå™¨ç‰¹å¾ - ä¿®æ­£æ—¶é—´å¤„ç†å’ŒJerkè®¡ç®—\n",
    "        if 'acc' in self.raw_data and not self.raw_data['acc'].empty:\n",
    "            acc_df = self.raw_data['acc'].copy().sort_values('full_timestamp').reset_index(drop=True)\n",
    "            \n",
    "            print(f\"\\n=== åŠ é€Ÿåº¦ä¼ æ„Ÿå™¨ç‰¹å¾æå– ===\")\n",
    "            \n",
    "            # é‡æ–°è®¡ç®—magnitudeï¼Œç¡®ä¿å•ä½æ­£ç¡®\n",
    "            print(f\"åŸå§‹åŠ é€Ÿåº¦æ•°æ®ç»Ÿè®¡:\")\n",
    "            print(f\"  X: {acc_df['x'].min():.3f} - {acc_df['x'].max():.3f}\")\n",
    "            print(f\"  Y: {acc_df['y'].min():.3f} - {acc_df['y'].max():.3f}\")\n",
    "            print(f\"  Z: {acc_df['z'].min():.3f} - {acc_df['z'].max():.3f}\")\n",
    "            \n",
    "            # é‡æ–°è®¡ç®—magnitude\n",
    "            acc_df[\"magnitude\"] = np.sqrt(acc_df[\"x\"]**2 + acc_df[\"y\"]**2 + acc_df[\"z\"]**2)\n",
    "            \n",
    "            # è®¡ç®—Jerkï¼ˆæ€¥åŠ¨åº¦ï¼‰- ä¿®æ­£ç‰ˆæœ¬\n",
    "            dt_acc = acc_df[\"full_timestamp\"].diff() / 1000000.0  # è½¬æ¢ä¸ºç§’\n",
    "            magnitude_changes = acc_df[\"magnitude\"].diff()\n",
    "\n",
    "            # è°ƒè¯•ï¼šæ£€æŸ¥magnitudeå˜åŒ–\n",
    "            print(f\"Magnitudeç»Ÿè®¡: {acc_df['magnitude'].min():.3f} - {acc_df['magnitude'].max():.3f}\")\n",
    "            print(f\"Magnitudeå˜åŒ–ç»Ÿè®¡: {magnitude_changes.min():.6f} - {magnitude_changes.max():.6f}\")\n",
    "            print(f\"æ—¶é—´é—´éš”ç»Ÿè®¡: {dt_acc.min():.6f} - {dt_acc.max():.6f} ç§’\")\n",
    "            \n",
    "            # åˆå§‹åŒ–jerksåˆ—è¡¨\n",
    "            jerks = []\n",
    "            \n",
    "            for i in range(len(acc_df)):\n",
    "                if i == 0:\n",
    "                    jerks.append(0.0)\n",
    "                else:\n",
    "                    dt = dt_acc.iloc[i]\n",
    "                    mag_change = magnitude_changes.iloc[i]\n",
    "                    \n",
    "                    # ä¿®æ­£æ—¶é—´èŒƒå›´ - åŠ é€Ÿåº¦è®¡é‡‡æ ·é¢‘ç‡æ›´é«˜\n",
    "                    if 0.0001 < dt < 1.0:  # 0.1ms åˆ° 1ç§’ï¼Œæ”¾å®½æ—¶é—´èŒƒå›´\n",
    "                        jerk = mag_change / dt\n",
    "                        # æ”¾å®½jerkèŒƒå›´ï¼Œå…è®¸æ›´å¤§çš„ç¬æ—¶å˜åŒ–\n",
    "                        jerk = max(-500, min(500, jerk))  # æ‰©å¤§jerkèŒƒå›´åˆ°Â±500\n",
    "                        jerks.append(jerk)\n",
    "                    else:\n",
    "                        # å¯¹äºå¼‚å¸¸æ—¶é—´é—´éš”ï¼Œä½¿ç”¨0è€Œä¸æ˜¯è·³è¿‡\n",
    "                        jerks.append(0.0)\n",
    "            \n",
    "            acc_df[\"jerk\"] = jerks\n",
    "            \n",
    "            # æ”¹è¿›çš„å¹³æ»‘å¤„ç† - ä½¿ç”¨æ›´ä¿å®ˆçš„å¹³æ»‘\n",
    "            if len(acc_df) > 5:\n",
    "                # ä½¿ç”¨æ›´å°çš„çª—å£ä¿æŒç¬æ—¶ç‰¹æ€§\n",
    "                win = min(5, len(acc_df)//10*2+1)  # å‡å°‘çª—å£å¤§å°\n",
    "                if win >= 3:\n",
    "                    try:\n",
    "                        acc_df[\"jerk_smooth\"] = savgol_filter(acc_df[\"jerk\"], win, 1)\n",
    "                    except:\n",
    "                        # å¦‚æœå¹³æ»‘å¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„æ»‘åŠ¨å¹³å‡\n",
    "                        acc_df[\"jerk_smooth\"] = acc_df[\"jerk\"].rolling(window=3, center=True).mean().fillna(acc_df[\"jerk\"])\n",
    "                else:\n",
    "                    acc_df[\"jerk_smooth\"] = acc_df[\"jerk\"]\n",
    "            else:\n",
    "                acc_df[\"jerk_smooth\"] = acc_df[\"jerk\"]\n",
    "            \n",
    "            # å»é™¤æç«¯å¼‚å¸¸å€¼\n",
    "            jerk_p99 = np.percentile(np.abs(acc_df[\"jerk_smooth\"]), 99)\n",
    "            acc_df[\"jerk_smooth\"] = np.clip(acc_df[\"jerk_smooth\"], -jerk_p99, jerk_p99)\n",
    "            \n",
    "            print(f\"Jerkè®¡ç®—ç»“æœ:\")\n",
    "            print(f\"  åŸå§‹èŒƒå›´: {min(jerks):.3f} - {max(jerks):.3f} m/sÂ³\")\n",
    "            print(f\"  å¹³æ»‘åèŒƒå›´: {acc_df['jerk_smooth'].min():.3f} - {acc_df['jerk_smooth'].max():.3f} m/sÂ³\")\n",
    "            print(f\"  éé›¶å€¼: {(np.array(jerks) != 0).sum()}/{len(jerks)}\")\n",
    "            print(f\"  99%åˆ†ä½æ•°: Â±{jerk_p99:.3f} m/sÂ³\")\n",
    "            \n",
    "            self.features['behavior'] = acc_df\n",
    "        \n",
    "        # é™€èºä»ªè½¬å‘ç‰¹å¾ - ä¿®æ­£è®¡ç®—\n",
    "        if 'gyro' in self.raw_data and not self.raw_data['gyro'].empty:\n",
    "            gyro_df = self.raw_data['gyro'].copy()\n",
    "            \n",
    "            print(f\"\\n=== é™€èºä»ªç‰¹å¾æå– ===\")\n",
    "            print(f\"é™€èºä»ªåŸå§‹æ•°æ®:\")\n",
    "            print(f\"  X: {gyro_df['x'].min():.3f} - {gyro_df['x'].max():.3f}\")\n",
    "            print(f\"  Y: {gyro_df['y'].min():.3f} - {gyro_df['y'].max():.3f}\")\n",
    "            print(f\"  Z: {gyro_df['z'].min():.3f} - {gyro_df['z'].max():.3f}\")\n",
    "            \n",
    "            # é‡æ–°è®¡ç®—è½¬å‘ç‡ - ä½¿ç”¨æ‰€æœ‰è½´çš„ä¿¡æ¯\n",
    "            gyro_df[\"turning_rate\"] = np.sqrt(gyro_df[\"x\"]**2 + gyro_df[\"y\"]**2 + gyro_df[\"z\"]**2)\n",
    "            \n",
    "            print(f\"è½¬å‘ç‡ç»Ÿè®¡: {gyro_df['turning_rate'].min():.3f} - {gyro_df['turning_rate'].max():.3f}\")\n",
    "            \n",
    "            self.features['turning'] = gyro_df\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def detect_hard_brake_events(self):\n",
    "        \"\"\"æ£€æµ‹æ€¥åˆ¹è½¦äº‹ä»¶ - ä¿®æ­£ç‰ˆ\"\"\"\n",
    "        logger.info(\"Detecting hard brake events with improved algorithm\")\n",
    "        \n",
    "        if 'route' not in self.features:\n",
    "            logger.warning(\"No route data available for hard brake detection\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        df = self.features['route'].copy()\n",
    "        \n",
    "        # æ•°æ®å¹³æ»‘\n",
    "        if len(df) > 5:\n",
    "            window_size = min(5, len(df) // 2 * 2 + 1)\n",
    "            df['speed_smooth'] = savgol_filter(df['speed_kmh'], window_size, 2)\n",
    "        else:\n",
    "            df['speed_smooth'] = df['speed_kmh']\n",
    "        \n",
    "        # é€Ÿåº¦å˜åŒ–åˆ†æ - ä½¿ç”¨ç›¸å¯¹æ—¶é—´\n",
    "        df['speed_change'] = df['speed_smooth'].diff()\n",
    "        time_diff_s = df['relative_time_s'].diff()\n",
    "        df['speed_change_rate'] = df['speed_change'] / time_diff_s\n",
    "        df['speed_change_pct'] = df['speed_change'] / (df['speed_smooth'].shift(1) + 1)\n",
    "        \n",
    "        # é’ˆå¯¹ä½é€Ÿåœºæ™¯è°ƒæ•´çš„æ€¥åˆ¹è½¦æ£€æµ‹æ¡ä»¶\n",
    "        conditions = [\n",
    "            # æ¡ä»¶1: é€‚åº”ä½é€Ÿçš„ç»å¯¹é€Ÿåº¦ä¸‹é™\n",
    "            (df['speed_change'] < -5) & (df['speed_smooth'] > 10),  # é™ä½é€Ÿåº¦é˜ˆå€¼\n",
    "            \n",
    "            # æ¡ä»¶2: ç›¸å¯¹é€Ÿåº¦å˜åŒ–\n",
    "            (df['speed_change_pct'] < -0.20) & (df['speed_smooth'] > 8),  # æé«˜ç›¸å¯¹å˜åŒ–æ•æ„Ÿåº¦\n",
    "            \n",
    "            # æ¡ä»¶3: é€Ÿåº¦å˜åŒ–ç‡ï¼ˆé’ˆå¯¹èµ·æ­¥é˜¶æ®µï¼‰\n",
    "            (df['speed_change_rate'] < -8) & (df['speed_smooth'] > 5),  # é™ä½é€Ÿåº¦é˜ˆå€¼\n",
    "        ]\n",
    "        \n",
    "        df['hard_brake_candidate'] = np.logical_or.reduce(conditions)\n",
    "        \n",
    "        # é€Ÿåº¦å³°å€¼æ£€æµ‹ - é’ˆå¯¹ä½é€Ÿä¼˜åŒ–\n",
    "        df['is_speed_peak'] = False\n",
    "        df['hard_brake_refined'] = False\n",
    "        \n",
    "        # å¯»æ‰¾å±€éƒ¨é€Ÿåº¦å³°å€¼ï¼ˆé™ä½é˜ˆå€¼é€‚åº”ä½é€Ÿï¼‰\n",
    "        for i in range(2, len(df) - 2):\n",
    "            current_speed = df['speed_smooth'].iloc[i]\n",
    "            prev_speed = df['speed_smooth'].iloc[i-1]\n",
    "            next_speed = df['speed_smooth'].iloc[i+1]\n",
    "            \n",
    "            if (current_speed > prev_speed and current_speed > next_speed and current_speed > 8):  # é™ä½å³°å€¼é˜ˆå€¼\n",
    "                df.loc[i, 'is_speed_peak'] = True\n",
    "        \n",
    "        # åœ¨å³°å€¼åæ£€æµ‹æ€¥åˆ¹è½¦\n",
    "        for i in range(len(df)):\n",
    "            if df['is_speed_peak'].iloc[i]:\n",
    "                peak_speed = df['speed_smooth'].iloc[i]\n",
    "                \n",
    "                for j in range(i+1, min(i+6, len(df))):\n",
    "                    current_speed = df['speed_smooth'].iloc[j]\n",
    "                    speed_drop = peak_speed - current_speed\n",
    "                    time_span = df['relative_time_s'].iloc[j] - df['relative_time_s'].iloc[i]\n",
    "                    \n",
    "                    # é’ˆå¯¹ä½é€Ÿè°ƒæ•´çš„æ€¥åˆ¹è½¦æ¡ä»¶\n",
    "                    if speed_drop > 8 and time_span < 5:  # é™ä½é€Ÿåº¦ä¸‹é™é˜ˆå€¼\n",
    "                        df.loc[j, 'hard_brake_refined'] = True\n",
    "                        break\n",
    "        \n",
    "        # æœ€ç»ˆæ€¥åˆ¹è½¦äº‹ä»¶\n",
    "        df['hard_brake_final'] = df['hard_brake_candidate'] | df['hard_brake_refined']\n",
    "        \n",
    "        # å»é‡å¤„ç†\n",
    "        df['hard_brake_filtered'] = False\n",
    "        if df['hard_brake_final'].any():\n",
    "            brake_indices = df[df['hard_brake_final']].index\n",
    "            filtered_indices = [brake_indices[0]] if len(brake_indices) > 0 else []\n",
    "            \n",
    "            for i in range(1, len(brake_indices)):\n",
    "                time_gap = df['relative_time_s'].iloc[brake_indices[i]] - df['relative_time_s'].iloc[brake_indices[i-1]]\n",
    "                if time_gap > 2.0:  # 2ç§’é—´éš”\n",
    "                    filtered_indices.append(brake_indices[i])\n",
    "            \n",
    "            if filtered_indices:\n",
    "                df.loc[filtered_indices, 'hard_brake_filtered'] = True\n",
    "        \n",
    "        hard_brake_events = df[df['hard_brake_filtered']]\n",
    "        \n",
    "        print(f\"\\n=== æ€¥åˆ¹è½¦æ£€æµ‹ç»“æœ ===\")\n",
    "        print(f\"å€™é€‰äº‹ä»¶: {df['hard_brake_candidate'].sum()}\")\n",
    "        print(f\"ç²¾ç‚¼äº‹ä»¶: {df['hard_brake_refined'].sum()}\")\n",
    "        print(f\"æœ€ç»ˆæ£€æµ‹åˆ°: {len(hard_brake_events)} ä¸ªæ€¥åˆ¹è½¦äº‹ä»¶\")\n",
    "        \n",
    "        if not hard_brake_events.empty:\n",
    "            print(\"æ€¥åˆ¹è½¦äº‹ä»¶è¯¦æƒ…:\")\n",
    "            for i, (idx, event) in enumerate(hard_brake_events.iterrows()):\n",
    "                time_min = event['relative_time_s'] / 60\n",
    "                print(f\"  äº‹ä»¶{i+1}: {time_min:.1f}åˆ†é’Ÿ - é€Ÿåº¦: {event['speed_kmh']:.1f} km/h, åŠ é€Ÿåº¦: {event['acceleration']:.2f} m/sÂ²\")\n",
    "        \n",
    "        # æ›´æ–°è·¯çº¿æ•°æ®\n",
    "        self.features['route'] = df\n",
    "        \n",
    "        return hard_brake_events\n",
    "    \n",
    "    def synchronize_and_model_energy(self):\n",
    "        \"\"\"æ•°æ®åŒæ­¥å’Œèƒ½è€—å»ºæ¨¡ - å¾®ç§’ç²¾åº¦ç‰ˆæœ¬\"\"\"\n",
    "        logger.info(\"Synchronizing data and modeling energy consumption (microsecond precision)\")\n",
    "        \n",
    "        if 'route' not in self.features or 'behavior' not in self.features:\n",
    "            logger.warning(\"Missing required data for energy modeling\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        route_df = self.features['route']\n",
    "        behavior_df = self.features['behavior']\n",
    "        \n",
    "        # ä½¿ç”¨å¾®ç§’æ—¶é—´æˆ³è¿›è¡ŒåŒæ­¥\n",
    "        route_times = route_df['timestamp'].values\n",
    "        behavior_times = behavior_df['full_timestamp'].values\n",
    "        \n",
    "        print(f\"\\n=== æ•°æ®åŒæ­¥ (å¾®ç§’ç²¾åº¦) ===\")\n",
    "        print(f\"GPSæ•°æ®ç‚¹: {len(route_df)}\")\n",
    "        print(f\"åŠ é€Ÿåº¦æ•°æ®ç‚¹: {len(behavior_df)}\")\n",
    "        \n",
    "        combined_data = []\n",
    "        sync_errors = 0\n",
    "        perfect_matches = 0\n",
    "        \n",
    "        for i, row in route_df.iterrows():\n",
    "            gps_time = row['timestamp']\n",
    "            time_diffs = np.abs(behavior_times - gps_time)\n",
    "            closest_acc_idx = np.argmin(time_diffs)\n",
    "            min_time_diff = time_diffs[closest_acc_idx]\n",
    "            \n",
    "            if min_time_diff == 0:\n",
    "                perfect_matches += 1\n",
    "            elif min_time_diff > MAX_TIME_DIFF:\n",
    "                sync_errors += 1\n",
    "                continue\n",
    "            \n",
    "            entry = {\n",
    "                'timestamp': gps_time,\n",
    "                'relative_time_s': row['relative_time_s'],\n",
    "                'speed': row['speed_ms'],\n",
    "                'speed_kmh': row['speed_kmh'],\n",
    "                'acceleration': row['acceleration'],\n",
    "                'gradient': row['gradient'],\n",
    "                'jerk': behavior_df['jerk_smooth'].iloc[closest_acc_idx],\n",
    "                'sync_error_us': min_time_diff  # å¾®ç§’\n",
    "            }\n",
    "            \n",
    "            # æ·»åŠ è½¬å‘æ•°æ®\n",
    "            if 'turning' in self.features:\n",
    "                turning_times = self.features['turning']['full_timestamp'].values\n",
    "                closest_turn_idx = np.argmin(np.abs(turning_times - gps_time))\n",
    "                turn_time_diff = np.abs(turning_times[closest_turn_idx] - gps_time)\n",
    "                \n",
    "                if turn_time_diff <= MAX_TIME_DIFF:\n",
    "                    entry['turning_rate'] = self.features['turning']['turning_rate'].iloc[closest_turn_idx]\n",
    "                else:\n",
    "                    entry['turning_rate'] = 0\n",
    "            else:\n",
    "                entry['turning_rate'] = 0\n",
    "            \n",
    "            combined_data.append(entry)\n",
    "        \n",
    "        if not combined_data:\n",
    "            logger.warning(\"No synchronized data points found\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        combined_df = pd.DataFrame(combined_data)\n",
    "        \n",
    "        # èƒ½è€—è®¡ç®—\n",
    "        combined_df['energy_factor'] = self._calculate_energy_consumption(combined_df)\n",
    "        \n",
    "        print(f\"åŒæ­¥ç»“æœ:\")\n",
    "        print(f\"  å®Œç¾åŒ¹é…: {perfect_matches}\")\n",
    "        print(f\"  æˆåŠŸåŒæ­¥: {len(combined_data)}\")\n",
    "        print(f\"  åŒæ­¥é”™è¯¯: {sync_errors}\")\n",
    "        print(f\"  å¹³å‡åŒæ­¥è¯¯å·®: {combined_df['sync_error_us'].mean():.0f} å¾®ç§’\")\n",
    "        \n",
    "        self.processed_data = combined_df\n",
    "        return combined_df\n",
    "    \n",
    "    def _calculate_energy_consumption_fixed(self, df):\n",
    "        \"\"\"è®¡ç®—èƒ½è€— - ä¿®æ­£ç‰ˆï¼Œè°ƒæ•´å‚æ•°ä½¿ç»“æœæ›´åˆç†\"\"\"\n",
    "        config = self.config['energy_model']\n",
    "        mass = config['vehicle_mass']\n",
    "        g = GRAVITY\n",
    "        rho = 1.225  # ç©ºæ°”å¯†åº¦\n",
    "        Cd = config['drag_coefficient']\n",
    "        A = config['frontal_area']\n",
    "        Cr = config['rolling_resistance']\n",
    "        \n",
    "        power_W = np.zeros(len(df))\n",
    "        \n",
    "        for i in range(len(df)):\n",
    "            v = max(0.1, df['speed'].iloc[i])\n",
    "            Î¸ = np.arctan(df['gradient'].iloc[i]) if abs(df['gradient'].iloc[i]) < 1 else 0\n",
    "            \n",
    "            F_roll = Cr * mass * g * np.cos(Î¸)\n",
    "            F_aero = 0.5 * rho * Cd * A * v**2\n",
    "            F_grad = mass * g * np.sin(Î¸)\n",
    "            F_acc = mass * df['acceleration'].iloc[i]\n",
    "            \n",
    "            F_total = F_roll + F_aero + F_grad + F_acc\n",
    "            F_traction = max(F_total, 0)\n",
    "            \n",
    "            # æ·»åŠ ç”µæœºæ•ˆç‡å› å­ï¼Œä½¿èƒ½è€—æ›´åˆç†\n",
    "            motor_efficiency = 0.85  # ç”µæœºæ•ˆç‡85%\n",
    "            power_W[i] = F_traction * v / motor_efficiency\n",
    "        \n",
    "        # è®¡ç®—èƒ½è€— - ä½¿ç”¨ç›¸å¯¹æ—¶é—´ï¼Œæ·»åŠ åˆç†æ€§æ£€æŸ¥\n",
    "        if len(df) > 1:\n",
    "            dt = df['relative_time_s'].diff().fillna(1.0)\n",
    "            dt = np.clip(dt, 0.01, 10.0)  # é™åˆ¶æ—¶é—´é—´éš”\n",
    "        else:\n",
    "            dt = np.array([1.0])\n",
    "        \n",
    "        energy_J = power_W * dt.values\n",
    "        \n",
    "        # é™åˆ¶å•ä¸ªæ•°æ®ç‚¹çš„èƒ½è€—ï¼Œé¿å…å¼‚å¸¸å€¼\n",
    "        energy_J = np.clip(energy_J, 0, 50000)  # é™åˆ¶å•ç‚¹æœ€å¤§èƒ½è€—50kJ\n",
    "        \n",
    "        df['energy_J'] = energy_J\n",
    "        \n",
    "        return power_W\n",
    "    \n",
    "    def cluster_driving_behaviors(self):\n",
    "        \"\"\"é©¾é©¶è¡Œä¸ºèšç±» - æ”¹è¿›ç‰ˆ\"\"\"\n",
    "        logger.info(\"Clustering driving behaviors with improved classification\")\n",
    "        \n",
    "        if self.processed_data is None or self.processed_data.empty:\n",
    "            logger.error(\"No processed data available for clustering\")\n",
    "            return {}, pd.DataFrame(), np.array([])\n",
    "        \n",
    "        data = self.processed_data.copy()\n",
    "        \n",
    "        # ç¡®ä¿æ‰€éœ€åˆ—å­˜åœ¨\n",
    "        required_cols = self.config['clustering']['features'] + ['energy_J']\n",
    "        for col in required_cols:\n",
    "            if col not in data.columns:\n",
    "                data[col] = 0.0\n",
    "        \n",
    "        print(f\"\\n=== é©¾é©¶è¡Œä¸ºèšç±» ===\")\n",
    "        for col in self.config['clustering']['features']:\n",
    "            if col in data.columns:\n",
    "                print(f\"{col}: {data[col].min():.3f} - {data[col].max():.3f} (å‡å€¼: {data[col].mean():.3f})\")\n",
    "        \n",
    "        # K-Meansèšç±»\n",
    "        feats = self.config['clustering']['features']\n",
    "        X = data[feats].fillna(0)\n",
    "        \n",
    "        # æ•°æ®æ ‡å‡†åŒ–\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        # PCAé™ç»´\n",
    "        try:\n",
    "            pca = PCA(n_components=2)\n",
    "            X_pca = pca.fit_transform(X_scaled)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"PCA failed: {e}\")\n",
    "            X_pca = X_scaled[:, :2] if X_scaled.shape[1] >= 2 else np.column_stack([X_scaled[:, 0], X_scaled[:, 0]])\n",
    "        \n",
    "        n_clusters = min(self.config['clustering']['n_clusters'], max(1, len(X) - 1))\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        clusters = kmeans.fit_predict(X_scaled)\n",
    "        \n",
    "        data['driver_cluster'] = clusters\n",
    "        \n",
    "        # ç”Ÿæˆèšç±»é…ç½®æ–‡ä»¶\n",
    "        cluster_profiles = {}\n",
    "        for cid in range(n_clusters):\n",
    "            data_c = data[data['driver_cluster'] == cid]\n",
    "            if data_c.empty:\n",
    "                cluster_profiles[cid] = {'size': 0, 'driver_type': 'unknown'}\n",
    "                continue\n",
    "            \n",
    "            # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡\n",
    "            if len(data_c) > 1:\n",
    "                dt = data_c['relative_time_s'].diff().fillna(1.0)\n",
    "                dt = np.clip(dt, 0.01, 10.0)\n",
    "                total_time = dt.sum()\n",
    "                total_distance = (data_c['speed'] * dt).sum() / 1000.0  # km\n",
    "            else:\n",
    "                total_time = 1.0\n",
    "                total_distance = 0.001\n",
    "            \n",
    "            total_energy = data_c['energy_J'].sum() / 3600000.0  # kWh (J->kWh)\n",
    "            energy_eff = total_energy / max(total_distance, 0.001) * 100  # kWh/100km\n",
    "            \n",
    "            profile = {\n",
    "                'size': len(data_c),\n",
    "                'avg_speed': data_c['speed'].mean(),\n",
    "                'std_speed': data_c['speed'].std(),\n",
    "                'avg_acceleration': data_c['acceleration'].mean(),\n",
    "                'std_acceleration': data_c['acceleration'].std(),\n",
    "                'avg_jerk': data_c['jerk'].mean(),\n",
    "                'std_jerk': data_c['jerk'].std(),\n",
    "                'avg_turning_rate': data_c['turning_rate'].mean(),\n",
    "                'std_turning_rate': data_c['turning_rate'].std(),\n",
    "                'energy_efficiency': energy_eff,\n",
    "                'total_time_s': total_time,\n",
    "                'total_distance_km': total_distance,\n",
    "            }\n",
    "            \n",
    "            # æ”¹è¿›çš„é©¾é©¶ç±»å‹åˆ†ç±» - é€‚åº”èµ·æ­¥é˜¶æ®µ\n",
    "            abs_avg_jerk = abs(profile['avg_jerk'])\n",
    "            abs_avg_acc = abs(profile['avg_acceleration'])\n",
    "            avg_speed = profile['avg_speed']\n",
    "            avg_turning = profile['avg_turning_rate']\n",
    "            \n",
    "            # é’ˆå¯¹èµ·æ­¥é˜¶æ®µçš„åˆ†ç±»é€»è¾‘\n",
    "            if abs_avg_jerk > 15.0 and abs_avg_acc > 2.0:\n",
    "                profile['driver_type'] = 'aggressive'\n",
    "            elif avg_turning > 0.15:\n",
    "                profile['driver_type'] = 'cornering'\n",
    "            elif avg_speed > 8.0 and abs_avg_acc > 1.0:  # è°ƒæ•´é€Ÿåº¦é˜ˆå€¼\n",
    "                profile['driver_type'] = 'dynamic'\n",
    "            elif avg_speed < 5.0 and abs_avg_jerk < 8.0:\n",
    "                profile['driver_type'] = 'cautious'\n",
    "            elif abs_avg_acc < 0.5 and abs_avg_jerk < 5.0:\n",
    "                profile['driver_type'] = 'efficient'\n",
    "            else:\n",
    "                profile['driver_type'] = 'normal'\n",
    "            \n",
    "            cluster_profiles[cid] = profile\n",
    "        \n",
    "        print(f\"èšç±»ç»“æœ:\")\n",
    "        for cid, profile in cluster_profiles.items():\n",
    "            print(f\"  Cluster {cid} ({profile['driver_type']}): {profile['size']} æ ·æœ¬\")\n",
    "            print(f\"    é€Ÿåº¦: {profile['avg_speed']*3.6:.1f} km/h, åŠ é€Ÿåº¦: {profile['avg_acceleration']:.2f} m/sÂ²\")\n",
    "            print(f\"    Jerk: {profile['avg_jerk']:.2f} m/sÂ³, èƒ½è€—: {profile['energy_efficiency']:.1f} kWh/100km\")\n",
    "        \n",
    "        # æ›´æ–°å¤„ç†åçš„æ•°æ®\n",
    "        self.processed_data = data\n",
    "        \n",
    "        # åœ¨ cluster_driving_behaviors() æ–¹æ³•çš„æœ€åï¼Œreturn è¯­å¥ä¹‹å‰æ·»åŠ ï¼š\n",
    "        print(f\"DEBUG: type of self.processed_data after clustering: {type(self.processed_data)}\")\n",
    "        print(f\"DEBUG: processed_data columns: {self.processed_data.columns.tolist() if isinstance(self.processed_data, pd.DataFrame) else 'Not DataFrame'}\")\n",
    "        \n",
    "        return cluster_profiles, X_pca, clusters\n",
    "    \n",
    "    def generate_comprehensive_report(self):\n",
    "        \"\"\"ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š\"\"\"\n",
    "        logger.info(\"Generating comprehensive analysis report\")\n",
    "        \n",
    "        if self.processed_data is None:\n",
    "            logger.error(\"No processed data available for report generation\")\n",
    "            return None\n",
    "        \n",
    "        # åŸºæœ¬ç»Ÿè®¡\n",
    "        data = self.processed_data\n",
    "        total_time = data['relative_time_s'].max()  # ä½¿ç”¨ç›¸å¯¹æ—¶é—´\n",
    "        total_distance = (data['speed'] * data['relative_time_s'].diff().fillna(1.0)).sum() / 1000.0  # km\n",
    "        avg_speed = data['speed'].mean() * 3.6  # km/h\n",
    "        max_speed = data['speed_kmh'].max()\n",
    "        \n",
    "        # æ€¥åˆ¹è½¦åˆ†æ\n",
    "        hard_brake_events = self.detect_hard_brake_events()\n",
    "        \n",
    "        # é©¾é©¶è¡Œä¸ºèšç±»\n",
    "        cluster_profiles, X_pca, clusters = self.cluster_driving_behaviors()\n",
    "\n",
    "        # ç¡®ä¿processed_dataè¢«æ­£ç¡®æ›´æ–°\n",
    "        if self.processed_data is not None:\n",
    "            data = self.processed_data  # ä½¿ç”¨æ›´æ–°åçš„æ•°æ®\n",
    "        else:\n",
    "            logger.error(\"processed_data is None after clustering\")\n",
    "            return None\n",
    "        \n",
    "        # ç”ŸæˆæŠ¥å‘Š\n",
    "        report = {\n",
    "            'metadata': {\n",
    "                'analysis_date': datetime.now().isoformat(),\n",
    "                'version': VERSION,\n",
    "                'data_points': len(data),\n",
    "                'duration_minutes': total_time / 60,\n",
    "                'total_distance_km': total_distance\n",
    "            },\n",
    "            'driving_summary': {\n",
    "                'max_speed_kmh': max_speed,\n",
    "                'avg_speed_kmh': avg_speed,\n",
    "                'total_hard_brakes': len(hard_brake_events),\n",
    "                'hard_brakes_per_hour': len(hard_brake_events) / max(total_time / 3600, 0.1)\n",
    "            },\n",
    "            'cluster_analysis': cluster_profiles,\n",
    "            'recommendations': self._generate_recommendations(cluster_profiles, hard_brake_events)\n",
    "        }\n",
    "        \n",
    "        self.results = {\n",
    "            'report': report,\n",
    "            'data': self.processed_data.copy(),\n",
    "            'hard_brake_events': hard_brake_events,\n",
    "            'cluster_profiles': cluster_profiles,\n",
    "            'pca_data': X_pca,\n",
    "            'clusters': clusters\n",
    "        }\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def _generate_recommendations(self, cluster_profiles, hard_brake_events):\n",
    "        \"\"\"ç”Ÿæˆé©¾é©¶å»ºè®®\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        # åŸºäºæ€¥åˆ¹è½¦çš„å»ºè®®\n",
    "        if len(hard_brake_events) > 3:  # é™ä½é˜ˆå€¼é€‚åº”èµ·æ­¥é˜¶æ®µ\n",
    "            recommendations.append({\n",
    "                'category': 'Safety',\n",
    "                'priority': 'High',\n",
    "                'message': 'Multiple hard braking events detected during startup phase. Consider smoother acceleration and anticipating traffic conditions.',\n",
    "                'impact': 'Reduces brake wear and improves passenger comfort'\n",
    "            })\n",
    "        elif len(hard_brake_events) == 0:\n",
    "            recommendations.append({\n",
    "                'category': 'Positive',\n",
    "                'priority': 'Low',\n",
    "                'message': 'Excellent! No hard braking events detected. Very smooth driving style.',\n",
    "                'impact': 'Optimal brake system preservation and passenger comfort'\n",
    "            })\n",
    "        \n",
    "        # åŸºäºèšç±»åˆ†æçš„å»ºè®®\n",
    "        for cid, profile in cluster_profiles.items():\n",
    "            if profile['driver_type'] == 'aggressive':\n",
    "                recommendations.append({\n",
    "                    'category': 'Efficiency',\n",
    "                    'priority': 'Medium',\n",
    "                    'message': f'Cluster {cid} shows aggressive driving patterns. Gentler acceleration can improve efficiency by 15-20%.',\n",
    "                    'impact': f'Current energy efficiency: {profile[\"energy_efficiency\"]:.1f} kWh/100km'\n",
    "                })\n",
    "            elif profile['driver_type'] == 'efficient':\n",
    "                recommendations.append({\n",
    "                    'category': 'Positive',\n",
    "                    'priority': 'Low',\n",
    "                    'message': f'Cluster {cid} demonstrates efficient driving behavior. Excellent energy management!',\n",
    "                    'impact': f'Outstanding energy efficiency: {profile[\"energy_efficiency\"]:.1f} kWh/100km'\n",
    "                })\n",
    "            elif profile['driver_type'] == 'cautious':\n",
    "                recommendations.append({\n",
    "                    'category': 'Performance',\n",
    "                    'priority': 'Low',\n",
    "                    'message': f'Cluster {cid} shows very cautious driving. Consider slightly more dynamic acceleration when safe.',\n",
    "                    'impact': 'May improve traffic flow while maintaining safety'\n",
    "                })\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def visualize_results(self, save_plots=True):\n",
    "        if not self.results:\n",
    "            logger.error(\"No results available for visualization\")\n",
    "            return\n",
    "        \n",
    "        # è°ƒè¯•ï¼šæ£€æŸ¥æ•°æ®ç±»å‹\n",
    "        print(f\"DEBUG: self.results keys: {list(self.results.keys())}\")\n",
    "        print(f\"DEBUG: type of self.results['data']: {type(self.results['data'])}\")\n",
    "        print(f\"DEBUG: type of self.processed_data: {type(self.processed_data)}\")\n",
    "        \n",
    "        # ç›´æ¥ä½¿ç”¨ processed_data\n",
    "        data = self.processed_data\n",
    "        if data is None or not isinstance(data, pd.DataFrame):\n",
    "            logger.error(f\"Invalid processed_data type: {type(data)}\")\n",
    "            return\n",
    "        \n",
    "        hard_brake_events = self.results['hard_brake_events']\n",
    "        cluster_profiles = self.results['cluster_profiles']\n",
    "        \n",
    "        # åˆ›å»ºç»¼åˆä»ªè¡¨æ¿\n",
    "        fig = plt.figure(figsize=(20, 16))\n",
    "        \n",
    "        # 1. é€Ÿåº¦æ—¶é—´æ›²çº¿ï¼ˆä½¿ç”¨ç›¸å¯¹æ—¶é—´ï¼‰\n",
    "        ax1 = plt.subplot(3, 3, 1)\n",
    "        time_minutes = data['relative_time_s'] / 60\n",
    "        \n",
    "        plt.plot(time_minutes, data['speed_kmh'], 'b-', alpha=0.7, linewidth=2, label='Speed (km/h)')\n",
    "        \n",
    "        if not hard_brake_events.empty:\n",
    "            brake_times = hard_brake_events['relative_time_s'] / 60\n",
    "            plt.scatter(brake_times, hard_brake_events['speed_kmh'], \n",
    "                       color='red', marker='X', s=100, zorder=5, \n",
    "                       label=f'Hard Brakes ({len(hard_brake_events)})')\n",
    "            \n",
    "            # æ·»åŠ æ€¥åˆ¹è½¦æ ‡æ³¨\n",
    "            for i, (idx, event) in enumerate(hard_brake_events.iterrows()):\n",
    "                plt.annotate(f'Brake {i+1}', \n",
    "                           xy=(event['relative_time_s']/60, event['speed_kmh']),\n",
    "                           xytext=(10, 20), textcoords='offset points',\n",
    "                           bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.8),\n",
    "                           arrowprops=dict(arrowstyle='->', color='red'))\n",
    "        \n",
    "        plt.title('Speed Profile with Hard Brake Events\\n(Startup Phase Analysis)')\n",
    "        plt.xlabel('Time (minutes)')\n",
    "        plt.ylabel('Speed (km/h)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. é©¾é©¶è¡Œä¸ºèšç±»PCAè§†å›¾\n",
    "        ax2 = plt.subplot(3, 3, 2)\n",
    "        scatter = plt.scatter(self.results['pca_data'][:, 0], self.results['pca_data'][:, 1], \n",
    "                             c=self.results['clusters'], cmap='viridis', alpha=0.7, s=30)\n",
    "        plt.title('Driver Behavior Clusters\\n(PCA Visualization)')\n",
    "        plt.xlabel('PCA Component 1')\n",
    "        plt.ylabel('PCA Component 2')\n",
    "        plt.colorbar(scatter, label='Cluster')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. åŠ é€Ÿåº¦åˆ†å¸ƒ\n",
    "        ax3 = plt.subplot(3, 3, 3)\n",
    "        colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown']\n",
    "        for cluster in range(len(cluster_profiles)):\n",
    "            cluster_data = data[data['driver_cluster'] == cluster]\n",
    "            if not cluster_data.empty and 'acceleration' in cluster_data.columns:\n",
    "                plt.hist(cluster_data['acceleration'], bins=15, alpha=0.6, \n",
    "                        label=f'Cluster {cluster}', density=True, \n",
    "                        color=colors[cluster % len(colors)])\n",
    "        plt.title('Acceleration Distribution by Cluster\\n(Startup Phase)')\n",
    "        plt.xlabel('Acceleration (m/sÂ²)')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Jerkåˆ†å¸ƒ\n",
    "        ax4 = plt.subplot(3, 3, 4)\n",
    "        for cluster in range(len(cluster_profiles)):\n",
    "            cluster_data = data[data['driver_cluster'] == cluster]\n",
    "            if not cluster_data.empty and 'jerk' in cluster_data.columns:\n",
    "                plt.hist(cluster_data['jerk'], bins=15, alpha=0.6, \n",
    "                        label=f'Cluster {cluster}', density=True,\n",
    "                        color=colors[cluster % len(colors)])\n",
    "        plt.title('Jerk Distribution by Cluster\\n(Instantaneous Values)')\n",
    "        plt.xlabel('Jerk (m/sÂ³)')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 5. é©¾é©¶ç±»å‹åˆ†å¸ƒ\n",
    "        ax5 = plt.subplot(3, 3, 5)\n",
    "        driver_types = [cluster_profiles[cid]['driver_type'] for cid in cluster_profiles.keys()]\n",
    "        type_counts = {}\n",
    "        for dtype in driver_types:\n",
    "            type_counts[dtype] = type_counts.get(dtype, 0) + 1\n",
    "        \n",
    "        colors_pie = {'aggressive': 'red', 'dynamic': 'orange', 'cornering': 'purple', \n",
    "                      'efficient': 'green', 'cautious': 'blue', 'normal': 'cyan', 'unknown': 'gray'}\n",
    "        pie_colors = [colors_pie.get(dtype, 'gray') for dtype in type_counts.keys()]\n",
    "        \n",
    "        plt.pie(type_counts.values(), labels=type_counts.keys(), colors=pie_colors,\n",
    "                autopct='%1.1f%%', startangle=90)\n",
    "        plt.title('Driver Type Distribution\\n(Startup Phase)')\n",
    "        \n",
    "        # 6. èƒ½è€—æ•ˆç‡å¯¹æ¯”\n",
    "        ax6 = plt.subplot(3, 3, 6)\n",
    "        cluster_ids = list(cluster_profiles.keys())\n",
    "        energy_effs = [cluster_profiles[cid]['energy_efficiency'] for cid in cluster_ids]\n",
    "        driver_types_list = [cluster_profiles[cid]['driver_type'] for cid in cluster_ids]\n",
    "        \n",
    "        bar_colors = [colors_pie.get(dtype, 'gray') for dtype in driver_types_list]\n",
    "        bars = plt.bar(range(len(cluster_ids)), energy_effs, color=bar_colors, alpha=0.8)\n",
    "        plt.title('Energy Efficiency by Cluster\\n(Startup Phase)')\n",
    "        plt.xlabel('Cluster')\n",
    "        plt.ylabel('Energy Efficiency (kWh/100km)')\n",
    "        plt.xticks(range(len(cluster_ids)), [f'C{cid}\\n({dtype})' for cid, dtype in zip(cluster_ids, driver_types_list)])\n",
    "        \n",
    "        for bar, eff in zip(bars, energy_effs):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(energy_effs)*0.01, \n",
    "                    f'{eff:.1f}', ha='center', va='bottom')\n",
    "        \n",
    "        # 7. é€Ÿåº¦vsåŠ é€Ÿåº¦æ•£ç‚¹å›¾\n",
    "        ax7 = plt.subplot(3, 3, 7)\n",
    "        scatter = plt.scatter(data['speed_kmh'], data['acceleration'], \n",
    "                             c=data['driver_cluster'], cmap='viridis', alpha=0.6, s=20)\n",
    "        plt.title('Speed vs Acceleration\\n(Startup Phase)')\n",
    "        plt.xlabel('Speed (km/h)')\n",
    "        plt.ylabel('Acceleration (m/sÂ²)')\n",
    "        plt.colorbar(scatter, label='Cluster')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 8. æ—¶é—´åºåˆ—åŠ é€Ÿåº¦\n",
    "        ax8 = plt.subplot(3, 3, 8)\n",
    "        sample_size = min(200, len(data))\n",
    "        sample_data = data.head(sample_size)\n",
    "        sample_times = sample_data['relative_time_s'] / 60\n",
    "        \n",
    "        plt.plot(sample_times, sample_data['acceleration'], 'g-', alpha=0.7, linewidth=1)\n",
    "        plt.title(f'Acceleration Time Series\\n(First {sample_size} points)')\n",
    "        plt.xlabel('Time (minutes)')\n",
    "        plt.ylabel('Acceleration (m/sÂ²)')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 9. ç»¼åˆè¯„åˆ†ä»ªè¡¨ç›˜\n",
    "        ax9 = plt.subplot(3, 3, 9)\n",
    "        \n",
    "        # è®¡ç®—è¯„åˆ† - é€‚åº”èµ·æ­¥é˜¶æ®µ\n",
    "        total_events = len(hard_brake_events)\n",
    "        total_time_hours = data['relative_time_s'].max() / 3600\n",
    "        events_per_hour = total_events / max(total_time_hours, 0.1)\n",
    "        \n",
    "        avg_energy_eff = np.mean([p['energy_efficiency'] for p in cluster_profiles.values()])\n",
    "        \n",
    "        # è¯„åˆ†è®¡ç®—ï¼ˆé’ˆå¯¹èµ·æ­¥é˜¶æ®µè°ƒæ•´ï¼‰\n",
    "        safety_score = max(0, 100 - events_per_hour * 15)  # èµ·æ­¥é˜¶æ®µé™ä½æƒ©ç½š\n",
    "        efficiency_score = max(0, 100 - max(0, avg_energy_eff - 25) * 2)  # èµ·æ­¥é˜¶æ®µèƒ½è€—å¯èƒ½è¾ƒé«˜\n",
    "        smoothness_score = 100 - min(50, np.mean([abs(p['avg_jerk']) for p in cluster_profiles.values()]) * 2)\n",
    "        overall_score = (safety_score + efficiency_score + smoothness_score) / 3\n",
    "        \n",
    "        # ç»˜åˆ¶ä»ªè¡¨ç›˜\n",
    "        scores = [safety_score, efficiency_score, smoothness_score, overall_score]\n",
    "        labels = ['Safety', 'Efficiency', 'Smoothness', 'Overall']\n",
    "        colors_gauge = ['red', 'green', 'blue', 'purple']\n",
    "        \n",
    "        bars = plt.bar(labels, scores, color=colors_gauge, alpha=0.7)\n",
    "        plt.ylim(0, 100)\n",
    "        plt.title('Eco-Driving Score Dashboard\\n(Startup Phase)')\n",
    "        plt.ylabel('Score (0-100)')\n",
    "        \n",
    "        for bar, score in zip(bars, scores):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2, \n",
    "                    f'{score:.0f}', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_plots:\n",
    "            plt.savefig('eco_driving_startup_analysis.png', dpi=300, bbox_inches='tight')\n",
    "            logger.info(\"Saved startup phase analysis plot\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def save_results(self, output_dir='eco_driving_results'):\n",
    "        \"\"\"ä¿å­˜åˆ†æç»“æœ\"\"\"\n",
    "        if not self.results:\n",
    "            logger.error(\"No results to save\")\n",
    "            return False\n",
    "        \n",
    "        # åˆ›å»ºè¾“å‡ºç›®å½•\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            # ä¿å­˜ä¸»è¦æ•°æ®\n",
    "            self.results['data'].to_csv(f'{output_dir}/processed_data.csv', index=False)\n",
    "            \n",
    "            if not self.results['hard_brake_events'].empty:\n",
    "                self.results['hard_brake_events'].to_csv(f'{output_dir}/hard_brake_events.csv', index=False)\n",
    "            \n",
    "            # ä¿å­˜JSONæŠ¥å‘Š\n",
    "            with open(f'{output_dir}/analysis_report.json', 'w', encoding='utf-8') as f:\n",
    "                json.dump(self.results['report'], f, indent=2, ensure_ascii=False, default=str)\n",
    "            \n",
    "            # ä¿å­˜æ–‡æœ¬æŠ¥å‘Š\n",
    "            self._save_text_report(f'{output_dir}/eco_driving_report.txt')\n",
    "            \n",
    "            logger.info(f\"Results saved to {output_dir}/\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving results: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def _save_text_report(self, filepath):\n",
    "        \"\"\"ä¿å­˜è¯¦ç»†æ–‡æœ¬æŠ¥å‘Š\"\"\"\n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            report = self.results['report']\n",
    "            cluster_profiles = self.results['cluster_profiles']\n",
    "            hard_brake_events = self.results['hard_brake_events']\n",
    "            \n",
    "            f.write(\"=\" * 80 + \"\\n\")\n",
    "            f.write(\"ECO-DRIVING ANALYSIS REPORT - STARTUP PHASE\\n\")\n",
    "            f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "            \n",
    "            # åŸºæœ¬ä¿¡æ¯\n",
    "            f.write(f\"Analysis Date: {report['metadata']['analysis_date']}\\n\")\n",
    "            f.write(f\"System Version: {report['metadata']['version']} (Microsecond Precision)\\n\")\n",
    "            f.write(f\"Data Points: {report['metadata']['data_points']}\\n\")\n",
    "            f.write(f\"Duration: {report['metadata']['duration_minutes']:.1f} minutes\\n\")\n",
    "            f.write(f\"Total Distance: {report['metadata']['total_distance_km']:.3f} km\\n\\n\")\n",
    "            \n",
    "            # é©¾é©¶æ‘˜è¦\n",
    "            f.write(\"DRIVING SUMMARY (STARTUP PHASE):\\n\")\n",
    "            f.write(\"-\" * 40 + \"\\n\")\n",
    "            f.write(f\"Maximum Speed: {report['driving_summary']['max_speed_kmh']:.1f} km/h\\n\")\n",
    "            f.write(f\"Average Speed: {report['driving_summary']['avg_speed_kmh']:.1f} km/h\\n\")\n",
    "            f.write(f\"Total Hard Brakes: {report['driving_summary']['total_hard_brakes']}\\n\")\n",
    "            f.write(f\"Hard Brakes per Hour: {report['driving_summary']['hard_brakes_per_hour']:.1f}\\n\\n\")\n",
    "            \n",
    "            # èšç±»åˆ†æ\n",
    "            f.write(\"DRIVER BEHAVIOR CLUSTERS (STARTUP PHASE):\\n\")\n",
    "            f.write(\"-\" * 40 + \"\\n\")\n",
    "            for cid, profile in cluster_profiles.items():\n",
    "                f.write(f\"\\nCluster {cid} - {profile['driver_type'].upper()}:\\n\")\n",
    "                f.write(f\"  Sample Size: {profile['size']} points\\n\")\n",
    "                f.write(f\"  Average Speed: {profile['avg_speed']*3.6:.1f} km/h\\n\")\n",
    "                f.write(f\"  Average Acceleration: {profile['avg_acceleration']:.3f} m/sÂ²\\n\")\n",
    "                f.write(f\"  Average Jerk: {profile['avg_jerk']:.3f} m/sÂ³ (instantaneous)\\n\")\n",
    "                f.write(f\"  Average Turning Rate: {profile['avg_turning_rate']:.3f} rad/s\\n\")\n",
    "                f.write(f\"  Energy Efficiency: {profile['energy_efficiency']:.2f} kWh/100km\\n\")\n",
    "                f.write(f\"  Total Distance: {profile['total_distance_km']:.4f} km\\n\")\n",
    "                f.write(f\"  Total Time: {profile['total_time_s']:.1f} seconds\\n\")\n",
    "            \n",
    "            # æ€¥åˆ¹è½¦è¯¦æƒ…\n",
    "            f.write(f\"\\nHARD BRAKE EVENTS DETAIL:\\n\")\n",
    "            f.write(\"-\" * 40 + \"\\n\")\n",
    "            if not hard_brake_events.empty:\n",
    "                for i, (idx, event) in enumerate(hard_brake_events.iterrows()):\n",
    "                    time_min = event['relative_time_s'] / 60\n",
    "                    f.write(f\"  Event {i+1}: {time_min:.1f} min - Speed: {event['speed_kmh']:.1f} km/h, \"\n",
    "                           f\"Acceleration: {event['acceleration']:.2f} m/sÂ²\\n\")\n",
    "            else:\n",
    "                f.write(\"  No hard brake events detected - Excellent smooth driving!\\n\")\n",
    "            \n",
    "            # å»ºè®®\n",
    "            f.write(f\"\\nRECOMMENDATIONS:\\n\")\n",
    "            f.write(\"-\" * 40 + \"\\n\")\n",
    "            for i, rec in enumerate(report['recommendations']):\n",
    "                f.write(f\"{i+1}. [{rec['category']} - {rec['priority']}] {rec['message']}\\n\")\n",
    "                f.write(f\"   Impact: {rec['impact']}\\n\\n\")\n",
    "            \n",
    "            # æŠ€æœ¯è¯´æ˜\n",
    "            f.write(\"TECHNICAL NOTES:\\n\")\n",
    "            f.write(\"-\" * 20 + \"\\n\")\n",
    "            f.write(\"â€¢ Timestamp precision: Microseconds\\n\")\n",
    "            f.write(\"â€¢ Analysis focus: Vehicle startup phase\\n\")\n",
    "            f.write(\"â€¢ Jerk calculation: Instantaneous values preserved\\n\")\n",
    "            f.write(\"â€¢ Acceleration: Real GPS-based calculation with synthetic backup\\n\")\n",
    "            f.write(\"â€¢ Energy model: Adapted for low-speed urban driving\\n\")\n",
    "\n",
    "# ä¸»è¦ä½¿ç”¨æ¥å£\n",
    "def run_complete_eco_driving_analysis(data_file, config=None):\n",
    "    \"\"\"\n",
    "    è¿è¡Œå®Œæ•´çš„ç”Ÿæ€é©¾é©¶åˆ†æ - å¾®ç§’æ—¶é—´æˆ³ç‰ˆæœ¬\n",
    "    \n",
    "    Args:\n",
    "        data_file: ä¼ æ„Ÿå™¨æ•°æ®æ–‡ä»¶è·¯å¾„\n",
    "        config: å¯é€‰é…ç½®å­—å…¸\n",
    "    \n",
    "    Returns:\n",
    "        EcoDrivingAnalyzerå®ä¾‹ï¼ŒåŒ…å«æ‰€æœ‰åˆ†æç»“æœ\n",
    "    \"\"\"\n",
    "    print(\"ğŸš— Starting Complete Eco-Driving Analysis System v2.1\")\n",
    "    print(\"ğŸ“ Optimized for startup phase analysis with microsecond precision\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # åˆå§‹åŒ–åˆ†æå™¨\n",
    "    analyzer = EcoDrivingAnalyzer(config)\n",
    "    \n",
    "    # 1. è§£ææ•°æ®\n",
    "    print(\"ğŸ“Š Step 1: Parsing sensor data (microsecond timestamps)...\")\n",
    "    if not analyzer.parse_sensor_data(data_file):\n",
    "        print(\"âŒ Failed to parse sensor data\")\n",
    "        return None\n",
    "    \n",
    "    # 2. æå–ç‰¹å¾\n",
    "    print(\"ğŸ” Step 2: Extracting driving features...\")\n",
    "    if not analyzer.extract_driving_features():\n",
    "        print(\"âŒ Failed to extract features\")\n",
    "        return None\n",
    "    \n",
    "    # 3. æ•°æ®åŒæ­¥å’Œèƒ½è€—å»ºæ¨¡\n",
    "    print(\"âš¡ Step 3: Synchronizing data and modeling energy...\")\n",
    "    combined_data = analyzer.synchronize_and_model_energy()\n",
    "    if combined_data.empty:\n",
    "        print(\"âŒ Failed to synchronize data\")\n",
    "        return None\n",
    "    \n",
    "    # 4. ç”Ÿæˆç»¼åˆæŠ¥å‘Š\n",
    "    print(\"ğŸ“‹ Step 4: Generating comprehensive report...\")\n",
    "    report = analyzer.generate_comprehensive_report()\n",
    "    if not report:\n",
    "        print(\"âŒ Failed to generate report\")\n",
    "        return None\n",
    "    \n",
    "    # 5. å¯è§†åŒ–ç»“æœ\n",
    "    print(\"ğŸ“ˆ Step 5: Creating visualizations...\")\n",
    "    analyzer.visualize_results()\n",
    "    \n",
    "    # 6. ä¿å­˜ç»“æœ\n",
    "    print(\"ğŸ’¾ Step 6: Saving results...\")\n",
    "    analyzer.save_results()\n",
    "    \n",
    "    print(\"\\nâœ… Analysis Complete!\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # æ‰“å°å…³é”®ç»“æœ\n",
    "    print(f\"ğŸ“Š Key Results (Startup Phase):\")\n",
    "    print(f\"  â€¢ Duration: {report['metadata']['duration_minutes']:.1f} minutes\")\n",
    "    print(f\"  â€¢ Max Speed: {report['driving_summary']['max_speed_kmh']:.1f} km/h\")\n",
    "    print(f\"  â€¢ Hard Brake Events: {len(analyzer.results['hard_brake_events'])}\")\n",
    "    print(f\"  â€¢ Driver Behavior Types: {len(set(p['driver_type'] for p in analyzer.results['cluster_profiles'].values()))}\")\n",
    "    print(f\"  â€¢ Average Energy Efficiency: {np.mean([p['energy_efficiency'] for p in analyzer.results['cluster_profiles'].values()]):.1f} kWh/100km\")\n",
    "    \n",
    "    return analyzer\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•ä»£ç \n",
    "if __name__ == \"__main__\":\n",
    "    # é’ˆå¯¹èµ·æ­¥é˜¶æ®µä¼˜åŒ–çš„é…ç½®\n",
    "    startup_config = {\n",
    "        'hard_brake_threshold': -2.0,  # é™ä½é˜ˆå€¼é€‚åº”èµ·æ­¥\n",
    "        'speed_drop_threshold': 6,     # é™ä½é€Ÿåº¦ä¸‹é™é˜ˆå€¼\n",
    "        'min_brake_speed': 8,          # é™ä½æœ€å°åˆ¹è½¦é€Ÿåº¦\n",
    "        'energy_model': {\n",
    "            'vehicle_mass': 1600,      # ç´§å‡‘å‹è½¿è½¦\n",
    "            'drag_coefficient': 0.26,  # ç°ä»£è½¿è½¦ä¼˜ç§€é£é˜»\n",
    "            'frontal_area': 2.2,       # ç´§å‡‘å‹è½¦è¿é£é¢ç§¯\n",
    "            'rolling_resistance': 0.010 # ä¼˜è´¨è½®èƒ\n",
    "        },\n",
    "        'clustering': {\n",
    "            'n_clusters': 3,\n",
    "            'features': ['speed', 'acceleration', 'jerk', 'turning_rate']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # è¿è¡Œåˆ†æ\n",
    "    data_file = \"ts_1747221572.csv\"  # ä½ çš„æ•°æ®æ–‡ä»¶\n",
    "    \n",
    "    print(\"ğŸš€ Running Eco-Driving Analysis - Startup Phase Optimized\")\n",
    "    print(f\"ğŸ“ Data file: {data_file}\")\n",
    "    print(\"ğŸ”§ Configuration: Optimized for startup phase with microsecond precision\")\n",
    "    print(\"â±ï¸  Expected analysis time: 30-60 seconds\")\n",
    "    print()\n",
    "    \n",
    "    # æ‰§è¡Œå®Œæ•´åˆ†æ\n",
    "    analyzer = run_complete_eco_driving_analysis(data_file, startup_config)\n",
    "    \n",
    "    if analyzer:\n",
    "        print(\"\\nğŸ‰ Analysis completed successfully!\")\n",
    "        print(\"ğŸ“ Check 'eco_driving_results' folder for detailed outputs:\")\n",
    "        print(\"   â€¢ processed_data.csv - Complete processed dataset\")\n",
    "        print(\"   â€¢ hard_brake_events.csv - Hard brake event details\") \n",
    "        print(\"   â€¢ analysis_report.json - Structured analysis results\")\n",
    "        print(\"   â€¢ eco_driving_report.txt - Human-readable report\")\n",
    "        print(\"   â€¢ eco_driving_startup_analysis.png - Comprehensive visualization\")\n",
    "        \n",
    "        # æ˜¾ç¤ºå¿«é€Ÿæ‘˜è¦\n",
    "        print(f\"\\nğŸ” Quick Analysis Summary:\")\n",
    "        report = analyzer.results['report']\n",
    "        print(f\"  â±ï¸  Duration: {report['metadata']['duration_minutes']:.1f} minutes\")\n",
    "        print(f\"  ğŸš— Max Speed: {report['driving_summary']['max_speed_kmh']:.1f} km/h\")\n",
    "        print(f\"  ğŸš¨ Hard Brakes: {report['driving_summary']['total_hard_brakes']}\")\n",
    "        \n",
    "        # æ˜¾ç¤ºé©¾é©¶ç±»å‹åˆ†å¸ƒ\n",
    "        cluster_types = [p['driver_type'] for p in analyzer.results['cluster_profiles'].values()]\n",
    "        type_counts = {}\n",
    "        for dtype in cluster_types:\n",
    "            type_counts[dtype] = type_counts.get(dtype, 0) + 1\n",
    "        \n",
    "        print(f\"  ğŸ¯ Driving Types Found: {', '.join(type_counts.keys())}\")\n",
    "        \n",
    "        # æ˜¾ç¤ºä¸»è¦å»ºè®®\n",
    "        print(f\"\\nğŸ’¡ Top Recommendations:\")\n",
    "        for i, rec in enumerate(report['recommendations'][:2]):\n",
    "            print(f\"  {i+1}. [{rec['priority']}] {rec['message'][:80]}...\")\n",
    "        \n",
    "        # æ•°æ®è´¨é‡æŠ¥å‘Š\n",
    "        data = analyzer.results['data']\n",
    "        print(f\"\\nğŸ“Š Data Quality Summary:\")\n",
    "        print(f\"  â€¢ Total Data Points: {len(data):,}\")\n",
    "        print(f\"  â€¢ GPS-Accelerometer Sync: {(data['sync_error_us'] < 100000).sum()}/{len(data)} points < 100ms\")\n",
    "        print(f\"  â€¢ Acceleration Range: {data['acceleration'].min():.2f} to {data['acceleration'].max():.2f} m/sÂ²\")\n",
    "        print(f\"  â€¢ Jerk Range: {data['jerk'].min():.2f} to {data['jerk'].max():.2f} m/sÂ³\")\n",
    "        print(f\"  â€¢ Speed Range: {data['speed_kmh'].min():.1f} to {data['speed_kmh'].max():.1f} km/h\")\n",
    "        \n",
    "        # æ€§èƒ½è¯„ä¼°\n",
    "        if 'hard_brake_events' in analyzer.results:\n",
    "            safety_rating = \"ğŸŸ¢ Excellent\" if len(analyzer.results['hard_brake_events']) == 0 else \\\n",
    "                           \"ğŸŸ¡ Good\" if len(analyzer.results['hard_brake_events']) <= 2 else \\\n",
    "                           \"ğŸŸ  Needs Improvement\"\n",
    "            print(f\"  â€¢ Safety Rating: {safety_rating}\")\n",
    "        \n",
    "        avg_energy = np.mean([p['energy_efficiency'] for p in analyzer.results['cluster_profiles'].values()])\n",
    "        efficiency_rating = \"ğŸŸ¢ Excellent\" if avg_energy < 20 else \\\n",
    "                           \"ğŸŸ¡ Good\" if avg_energy < 30 else \\\n",
    "                           \"ğŸŸ  Moderate\"\n",
    "        print(f\"  â€¢ Efficiency Rating: {efficiency_rating} ({avg_energy:.1f} kWh/100km)\")\n",
    "        \n",
    "        print(f\"\\nâœ¨ Analysis Features Highlights:\")\n",
    "        print(f\"  âœ… Microsecond timestamp precision\")\n",
    "        print(f\"  âœ… Real GPS-based acceleration calculation\")\n",
    "        print(f\"  âœ… Instantaneous jerk values (not averaged)\")\n",
    "        print(f\"  âœ… Startup phase optimized thresholds\")\n",
    "        print(f\"  âœ… Intelligent hard brake detection\")\n",
    "        print(f\"  âœ… Multi-dimensional driver behavior clustering\")\n",
    "        print(f\"  âœ… Personalized driving recommendations\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ Analysis failed. Please check your data file and try again.\")\n",
    "        print(\"\\nğŸ”§ Troubleshooting Tips:\")\n",
    "        print(\"  â€¢ Ensure your CSV file exists and is readable\")\n",
    "        print(\"  â€¢ Check that the data format matches the expected structure:\")\n",
    "        print(\"    - GPS: 0,timestamp,lat,lon,alt,speed_kmh,satellites\")\n",
    "        print(\"    - Accelerometer: 1,timestamp,timestamp_us,x,y,z\")\n",
    "        print(\"    - Gyroscope: 2,timestamp,timestamp_us,x,y,z\")\n",
    "        print(\"  â€¢ Verify that timestamps are in microseconds\")\n",
    "        print(\"  â€¢ Make sure the file contains sufficient data points\")\n",
    "\n",
    "# è¾…åŠ©å‡½æ•°ï¼šæ•°æ®æ ¼å¼éªŒè¯\n",
    "def validate_data_format(file_path, sample_lines=10):\n",
    "    \"\"\"\n",
    "    éªŒè¯æ•°æ®æ–‡ä»¶æ ¼å¼\n",
    "    Args:\n",
    "        file_path: æ•°æ®æ–‡ä»¶è·¯å¾„\n",
    "        sample_lines: æ£€æŸ¥çš„æ ·æœ¬è¡Œæ•°\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ” Validating data format for {file_path}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = [f.readline().strip() for _ in range(sample_lines)]\n",
    "        \n",
    "        format_counts = {'gps': 0, 'acc': 0, 'gyro': 0, 'rot': 0, 'unknown': 0}\n",
    "        \n",
    "        print(\"Sample data lines:\")\n",
    "        for i, line in enumerate(lines):\n",
    "            if not line:\n",
    "                continue\n",
    "            values = line.split(',')\n",
    "            print(f\"  {i+1}: {line}\")\n",
    "            \n",
    "            if len(values) >= 2:\n",
    "                try:\n",
    "                    data_type = int(values[0])\n",
    "                    if data_type == 0:\n",
    "                        format_counts['gps'] += 1\n",
    "                        if len(values) < 6:\n",
    "                            print(f\"    âš ï¸  GPS line has only {len(values)} columns, expected 6+\")\n",
    "                    elif data_type == 1:\n",
    "                        format_counts['acc'] += 1\n",
    "                        if len(values) < 5:\n",
    "                            print(f\"    âš ï¸  Accelerometer line has only {len(values)} columns, expected 5+\")\n",
    "                    elif data_type == 2:\n",
    "                        format_counts['gyro'] += 1\n",
    "                        if len(values) < 5:\n",
    "                            print(f\"    âš ï¸  Gyroscope line has only {len(values)} columns, expected 5+\")\n",
    "                    elif data_type == 3:\n",
    "                        format_counts['rot'] += 1\n",
    "                        if len(values) < 6:\n",
    "                            print(f\"    âš ï¸  Rotation line has only {len(values)} columns, expected 6+\")\n",
    "                    else:\n",
    "                        format_counts['unknown'] += 1\n",
    "                        print(f\"    âš ï¸  Unknown data type: {data_type}\")\n",
    "                except ValueError:\n",
    "                    format_counts['unknown'] += 1\n",
    "                    print(f\"    âŒ Invalid data type: {values[0]}\")\n",
    "        \n",
    "        print(f\"\\nData type distribution in sample:\")\n",
    "        for dtype, count in format_counts.items():\n",
    "            if count > 0:\n",
    "                print(f\"  {dtype}: {count} lines\")\n",
    "        \n",
    "        # éªŒè¯æ—¶é—´æˆ³\n",
    "        if format_counts['gps'] > 0 or format_counts['acc'] > 0:\n",
    "            print(f\"\\nTimestamp validation:\")\n",
    "            for line in lines:\n",
    "                if not line:\n",
    "                    continue\n",
    "                values = line.split(',')\n",
    "                if len(values) >= 2:\n",
    "                    try:\n",
    "                        timestamp = int(values[1])\n",
    "                        if timestamp > 1000000000000:  # å¾®ç§’çº§æ—¶é—´æˆ³\n",
    "                            print(f\"  âœ… Microsecond timestamp detected: {timestamp}\")\n",
    "                        elif timestamp > 1000000000:   # æ¯«ç§’çº§æ—¶é—´æˆ³\n",
    "                            print(f\"  âš ï¸  Millisecond timestamp detected: {timestamp}\")\n",
    "                        else:\n",
    "                            print(f\"  âŒ Unusual timestamp: {timestamp}\")\n",
    "                        break\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error validating file: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d42759cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 15:26:56,544 - INFO - EcoDrivingAnalyzer v2.1 initialized (microsecond timestamps)\n",
      "2025-05-27 15:26:56,544 - INFO - Parsing sensor data from ts_1747221572.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Running Eco-Driving Analysis - Startup Phase Optimized\n",
      "ğŸ“ Data file: ts_1747221572.csv\n",
      "ğŸ”§ Configuration: Optimized for startup phase with microsecond precision\n",
      "â±ï¸  Expected analysis time: 30-60 seconds\n",
      "\n",
      "ğŸš— Starting Complete Eco-Driving Analysis System v2.1\n",
      "ğŸ“ Optimized for startup phase analysis with microsecond precision\n",
      "======================================================================\n",
      "ğŸ“Š Step 1: Parsing sensor data (microsecond timestamps)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 15:26:57,076 - INFO - Parsed 100000 lines from ts_1747221572.csv\n",
      "2025-05-27 15:26:57,209 - INFO - Extracting driving features with microsecond precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GPSæ•°æ®è§£æ ===\n",
      "GPSåŸå§‹è¡Œæ•°: 667\n",
      "æ ·æœ¬æ•°æ®: ['0', '1747221671', '57.687946', '11.980719', '56.200001', '2.857636', '12']\n",
      "GPSæ•°æ®è´¨é‡æ£€æŸ¥:\n",
      "  æ•°æ®ç‚¹æ•°: 667\n",
      "  æ—¶é—´è·¨åº¦: 0.0 ç§’ (0.0 åˆ†é’Ÿ)\n",
      "  é€Ÿåº¦èŒƒå›´: 0.0 - 91.8 km/h\n",
      "  ä½ç½®å˜åŒ–: çº¬åº¦ 0.038410Â°, ç»åº¦ 0.017737Â°\n",
      "\n",
      "=== åŠ é€Ÿåº¦ä¼ æ„Ÿå™¨æ•°æ®è§£æ ===\n",
      "åŠ é€Ÿåº¦åŸå§‹è¡Œæ•°: 84489\n",
      "æ ·æœ¬æ•°æ®: ['1', '1747221671', '3809', '-1.800781', '-0.957031', '9.539062']\n",
      "åŠ é€Ÿåº¦æ•°æ®è´¨é‡æ£€æŸ¥:\n",
      "  æ•°æ®ç‚¹æ•°: 84489\n",
      "  æ—¶é—´è·¨åº¦: 1.0 ç§’\n",
      "  åŸå§‹åŠ é€Ÿåº¦æœ€å¤§å€¼: 14.90\n",
      "\n",
      "=== é™€èºä»ªæ•°æ®è§£æ ===\n",
      "  æ•°æ®ç‚¹æ•°: 12051\n",
      "  Zè½´è§’é€Ÿåº¦èŒƒå›´: -0.529 - 0.596 rad/s\n",
      "ğŸ” Step 2: Extracting driving features...\n",
      "\n",
      "=== GPSç‰¹å¾æå– ===\n",
      "GPSåŠ é€Ÿåº¦è®¡ç®—ç»“æœ:\n",
      "  éé›¶å€¼: 0/667 (0.0%)\n",
      "  èŒƒå›´: 0.000 - 0.000 m/sÂ²\n",
      "  å¹³å‡: 0.000 m/sÂ²\n",
      "  æ ‡å‡†å·®: 0.000 m/sÂ²\n",
      "âš ï¸  GPSåŠ é€Ÿåº¦è®¡ç®—å¼‚å¸¸ï¼Œä½¿ç”¨æ”¹è¿›çš„åˆæˆæ–¹æ³•...\n",
      "  åˆæˆåŠ é€Ÿåº¦èŒƒå›´: -8.000 - 8.000 m/sÂ²\n",
      "\n",
      "=== åŠ é€Ÿåº¦ä¼ æ„Ÿå™¨ç‰¹å¾æå– ===\n",
      "Magnitudeç»Ÿè®¡: 4.599 - 14.913\n",
      "Magnitudeå˜åŒ–ç»Ÿè®¡: -5.348178 - 5.949456\n",
      "æ—¶é—´é—´éš”ç»Ÿè®¡: 0.000000 - 0.000221 ç§’\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'jerks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1202\u001b[0m\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;66;03m# æ‰§è¡Œå®Œæ•´åˆ†æ\u001b[39;00m\n\u001b[0;32m-> 1202\u001b[0m analyzer \u001b[38;5;241m=\u001b[39m run_complete_eco_driving_analysis(data_file, startup_config)\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m analyzer:\n\u001b[1;32m   1205\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mğŸ‰ Analysis completed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[25], line 1134\u001b[0m, in \u001b[0;36mrun_complete_eco_driving_analysis\u001b[0;34m(data_file, config)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;66;03m# 2. æå–ç‰¹å¾\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ” Step 2: Extracting driving features...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m analyzer\u001b[38;5;241m.\u001b[39mextract_driving_features():\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâŒ Failed to extract features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[25], line 355\u001b[0m, in \u001b[0;36mEcoDrivingAnalyzer.extract_driving_features\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(acc_df)):\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 355\u001b[0m         jerks\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m0.0\u001b[39m)\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    357\u001b[0m         dt \u001b[38;5;241m=\u001b[39m dt_acc\u001b[38;5;241m.\u001b[39miloc[i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jerks' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.signal import savgol_filter\n",
    "from geopy.distance import geodesic\n",
    "import warnings\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "# é…ç½®æ—¥å¿—å’Œå¸¸é‡\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ç³»ç»Ÿå¸¸é‡ - ä¿®æ­£ä¸ºå¾®ç§’\n",
    "GRAVITY = 9.81\n",
    "MAX_TIME_DIFF = 5000000  # æœ€å¤§æ—¶é—´å·®ï¼ˆå¾®ç§’ï¼‰5ç§’\n",
    "MAX_SAMPLES = 100000     # å¢åŠ æœ€å¤§æ ·æœ¬æ•°\n",
    "VERSION = \"2.1\"\n",
    "\n",
    "class EcoDrivingAnalyzer:\n",
    "    \"\"\"ç”Ÿæ€é©¾é©¶åˆ†æä¸»ç±» - å¾®ç§’æ—¶é—´æˆ³ç‰ˆæœ¬\"\"\"\n",
    "    \n",
    "    def __init__(self, config=None):\n",
    "        \"\"\"åˆå§‹åŒ–åˆ†æå™¨\"\"\"\n",
    "        self.config = config or self._default_config()\n",
    "        self.raw_data = {}\n",
    "        self.processed_data = None\n",
    "        self.features = {}\n",
    "        self.results = {}\n",
    "        self.time_offset = None  # ç”¨äºè®¡ç®—ç›¸å¯¹æ—¶é—´\n",
    "        \n",
    "        logger.info(f\"EcoDrivingAnalyzer v{VERSION} initialized (microsecond timestamps)\")\n",
    "    \n",
    "    def _default_config(self):\n",
    "        \"\"\"é»˜è®¤é…ç½®\"\"\"\n",
    "        return {\n",
    "            'hard_brake_threshold': -2.5,\n",
    "            'speed_drop_threshold': 8,\n",
    "            'min_brake_speed': 15,\n",
    "            'energy_model': {\n",
    "                'vehicle_mass': 1800,          # æ›´è½»çš„ä¹˜ç”¨è½¦\n",
    "                'drag_coefficient': 0.28,      # ç°ä»£è½¿è½¦é£é˜»ç³»æ•°\n",
    "                'frontal_area': 2.3,           # ç°ä»£è½¿è½¦è¿é£é¢ç§¯\n",
    "                'rolling_resistance': 0.012    # ç°ä»£è½®èƒæ»šåŠ¨é˜»åŠ›\n",
    "            },\n",
    "            'clustering': {\n",
    "                'n_clusters': 3,\n",
    "                'features': ['speed', 'acceleration', 'jerk', 'turning_rate']\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def parse_sensor_data(self, file_path):\n",
    "        \"\"\"è§£æä¼ æ„Ÿå™¨æ•°æ®æ–‡ä»¶ - ä¿®æ­£å¾®ç§’æ—¶é—´æˆ³å¤„ç†\"\"\"\n",
    "        logger.info(f\"Parsing sensor data from {file_path}\")\n",
    "        \n",
    "        gps_rows, acc_rows, gyro_rows, rot_rows = [], [], [], []\n",
    "        total_rows = 0\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, \"r\") as file:\n",
    "                for line_num, line in enumerate(file):\n",
    "                    values = line.strip().split(\",\")\n",
    "                    if len(values) < 2:\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        data_type = int(values[0])\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                    \n",
    "                    # ä¿®æ­£æ•°æ®è§£æé€»è¾‘\n",
    "                    if data_type == 0 and len(values) >= 6:  # GPSæ•°æ®\n",
    "                        gps_rows.append(values)\n",
    "                    elif data_type == 1 and len(values) >= 5:  # åŠ é€Ÿåº¦è®¡æ•°æ®\n",
    "                        acc_rows.append(values)\n",
    "                    elif data_type == 2 and len(values) >= 5:  # é™€èºä»ªæ•°æ®\n",
    "                        gyro_rows.append(values)\n",
    "                    elif data_type == 3 and len(values) >= 6:  # å››å…ƒæ•°æ•°æ®\n",
    "                        rot_rows.append(values)\n",
    "                    \n",
    "                    total_rows += 1\n",
    "                    if total_rows >= MAX_SAMPLES:\n",
    "                        break\n",
    "            \n",
    "            logger.info(f\"Parsed {total_rows} lines from {file_path}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading file: {e}\")\n",
    "            return False\n",
    "        \n",
    "        # å¤„ç†GPSæ•°æ®\n",
    "        if gps_rows:\n",
    "            print(f\"\\n=== GPSæ•°æ®è§£æ ===\")\n",
    "            print(f\"GPSåŸå§‹è¡Œæ•°: {len(gps_rows)}\")\n",
    "            print(f\"æ ·æœ¬æ•°æ®: {gps_rows[0]}\")\n",
    "            \n",
    "            # å¤„ç†GPSæ•°æ®æ ¼å¼ï¼š0,timestamp,lat,lon,alt,speed_kmh,satellites\n",
    "            gps_data = []\n",
    "            for row in gps_rows:\n",
    "                try:\n",
    "                    if len(row) >= 6:\n",
    "                        gps_data.append([\n",
    "                            int(row[0]),      # data_type\n",
    "                            int(row[1]),      # timestamp (å¾®ç§’)\n",
    "                            float(row[2]),    # latitude\n",
    "                            float(row[3]),    # longitude\n",
    "                            float(row[4]),    # altitude\n",
    "                            float(row[5]),    # speed_kmh\n",
    "                            int(row[6]) if len(row) > 6 else 12  # satellites\n",
    "                        ])\n",
    "                except (ValueError, IndexError) as e:\n",
    "                    continue\n",
    "            \n",
    "            if gps_data:\n",
    "                gps_df = pd.DataFrame(gps_data, columns=[\n",
    "                    \"data_type\", \"timestamp\", \"latitude\", \"longitude\", \n",
    "                    \"altitude\", \"speed_kmh\", \"satellites\"\n",
    "                ])\n",
    "                \n",
    "                gps_df[\"speed_ms\"] = gps_df[\"speed_kmh\"] / 3.6\n",
    "                \n",
    "                # è®¾ç½®æ—¶é—´åç§»é‡\n",
    "                if self.time_offset is None:\n",
    "                    self.time_offset = gps_df['timestamp'].min()\n",
    "                \n",
    "                # è®¡ç®—ç›¸å¯¹æ—¶é—´ï¼ˆç§’ï¼‰\n",
    "                gps_df['relative_time_s'] = (gps_df['timestamp'] - self.time_offset) / 1000000.0\n",
    "                \n",
    "                print(f\"GPSæ•°æ®è´¨é‡æ£€æŸ¥:\")\n",
    "                print(f\"  æ•°æ®ç‚¹æ•°: {len(gps_df)}\")\n",
    "                print(f\"  æ—¶é—´è·¨åº¦: {gps_df['relative_time_s'].max():.1f} ç§’ ({gps_df['relative_time_s'].max()/60:.1f} åˆ†é’Ÿ)\")\n",
    "                print(f\"  é€Ÿåº¦èŒƒå›´: {gps_df['speed_kmh'].min():.1f} - {gps_df['speed_kmh'].max():.1f} km/h\")\n",
    "                print(f\"  ä½ç½®å˜åŒ–: çº¬åº¦ {gps_df['latitude'].max()-gps_df['latitude'].min():.6f}Â°, ç»åº¦ {gps_df['longitude'].max()-gps_df['longitude'].min():.6f}Â°\")\n",
    "                \n",
    "                # æ•°æ®æ¸…æ´—\n",
    "                gps_df = gps_df[gps_df[\"speed_kmh\"] <= 200]\n",
    "                gps_df = gps_df[gps_df[\"latitude\"].between(-90, 90)]\n",
    "                gps_df = gps_df[gps_df[\"longitude\"].between(-180, 180)]\n",
    "                \n",
    "                self.raw_data['gps'] = gps_df\n",
    "        \n",
    "        # å¤„ç†åŠ é€Ÿåº¦ä¼ æ„Ÿå™¨æ•°æ®\n",
    "        if acc_rows:\n",
    "            print(f\"\\n=== åŠ é€Ÿåº¦ä¼ æ„Ÿå™¨æ•°æ®è§£æ ===\")\n",
    "            print(f\"åŠ é€Ÿåº¦åŸå§‹è¡Œæ•°: {len(acc_rows)}\")\n",
    "            print(f\"æ ·æœ¬æ•°æ®: {acc_rows[0]}\")\n",
    "            \n",
    "            # å¤„ç†åŠ é€Ÿåº¦æ•°æ®æ ¼å¼ï¼š1,timestamp,timestamp_us,x,y,z\n",
    "            acc_data = []\n",
    "            for row in acc_rows:\n",
    "                try:\n",
    "                    if len(row) >= 5:\n",
    "                        acc_data.append([\n",
    "                            int(row[0]),      # data_type\n",
    "                            int(row[1]),      # timestamp (å¾®ç§’)\n",
    "                            int(row[2]),      # timestamp_us (é¢å¤–çš„å¾®ç§’)\n",
    "                            float(row[3]),    # x\n",
    "                            float(row[4]),    # y\n",
    "                            float(row[5]) if len(row) > 5 else 0.0  # z\n",
    "                        ])\n",
    "                except (ValueError, IndexError):\n",
    "                    continue\n",
    "            \n",
    "            if acc_data:\n",
    "                acc_df = pd.DataFrame(acc_data, columns=[\n",
    "                    \"data_type\", \"timestamp\", \"timestamp_us\", \"x\", \"y\", \"z\"\n",
    "                ])\n",
    "                \n",
    "                # è®¡ç®—å®Œæ•´æ—¶é—´æˆ³ï¼ˆä¸»æ—¶é—´æˆ³ + å¾®ç§’åç§»ï¼‰\n",
    "                acc_df['full_timestamp'] = acc_df['timestamp'] + acc_df['timestamp_us']\n",
    "                \n",
    "                if self.time_offset is None:\n",
    "                    self.time_offset = acc_df['full_timestamp'].min()\n",
    "                \n",
    "                acc_df['relative_time_s'] = (acc_df['full_timestamp'] - self.time_offset) / 1000000.0\n",
    "                \n",
    "                print(f\"åŠ é€Ÿåº¦æ•°æ®è´¨é‡æ£€æŸ¥:\")\n",
    "                print(f\"  æ•°æ®ç‚¹æ•°: {len(acc_df)}\")\n",
    "                print(f\"  æ—¶é—´è·¨åº¦: {acc_df['relative_time_s'].max():.1f} ç§’\")\n",
    "                \n",
    "                # æ£€æŸ¥åŠ é€Ÿåº¦èŒƒå›´å’Œç¼©æ”¾\n",
    "                max_acc = max(acc_df['x'].abs().max(), acc_df['y'].abs().max(), acc_df['z'].abs().max())\n",
    "                print(f\"  åŸå§‹åŠ é€Ÿåº¦æœ€å¤§å€¼: {max_acc:.2f}\")\n",
    "                \n",
    "                # æ™ºèƒ½ç¼©æ”¾ - æ ¹æ®æ•°æ®èŒƒå›´åˆ¤æ–­å•ä½\n",
    "                if max_acc > 50:  # å¦‚æœæ•°å€¼å¾ˆå¤§ï¼Œå¯èƒ½éœ€è¦ç¼©æ”¾\n",
    "                    if max_acc > 1000:\n",
    "                        scale_factor = 1000.0\n",
    "                        print(\"  æ£€æµ‹åˆ°åŠ é€Ÿåº¦å•ä½å¯èƒ½æ˜¯ mgï¼Œåº”ç”¨1000xç¼©æ”¾\")\n",
    "                    else:\n",
    "                        scale_factor = 10.0\n",
    "                        print(\"  æ£€æµ‹åˆ°åŠ é€Ÿåº¦å•ä½å¼‚å¸¸ï¼Œåº”ç”¨10xç¼©æ”¾\")\n",
    "                    \n",
    "                    acc_df[[\"x\", \"y\", \"z\"]] = acc_df[[\"x\", \"y\", \"z\"]] / scale_factor\n",
    "                    print(f\"  ç¼©æ”¾åèŒƒå›´: {acc_df['x'].min():.2f} - {acc_df['x'].max():.2f}\")\n",
    "                \n",
    "                acc_df[\"magnitude\"] = np.sqrt(acc_df[\"x\"]**2 + acc_df[\"y\"]**2 + acc_df[\"z\"]**2)\n",
    "                self.raw_data['acc'] = acc_df\n",
    "        \n",
    "        # å¤„ç†é™€èºä»ªæ•°æ®\n",
    "        if gyro_rows:\n",
    "            print(f\"\\n=== é™€èºä»ªæ•°æ®è§£æ ===\")\n",
    "            gyro_data = []\n",
    "            for row in gyro_rows:\n",
    "                try:\n",
    "                    if len(row) >= 5:\n",
    "                        gyro_data.append([\n",
    "                            int(row[0]),      # data_type\n",
    "                            int(row[1]),      # timestamp\n",
    "                            int(row[2]),      # timestamp_us\n",
    "                            float(row[3]),    # x\n",
    "                            float(row[4]),    # y\n",
    "                            float(row[5]) if len(row) > 5 else 0.0  # z\n",
    "                        ])\n",
    "                except (ValueError, IndexError):\n",
    "                    continue\n",
    "            \n",
    "            if gyro_data:\n",
    "                gyro_df = pd.DataFrame(gyro_data, columns=[\n",
    "                    \"data_type\", \"timestamp\", \"timestamp_us\", \"x\", \"y\", \"z\"\n",
    "                ])\n",
    "                gyro_df['full_timestamp'] = gyro_df['timestamp'] + gyro_df['timestamp_us']\n",
    "                \n",
    "                if self.time_offset is None:\n",
    "                    self.time_offset = gyro_df['full_timestamp'].min()\n",
    "                \n",
    "                gyro_df['relative_time_s'] = (gyro_df['full_timestamp'] - self.time_offset) / 1000000.0\n",
    "                gyro_df[\"turning_rate\"] = gyro_df[\"z\"].abs()\n",
    "                \n",
    "                print(f\"  æ•°æ®ç‚¹æ•°: {len(gyro_df)}\")\n",
    "                print(f\"  Zè½´è§’é€Ÿåº¦èŒƒå›´: {gyro_df['z'].min():.3f} - {gyro_df['z'].max():.3f} rad/s\")\n",
    "                \n",
    "                self.raw_data['gyro'] = gyro_df\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def extract_driving_features(self):\n",
    "        \"\"\"æå–é©¾é©¶ç‰¹å¾ - ä¿®æ­£æ—¶é—´å¤„ç†\"\"\"\n",
    "        logger.info(\"Extracting driving features with microsecond precision\")\n",
    "        \n",
    "        # GPSè·¯çº¿ç‰¹å¾\n",
    "        if 'gps' in self.raw_data and not self.raw_data['gps'].empty:\n",
    "            gps_df = self.raw_data['gps'].copy().sort_values('timestamp').reset_index(drop=True)\n",
    "            \n",
    "            print(f\"\\n=== GPSç‰¹å¾æå– ===\")\n",
    "            \n",
    "            # è®¡ç®—è·ç¦»å’Œå¡åº¦\n",
    "            distances, gradients = [], []\n",
    "            for i in range(1, len(gps_df)):\n",
    "                p1 = (gps_df[\"latitude\"].iloc[i-1], gps_df[\"longitude\"].iloc[i-1])\n",
    "                p2 = (gps_df[\"latitude\"].iloc[i], gps_df[\"longitude\"].iloc[i])\n",
    "                try:\n",
    "                    d = geodesic(p1, p2).meters\n",
    "                except Exception:\n",
    "                    d = 0\n",
    "                distances.append(d)\n",
    "                \n",
    "                alt_diff = gps_df[\"altitude\"].iloc[i] - gps_df[\"altitude\"].iloc[i-1]\n",
    "                gradient = alt_diff / d if d > 0.5 else 0  # è·ç¦»>0.5ç±³æ‰è®¡ç®—å¡åº¦\n",
    "                gradients.append(gradient)\n",
    "            \n",
    "            if distances:\n",
    "                gps_df.loc[1:, \"distance\"] = distances\n",
    "                gps_df.loc[1:, \"gradient\"] = gradients\n",
    "            gps_df[\"distance\"] = gps_df.get(\"distance\", 0).fillna(0)\n",
    "            gps_df[\"gradient\"] = gps_df.get(\"gradient\", 0).fillna(0)\n",
    "            \n",
    "            # ä¿®æ­£çš„åŠ é€Ÿåº¦è®¡ç®— - ä½¿ç”¨å¾®ç§’ç²¾åº¦\n",
    "            dt_values = gps_df[\"timestamp\"].diff() / 1000000.0  # è½¬æ¢ä¸ºç§’\n",
    "            speed_changes_ms = gps_df[\"speed_ms\"].diff()\n",
    "            \n",
    "            accelerations = []\n",
    "            for i in range(len(gps_df)):\n",
    "                if i == 0:\n",
    "                    accelerations.append(0.0)\n",
    "                else:\n",
    "                    dt = dt_values.iloc[i]\n",
    "                    speed_change = speed_changes_ms.iloc[i]\n",
    "                    \n",
    "                    # ä¿®æ­£æ—¶é—´èŒƒå›´æ£€æŸ¥\n",
    "                    if 0.01 < dt < 300:  # 10ms åˆ° 5åˆ†é’Ÿ\n",
    "                        acc = speed_change / dt\n",
    "                        acc = max(-12, min(12, acc))  # åˆç†çš„åŠ é€Ÿåº¦èŒƒå›´\n",
    "                        accelerations.append(acc)\n",
    "                    else:\n",
    "                        # å¯¹äºå¼‚å¸¸æ—¶é—´é—´éš”ï¼Œä½¿ç”¨å‰ä¸€ä¸ªåŠ é€Ÿåº¦çš„è¡°å‡å€¼\n",
    "                        if i > 1:\n",
    "                            accelerations.append(accelerations[-1] * 0.8)\n",
    "                        else:\n",
    "                            accelerations.append(0.0)\n",
    "            \n",
    "            gps_df[\"acceleration\"] = accelerations\n",
    "            \n",
    "            # æ£€æŸ¥GPSåŠ é€Ÿåº¦è®¡ç®—ç»“æœ\n",
    "            acc_nonzero = (np.array(accelerations) != 0).sum()\n",
    "            acc_range = [min(accelerations), max(accelerations)]\n",
    "            \n",
    "            print(f\"GPSåŠ é€Ÿåº¦è®¡ç®—ç»“æœ:\")\n",
    "            print(f\"  éé›¶å€¼: {acc_nonzero}/{len(accelerations)} ({acc_nonzero/len(accelerations)*100:.1f}%)\")\n",
    "            print(f\"  èŒƒå›´: {acc_range[0]:.3f} - {acc_range[1]:.3f} m/sÂ²\")\n",
    "            print(f\"  å¹³å‡: {np.mean(accelerations):.3f} m/sÂ²\")\n",
    "            print(f\"  æ ‡å‡†å·®: {np.std(accelerations):.3f} m/sÂ²\")\n",
    "            \n",
    "            # å¦‚æœGPSåŠ é€Ÿåº¦ä»ç„¶é—®é¢˜å¾ˆå¤§ï¼Œä½¿ç”¨æ”¹è¿›çš„åˆæˆæ–¹æ³•\n",
    "            if abs(max(accelerations)) < 0.01 or acc_nonzero < len(accelerations) * 0.1:\n",
    "                print(\"âš ï¸  GPSåŠ é€Ÿåº¦è®¡ç®—å¼‚å¸¸ï¼Œä½¿ç”¨æ”¹è¿›çš„åˆæˆæ–¹æ³•...\")\n",
    "                \n",
    "                # ä½¿ç”¨é€Ÿåº¦çš„å˜åŒ–è¶‹åŠ¿ç”Ÿæˆæ›´çœŸå®çš„åŠ é€Ÿåº¦\n",
    "                speed_smooth = gps_df['speed_ms'].rolling(window=3, center=True).mean().fillna(gps_df['speed_ms'])\n",
    "                speed_diff = speed_smooth.diff()\n",
    "                time_diff = gps_df['relative_time_s'].diff()\n",
    "                \n",
    "                synthetic_acc = []\n",
    "                for i in range(len(gps_df)):\n",
    "                    if i == 0:\n",
    "                        synthetic_acc.append(0.0)\n",
    "                    else:\n",
    "                        dt = time_diff.iloc[i]\n",
    "                        if dt > 0:\n",
    "                            acc = speed_diff.iloc[i] / dt\n",
    "                            acc = max(-8, min(8, acc))\n",
    "                            synthetic_acc.append(acc)\n",
    "                        else:\n",
    "                            synthetic_acc.append(0.0)\n",
    "                \n",
    "                gps_df['acceleration'] = synthetic_acc\n",
    "                print(f\"  åˆæˆåŠ é€Ÿåº¦èŒƒå›´: {min(synthetic_acc):.3f} - {max(synthetic_acc):.3f} m/sÂ²\")\n",
    "            \n",
    "            self.features['route'] = gps_df\n",
    "        \n",
    "        # åŠ é€Ÿåº¦ä¼ æ„Ÿå™¨ç‰¹å¾ - ä¿®æ­£æ—¶é—´å¤„ç†\n",
    "        if 'acc' in self.raw_data and not self.raw_data['acc'].empty:\n",
    "            acc_df = self.raw_data['acc'].copy().sort_values('full_timestamp').reset_index(drop=True)\n",
    "            \n",
    "            print(f\"\\n=== åŠ é€Ÿåº¦ä¼ æ„Ÿå™¨ç‰¹å¾æå– ===\")\n",
    "            \n",
    "            # è®¡ç®—Jerkï¼ˆæ€¥åŠ¨åº¦ï¼‰- ä½¿ç”¨å¾®ç§’ç²¾åº¦\n",
    "            dt_acc = acc_df[\"full_timestamp\"].diff() / 1000000.0  # è½¬æ¢ä¸ºç§’\n",
    "            magnitude_changes = acc_df[\"magnitude\"].diff()\n",
    "\n",
    "            # è°ƒè¯•ï¼šæ£€æŸ¥magnitudeå˜åŒ–\n",
    "            print(f\"Magnitudeç»Ÿè®¡: {acc_df['magnitude'].min():.3f} - {acc_df['magnitude'].max():.3f}\")\n",
    "            print(f\"Magnitudeå˜åŒ–ç»Ÿè®¡: {magnitude_changes.min():.6f} - {magnitude_changes.max():.6f}\")\n",
    "            print(f\"æ—¶é—´é—´éš”ç»Ÿè®¡: {dt_acc.min():.6f} - {dt_acc.max():.6f} ç§’\")\n",
    "            \n",
    "            for i in range(len(acc_df)):\n",
    "                if i == 0:\n",
    "                    jerks.append(0.0)\n",
    "                else:\n",
    "                    dt = dt_acc.iloc[i]\n",
    "                    mag_change = magnitude_changes.iloc[i]\n",
    "                    \n",
    "                    # ä¿®æ­£æ—¶é—´èŒƒå›´ - åŠ é€Ÿåº¦è®¡é‡‡æ ·é¢‘ç‡æ›´é«˜\n",
    "                    if 0.001 < dt < 1.0:  # 1ms åˆ° 1ç§’\n",
    "                        jerk = mag_change / dt\n",
    "                        jerk = max(-100, min(100, jerk))  # æ‰©å¤§jerkèŒƒå›´\n",
    "                        jerks.append(jerk)\n",
    "                    else:\n",
    "                        jerks.append(0.0)\n",
    "            \n",
    "            acc_df[\"jerk\"] = jerks\n",
    "            \n",
    "            # æ”¹è¿›çš„å¹³æ»‘å¤„ç†\n",
    "            if len(acc_df) > 5:\n",
    "                # ä½¿ç”¨æ›´å°çš„çª—å£ä¿æŒç¬æ—¶ç‰¹æ€§\n",
    "                win = min(3, len(acc_df)//2*2+1)\n",
    "                if win >= 3:\n",
    "                    acc_df[\"jerk_smooth\"] = savgol_filter(acc_df[\"jerk\"], win, 1)\n",
    "                else:\n",
    "                    acc_df[\"jerk_smooth\"] = acc_df[\"jerk\"]\n",
    "            else:\n",
    "                acc_df[\"jerk_smooth\"] = acc_df[\"jerk\"]\n",
    "            \n",
    "            print(f\"Jerkè®¡ç®—ç»“æœ:\")\n",
    "            print(f\"  åŸå§‹èŒƒå›´: {min(jerks):.3f} - {max(jerks):.3f} m/sÂ³\")\n",
    "            print(f\"  å¹³æ»‘åèŒƒå›´: {acc_df['jerk_smooth'].min():.3f} - {acc_df['jerk_smooth'].max():.3f} m/sÂ³\")\n",
    "            print(f\"  éé›¶å€¼: {(np.array(jerks) != 0).sum()}/{len(jerks)}\")\n",
    "            \n",
    "            self.features['behavior'] = acc_df\n",
    "        \n",
    "        # é™€èºä»ªè½¬å‘ç‰¹å¾\n",
    "        if 'gyro' in self.raw_data and not self.raw_data['gyro'].empty:\n",
    "            self.features['turning'] = self.raw_data['gyro'].copy()\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def detect_hard_brake_events(self):\n",
    "        \"\"\"æ£€æµ‹æ€¥åˆ¹è½¦äº‹ä»¶ - ä¿®æ­£ç‰ˆ\"\"\"\n",
    "        logger.info(\"Detecting hard brake events with improved algorithm\")\n",
    "        \n",
    "        if 'route' not in self.features:\n",
    "            logger.warning(\"No route data available for hard brake detection\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        df = self.features['route'].copy()\n",
    "        \n",
    "        # æ•°æ®å¹³æ»‘\n",
    "        if len(df) > 5:\n",
    "            window_size = min(5, len(df) // 2 * 2 + 1)\n",
    "            df['speed_smooth'] = savgol_filter(df['speed_kmh'], window_size, 2)\n",
    "        else:\n",
    "            df['speed_smooth'] = df['speed_kmh']\n",
    "        \n",
    "        # é€Ÿåº¦å˜åŒ–åˆ†æ - ä½¿ç”¨ç›¸å¯¹æ—¶é—´\n",
    "        df['speed_change'] = df['speed_smooth'].diff()\n",
    "        time_diff_s = df['relative_time_s'].diff()\n",
    "        df['speed_change_rate'] = df['speed_change'] / time_diff_s\n",
    "        df['speed_change_pct'] = df['speed_change'] / (df['speed_smooth'].shift(1) + 1)\n",
    "        \n",
    "        # é’ˆå¯¹ä½é€Ÿåœºæ™¯è°ƒæ•´çš„æ€¥åˆ¹è½¦æ£€æµ‹æ¡ä»¶\n",
    "        conditions = [\n",
    "            # æ¡ä»¶1: é€‚åº”ä½é€Ÿçš„ç»å¯¹é€Ÿåº¦ä¸‹é™\n",
    "            (df['speed_change'] < -5) & (df['speed_smooth'] > 10),  # é™ä½é€Ÿåº¦é˜ˆå€¼\n",
    "            \n",
    "            # æ¡ä»¶2: ç›¸å¯¹é€Ÿåº¦å˜åŒ–\n",
    "            (df['speed_change_pct'] < -0.20) & (df['speed_smooth'] > 8),  # æé«˜ç›¸å¯¹å˜åŒ–æ•æ„Ÿåº¦\n",
    "            \n",
    "            # æ¡ä»¶3: é€Ÿåº¦å˜åŒ–ç‡ï¼ˆé’ˆå¯¹èµ·æ­¥é˜¶æ®µï¼‰\n",
    "            (df['speed_change_rate'] < -8) & (df['speed_smooth'] > 5),  # é™ä½é€Ÿåº¦é˜ˆå€¼\n",
    "        ]\n",
    "        \n",
    "        df['hard_brake_candidate'] = np.logical_or.reduce(conditions)\n",
    "        \n",
    "        # é€Ÿåº¦å³°å€¼æ£€æµ‹ - é’ˆå¯¹ä½é€Ÿä¼˜åŒ–\n",
    "        df['is_speed_peak'] = False\n",
    "        df['hard_brake_refined'] = False\n",
    "        \n",
    "        # å¯»æ‰¾å±€éƒ¨é€Ÿåº¦å³°å€¼ï¼ˆé™ä½é˜ˆå€¼é€‚åº”ä½é€Ÿï¼‰\n",
    "        for i in range(2, len(df) - 2):\n",
    "            current_speed = df['speed_smooth'].iloc[i]\n",
    "            prev_speed = df['speed_smooth'].iloc[i-1]\n",
    "            next_speed = df['speed_smooth'].iloc[i+1]\n",
    "            \n",
    "            if (current_speed > prev_speed and current_speed > next_speed and current_speed > 8):  # é™ä½å³°å€¼é˜ˆå€¼\n",
    "                df.loc[i, 'is_speed_peak'] = True\n",
    "        \n",
    "        # åœ¨å³°å€¼åæ£€æµ‹æ€¥åˆ¹è½¦\n",
    "        for i in range(len(df)):\n",
    "            if df['is_speed_peak'].iloc[i]:\n",
    "                peak_speed = df['speed_smooth'].iloc[i]\n",
    "                \n",
    "                for j in range(i+1, min(i+6, len(df))):\n",
    "                    current_speed = df['speed_smooth'].iloc[j]\n",
    "                    speed_drop = peak_speed - current_speed\n",
    "                    time_span = df['relative_time_s'].iloc[j] - df['relative_time_s'].iloc[i]\n",
    "                    \n",
    "                    # é’ˆå¯¹ä½é€Ÿè°ƒæ•´çš„æ€¥åˆ¹è½¦æ¡ä»¶\n",
    "                    if speed_drop > 8 and time_span < 5:  # é™ä½é€Ÿåº¦ä¸‹é™é˜ˆå€¼\n",
    "                        df.loc[j, 'hard_brake_refined'] = True\n",
    "                        break\n",
    "        \n",
    "        # æœ€ç»ˆæ€¥åˆ¹è½¦äº‹ä»¶\n",
    "        df['hard_brake_final'] = df['hard_brake_candidate'] | df['hard_brake_refined']\n",
    "        \n",
    "        # å»é‡å¤„ç†\n",
    "        df['hard_brake_filtered'] = False\n",
    "        if df['hard_brake_final'].any():\n",
    "            brake_indices = df[df['hard_brake_final']].index\n",
    "            filtered_indices = [brake_indices[0]] if len(brake_indices) > 0 else []\n",
    "            \n",
    "            for i in range(1, len(brake_indices)):\n",
    "                time_gap = df['relative_time_s'].iloc[brake_indices[i]] - df['relative_time_s'].iloc[brake_indices[i-1]]\n",
    "                if time_gap > 2.0:  # 2ç§’é—´éš”\n",
    "                    filtered_indices.append(brake_indices[i])\n",
    "            \n",
    "            if filtered_indices:\n",
    "                df.loc[filtered_indices, 'hard_brake_filtered'] = True\n",
    "        \n",
    "        hard_brake_events = df[df['hard_brake_filtered']]\n",
    "        \n",
    "        print(f\"\\n=== æ€¥åˆ¹è½¦æ£€æµ‹ç»“æœ ===\")\n",
    "        print(f\"å€™é€‰äº‹ä»¶: {df['hard_brake_candidate'].sum()}\")\n",
    "        print(f\"ç²¾ç‚¼äº‹ä»¶: {df['hard_brake_refined'].sum()}\")\n",
    "        print(f\"æœ€ç»ˆæ£€æµ‹åˆ°: {len(hard_brake_events)} ä¸ªæ€¥åˆ¹è½¦äº‹ä»¶\")\n",
    "        \n",
    "        if not hard_brake_events.empty:\n",
    "            print(\"æ€¥åˆ¹è½¦äº‹ä»¶è¯¦æƒ…:\")\n",
    "            for i, (idx, event) in enumerate(hard_brake_events.iterrows()):\n",
    "                time_min = event['relative_time_s'] / 60\n",
    "                print(f\"  äº‹ä»¶{i+1}: {time_min:.1f}åˆ†é’Ÿ - é€Ÿåº¦: {event['speed_kmh']:.1f} km/h, åŠ é€Ÿåº¦: {event['acceleration']:.2f} m/sÂ²\")\n",
    "        \n",
    "        # æ›´æ–°è·¯çº¿æ•°æ®\n",
    "        self.features['route'] = df\n",
    "        \n",
    "        return hard_brake_events\n",
    "    \n",
    "    def synchronize_and_model_energy(self):\n",
    "        \"\"\"æ•°æ®åŒæ­¥å’Œèƒ½è€—å»ºæ¨¡ - å¾®ç§’ç²¾åº¦ç‰ˆæœ¬\"\"\"\n",
    "        logger.info(\"Synchronizing data and modeling energy consumption (microsecond precision)\")\n",
    "        \n",
    "        if 'route' not in self.features or 'behavior' not in self.features:\n",
    "            logger.warning(\"Missing required data for energy modeling\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        route_df = self.features['route']\n",
    "        behavior_df = self.features['behavior']\n",
    "        \n",
    "        # ä½¿ç”¨å¾®ç§’æ—¶é—´æˆ³è¿›è¡ŒåŒæ­¥\n",
    "        route_times = route_df['timestamp'].values\n",
    "        behavior_times = behavior_df['full_timestamp'].values\n",
    "        \n",
    "        print(f\"\\n=== æ•°æ®åŒæ­¥ (å¾®ç§’ç²¾åº¦) ===\")\n",
    "        print(f\"GPSæ•°æ®ç‚¹: {len(route_df)}\")\n",
    "        print(f\"åŠ é€Ÿåº¦æ•°æ®ç‚¹: {len(behavior_df)}\")\n",
    "        \n",
    "        combined_data = []\n",
    "        sync_errors = 0\n",
    "        perfect_matches = 0\n",
    "        \n",
    "        for i, row in route_df.iterrows():\n",
    "            gps_time = row['timestamp']\n",
    "            time_diffs = np.abs(behavior_times - gps_time)\n",
    "            closest_acc_idx = np.argmin(time_diffs)\n",
    "            min_time_diff = time_diffs[closest_acc_idx]\n",
    "            \n",
    "            if min_time_diff == 0:\n",
    "                perfect_matches += 1\n",
    "            elif min_time_diff > MAX_TIME_DIFF:\n",
    "                sync_errors += 1\n",
    "                continue\n",
    "            \n",
    "            entry = {\n",
    "                'timestamp': gps_time,\n",
    "                'relative_time_s': row['relative_time_s'],\n",
    "                'speed': row['speed_ms'],\n",
    "                'speed_kmh': row['speed_kmh'],\n",
    "                'acceleration': row['acceleration'],\n",
    "                'gradient': row['gradient'],\n",
    "                'jerk': behavior_df['jerk_smooth'].iloc[closest_acc_idx],\n",
    "                'sync_error_us': min_time_diff  # å¾®ç§’\n",
    "            }\n",
    "            \n",
    "            # æ·»åŠ è½¬å‘æ•°æ®\n",
    "            if 'turning' in self.features:\n",
    "                turning_times = self.features['turning']['full_timestamp'].values\n",
    "                closest_turn_idx = np.argmin(np.abs(turning_times - gps_time))\n",
    "                turn_time_diff = np.abs(turning_times[closest_turn_idx] - gps_time)\n",
    "                \n",
    "                if turn_time_diff <= MAX_TIME_DIFF:\n",
    "                    entry['turning_rate'] = self.features['turning']['turning_rate'].iloc[closest_turn_idx]\n",
    "                else:\n",
    "                    entry['turning_rate'] = 0\n",
    "            else:\n",
    "                entry['turning_rate'] = 0\n",
    "            \n",
    "            combined_data.append(entry)\n",
    "        \n",
    "        if not combined_data:\n",
    "            logger.warning(\"No synchronized data points found\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        combined_df = pd.DataFrame(combined_data)\n",
    "        \n",
    "        # èƒ½è€—è®¡ç®—\n",
    "        combined_df['energy_factor'] = self._calculate_energy_consumption(combined_df)\n",
    "        \n",
    "        print(f\"åŒæ­¥ç»“æœ:\")\n",
    "        print(f\"  å®Œç¾åŒ¹é…: {perfect_matches}\")\n",
    "        print(f\"  æˆåŠŸåŒæ­¥: {len(combined_data)}\")\n",
    "        print(f\"  åŒæ­¥é”™è¯¯: {sync_errors}\")\n",
    "        print(f\"  å¹³å‡åŒæ­¥è¯¯å·®: {combined_df['sync_error_us'].mean():.0f} å¾®ç§’\")\n",
    "        \n",
    "        self.processed_data = combined_df\n",
    "        return combined_df\n",
    "    \n",
    "    def _calculate_energy_consumption(self, df):\n",
    "        \"\"\"è®¡ç®—èƒ½è€— - ä¿®æ­£ç‰ˆ\"\"\"\n",
    "        config = self.config['energy_model']\n",
    "        mass = config['vehicle_mass']\n",
    "        g = GRAVITY\n",
    "        rho = 1.225  # ç©ºæ°”å¯†åº¦\n",
    "        Cd = config['drag_coefficient']\n",
    "        A = config['frontal_area']\n",
    "        Cr = config['rolling_resistance']\n",
    "        \n",
    "        power_W = np.zeros(len(df))\n",
    "        \n",
    "        for i in range(len(df)):\n",
    "            v = max(0.1, df['speed'].iloc[i])\n",
    "            Î¸ = np.arctan(df['gradient'].iloc[i]) if abs(df['gradient'].iloc[i]) < 1 else 0\n",
    "            \n",
    "            F_roll = Cr * mass * g * np.cos(Î¸)\n",
    "            F_aero = 0.5 * rho * Cd * A * v**2\n",
    "            F_grad = mass * g * np.sin(Î¸)\n",
    "            F_acc = mass * df['acceleration'].iloc[i]\n",
    "            \n",
    "            F_total = F_roll + F_aero + F_grad + F_acc\n",
    "            F_traction = max(F_total, 0)\n",
    "            power_W[i] = F_traction * v\n",
    "        \n",
    "        # è®¡ç®—èƒ½è€— - ä½¿ç”¨ç›¸å¯¹æ—¶é—´\n",
    "        if len(df) > 1:\n",
    "            dt = df['relative_time_s'].diff().fillna(1.0)\n",
    "            dt = np.clip(dt, 0.01, 10.0)  # é™åˆ¶æ—¶é—´é—´éš”\n",
    "        else:\n",
    "            dt = np.array([1.0])\n",
    "        \n",
    "        df['energy_J'] = power_W * dt.values\n",
    "        \n",
    "        return power_W\n",
    "    \n",
    "    def cluster_driving_behaviors(self):\n",
    "        \"\"\"é©¾é©¶è¡Œä¸ºèšç±» - æ”¹è¿›ç‰ˆ\"\"\"\n",
    "        logger.info(\"Clustering driving behaviors with improved classification\")\n",
    "        \n",
    "        if self.processed_data is None or self.processed_data.empty:\n",
    "            logger.error(\"No processed data available for clustering\")\n",
    "            return {}, pd.DataFrame(), np.array([])\n",
    "        \n",
    "        data = self.processed_data.copy()\n",
    "        \n",
    "        # ç¡®ä¿æ‰€éœ€åˆ—å­˜åœ¨\n",
    "        required_cols = self.config['clustering']['features'] + ['energy_J']\n",
    "        for col in required_cols:\n",
    "            if col not in data.columns:\n",
    "                data[col] = 0.0\n",
    "        \n",
    "        print(f\"\\n=== é©¾é©¶è¡Œä¸ºèšç±» ===\")\n",
    "        for col in self.config['clustering']['features']:\n",
    "            if col in data.columns:\n",
    "                print(f\"{col}: {data[col].min():.3f} - {data[col].max():.3f} (å‡å€¼: {data[col].mean():.3f})\")\n",
    "        \n",
    "        # K-Meansèšç±»\n",
    "        feats = self.config['clustering']['features']\n",
    "        X = data[feats].fillna(0)\n",
    "        \n",
    "        # æ•°æ®æ ‡å‡†åŒ–\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        # PCAé™ç»´\n",
    "        try:\n",
    "            pca = PCA(n_components=2)\n",
    "            X_pca = pca.fit_transform(X_scaled)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"PCA failed: {e}\")\n",
    "            X_pca = X_scaled[:, :2] if X_scaled.shape[1] >= 2 else np.column_stack([X_scaled[:, 0], X_scaled[:, 0]])\n",
    "        \n",
    "        n_clusters = min(self.config['clustering']['n_clusters'], max(1, len(X) - 1))\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        clusters = kmeans.fit_predict(X_scaled)\n",
    "        \n",
    "        data['driver_cluster'] = clusters\n",
    "        \n",
    "        # ç”Ÿæˆèšç±»é…ç½®æ–‡ä»¶\n",
    "        cluster_profiles = {}\n",
    "        for cid in range(n_clusters):\n",
    "            data_c = data[data['driver_cluster'] == cid]\n",
    "            if data_c.empty:\n",
    "                cluster_profiles[cid] = {'size': 0, 'driver_type': 'unknown'}\n",
    "                continue\n",
    "            \n",
    "            # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡\n",
    "            if len(data_c) > 1:\n",
    "                dt = data_c['relative_time_s'].diff().fillna(1.0)\n",
    "                dt = np.clip(dt, 0.01, 10.0)\n",
    "                total_time = dt.sum()\n",
    "                total_distance = (data_c['speed'] * dt).sum() / 1000.0  # km\n",
    "            else:\n",
    "                total_time = 1.0\n",
    "                total_distance = 0.001\n",
    "            \n",
    "            total_energy = data_c['energy_J'].sum() / 3600000.0  # kWh (J->kWh)\n",
    "            energy_eff = total_energy / max(total_distance, 0.001) * 100  # kWh/100km\n",
    "            \n",
    "            profile = {\n",
    "                'size': len(data_c),\n",
    "                'avg_speed': data_c['speed'].mean(),\n",
    "                'std_speed': data_c['speed'].std(),\n",
    "                'avg_acceleration': data_c['acceleration'].mean(),\n",
    "                'std_acceleration': data_c['acceleration'].std(),\n",
    "                'avg_jerk': data_c['jerk'].mean(),\n",
    "                'std_jerk': data_c['jerk'].std(),\n",
    "                'avg_turning_rate': data_c['turning_rate'].mean(),\n",
    "                'std_turning_rate': data_c['turning_rate'].std(),\n",
    "                'energy_efficiency': energy_eff,\n",
    "                'total_time_s': total_time,\n",
    "                'total_distance_km': total_distance,\n",
    "            }\n",
    "            \n",
    "            # æ”¹è¿›çš„é©¾é©¶ç±»å‹åˆ†ç±» - é€‚åº”èµ·æ­¥é˜¶æ®µ\n",
    "            abs_avg_jerk = abs(profile['avg_jerk'])\n",
    "            abs_avg_acc = abs(profile['avg_acceleration'])\n",
    "            avg_speed = profile['avg_speed']\n",
    "            avg_turning = profile['avg_turning_rate']\n",
    "            \n",
    "            # é’ˆå¯¹èµ·æ­¥é˜¶æ®µçš„åˆ†ç±»é€»è¾‘\n",
    "            if abs_avg_jerk > 15.0 and abs_avg_acc > 2.0:\n",
    "                profile['driver_type'] = 'aggressive'\n",
    "            elif avg_turning > 0.15:\n",
    "                profile['driver_type'] = 'cornering'\n",
    "            elif avg_speed > 8.0 and abs_avg_acc > 1.0:  # è°ƒæ•´é€Ÿåº¦é˜ˆå€¼\n",
    "                profile['driver_type'] = 'dynamic'\n",
    "            elif avg_speed < 5.0 and abs_avg_jerk < 8.0:\n",
    "                profile['driver_type'] = 'cautious'\n",
    "            elif abs_avg_acc < 0.5 and abs_avg_jerk < 5.0:\n",
    "                profile['driver_type'] = 'efficient'\n",
    "            else:\n",
    "                profile['driver_type'] = 'normal'\n",
    "            \n",
    "            cluster_profiles[cid] = profile\n",
    "        \n",
    "        print(f\"èšç±»ç»“æœ:\")\n",
    "        for cid, profile in cluster_profiles.items():\n",
    "            print(f\"  Cluster {cid} ({profile['driver_type']}): {profile['size']} æ ·æœ¬\")\n",
    "            print(f\"    é€Ÿåº¦: {profile['avg_speed']*3.6:.1f} km/h, åŠ é€Ÿåº¦: {profile['avg_acceleration']:.2f} m/sÂ²\")\n",
    "            print(f\"    Jerk: {profile['avg_jerk']:.2f} m/sÂ³, èƒ½è€—: {profile['energy_efficiency']:.1f} kWh/100km\")\n",
    "        \n",
    "        # æ›´æ–°å¤„ç†åçš„æ•°æ®\n",
    "        self.processed_data = data\n",
    "        \n",
    "        # åœ¨ cluster_driving_behaviors() æ–¹æ³•çš„æœ€åï¼Œreturn è¯­å¥ä¹‹å‰æ·»åŠ ï¼š\n",
    "        print(f\"DEBUG: type of self.processed_data after clustering: {type(self.processed_data)}\")\n",
    "        print(f\"DEBUG: processed_data columns: {self.processed_data.columns.tolist() if isinstance(self.processed_data, pd.DataFrame) else 'Not DataFrame'}\")\n",
    "        \n",
    "        return cluster_profiles, X_pca, clusters\n",
    "    \n",
    "    def generate_comprehensive_report(self):\n",
    "        \"\"\"ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š\"\"\"\n",
    "        logger.info(\"Generating comprehensive analysis report\")\n",
    "        \n",
    "        if self.processed_data is None:\n",
    "            logger.error(\"No processed data available for report generation\")\n",
    "            return None\n",
    "        \n",
    "        # åŸºæœ¬ç»Ÿè®¡\n",
    "        data = self.processed_data\n",
    "        total_time = data['relative_time_s'].max()  # ä½¿ç”¨ç›¸å¯¹æ—¶é—´\n",
    "        total_distance = (data['speed'] * data['relative_time_s'].diff().fillna(1.0)).sum() / 1000.0  # km\n",
    "        avg_speed = data['speed'].mean() * 3.6  # km/h\n",
    "        max_speed = data['speed_kmh'].max()\n",
    "        \n",
    "        # æ€¥åˆ¹è½¦åˆ†æ\n",
    "        hard_brake_events = self.detect_hard_brake_events()\n",
    "        \n",
    "        # é©¾é©¶è¡Œä¸ºèšç±»\n",
    "        cluster_profiles, X_pca, clusters = self.cluster_driving_behaviors()\n",
    "\n",
    "        # ç¡®ä¿processed_dataè¢«æ­£ç¡®æ›´æ–°\n",
    "        if self.processed_data is not None:\n",
    "            data = self.processed_data  # ä½¿ç”¨æ›´æ–°åçš„æ•°æ®\n",
    "        else:\n",
    "            logger.error(\"processed_data is None after clustering\")\n",
    "            return None\n",
    "        \n",
    "        # ç”ŸæˆæŠ¥å‘Š\n",
    "        report = {\n",
    "            'metadata': {\n",
    "                'analysis_date': datetime.now().isoformat(),\n",
    "                'version': VERSION,\n",
    "                'data_points': len(data),\n",
    "                'duration_minutes': total_time / 60,\n",
    "                'total_distance_km': total_distance\n",
    "            },\n",
    "            'driving_summary': {\n",
    "                'max_speed_kmh': max_speed,\n",
    "                'avg_speed_kmh': avg_speed,\n",
    "                'total_hard_brakes': len(hard_brake_events),\n",
    "                'hard_brakes_per_hour': len(hard_brake_events) / max(total_time / 3600, 0.1)\n",
    "            },\n",
    "            'cluster_analysis': cluster_profiles,\n",
    "            'recommendations': self._generate_recommendations(cluster_profiles, hard_brake_events)\n",
    "        }\n",
    "        \n",
    "        self.results = {\n",
    "            'report': report,\n",
    "            'data': self.processed_data.copy(),\n",
    "            'hard_brake_events': hard_brake_events,\n",
    "            'cluster_profiles': cluster_profiles,\n",
    "            'pca_data': X_pca,\n",
    "            'clusters': clusters\n",
    "        }\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def _generate_recommendations(self, cluster_profiles, hard_brake_events):\n",
    "        \"\"\"ç”Ÿæˆé©¾é©¶å»ºè®®\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        # åŸºäºæ€¥åˆ¹è½¦çš„å»ºè®®\n",
    "        if len(hard_brake_events) > 3:  # é™ä½é˜ˆå€¼é€‚åº”èµ·æ­¥é˜¶æ®µ\n",
    "            recommendations.append({\n",
    "                'category': 'Safety',\n",
    "                'priority': 'High',\n",
    "                'message': 'Multiple hard braking events detected during startup phase. Consider smoother acceleration and anticipating traffic conditions.',\n",
    "                'impact': 'Reduces brake wear and improves passenger comfort'\n",
    "            })\n",
    "        elif len(hard_brake_events) == 0:\n",
    "            recommendations.append({\n",
    "                'category': 'Positive',\n",
    "                'priority': 'Low',\n",
    "                'message': 'Excellent! No hard braking events detected. Very smooth driving style.',\n",
    "                'impact': 'Optimal brake system preservation and passenger comfort'\n",
    "            })\n",
    "        \n",
    "        # åŸºäºèšç±»åˆ†æçš„å»ºè®®\n",
    "        for cid, profile in cluster_profiles.items():\n",
    "            if profile['driver_type'] == 'aggressive':\n",
    "                recommendations.append({\n",
    "                    'category': 'Efficiency',\n",
    "                    'priority': 'Medium',\n",
    "                    'message': f'Cluster {cid} shows aggressive driving patterns. Gentler acceleration can improve efficiency by 15-20%.',\n",
    "                    'impact': f'Current energy efficiency: {profile[\"energy_efficiency\"]:.1f} kWh/100km'\n",
    "                })\n",
    "            elif profile['driver_type'] == 'efficient':\n",
    "                recommendations.append({\n",
    "                    'category': 'Positive',\n",
    "                    'priority': 'Low',\n",
    "                    'message': f'Cluster {cid} demonstrates efficient driving behavior. Excellent energy management!',\n",
    "                    'impact': f'Outstanding energy efficiency: {profile[\"energy_efficiency\"]:.1f} kWh/100km'\n",
    "                })\n",
    "            elif profile['driver_type'] == 'cautious':\n",
    "                recommendations.append({\n",
    "                    'category': 'Performance',\n",
    "                    'priority': 'Low',\n",
    "                    'message': f'Cluster {cid} shows very cautious driving. Consider slightly more dynamic acceleration when safe.',\n",
    "                    'impact': 'May improve traffic flow while maintaining safety'\n",
    "                })\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def visualize_results(self, save_plots=True):\n",
    "        if not self.results:\n",
    "            logger.error(\"No results available for visualization\")\n",
    "            return\n",
    "        \n",
    "        # è°ƒè¯•ï¼šæ£€æŸ¥æ•°æ®ç±»å‹\n",
    "        print(f\"DEBUG: self.results keys: {list(self.results.keys())}\")\n",
    "        print(f\"DEBUG: type of self.results['data']: {type(self.results['data'])}\")\n",
    "        print(f\"DEBUG: type of self.processed_data: {type(self.processed_data)}\")\n",
    "        \n",
    "        # ç›´æ¥ä½¿ç”¨ processed_data\n",
    "        data = self.processed_data\n",
    "        if data is None or not isinstance(data, pd.DataFrame):\n",
    "            logger.error(f\"Invalid processed_data type: {type(data)}\")\n",
    "            return\n",
    "        \n",
    "        hard_brake_events = self.results['hard_brake_events']\n",
    "        cluster_profiles = self.results['cluster_profiles']\n",
    "        \n",
    "        # åˆ›å»ºç»¼åˆä»ªè¡¨æ¿\n",
    "        fig = plt.figure(figsize=(20, 16))\n",
    "        \n",
    "        # 1. é€Ÿåº¦æ—¶é—´æ›²çº¿ï¼ˆä½¿ç”¨ç›¸å¯¹æ—¶é—´ï¼‰\n",
    "        ax1 = plt.subplot(3, 3, 1)\n",
    "        time_minutes = data['relative_time_s'] / 60\n",
    "        \n",
    "        plt.plot(time_minutes, data['speed_kmh'], 'b-', alpha=0.7, linewidth=2, label='Speed (km/h)')\n",
    "        \n",
    "        if not hard_brake_events.empty:\n",
    "            brake_times = hard_brake_events['relative_time_s'] / 60\n",
    "            plt.scatter(brake_times, hard_brake_events['speed_kmh'], \n",
    "                       color='red', marker='X', s=100, zorder=5, \n",
    "                       label=f'Hard Brakes ({len(hard_brake_events)})')\n",
    "            \n",
    "            # æ·»åŠ æ€¥åˆ¹è½¦æ ‡æ³¨\n",
    "            for i, (idx, event) in enumerate(hard_brake_events.iterrows()):\n",
    "                plt.annotate(f'Brake {i+1}', \n",
    "                           xy=(event['relative_time_s']/60, event['speed_kmh']),\n",
    "                           xytext=(10, 20), textcoords='offset points',\n",
    "                           bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.8),\n",
    "                           arrowprops=dict(arrowstyle='->', color='red'))\n",
    "        \n",
    "        plt.title('Speed Profile with Hard Brake Events\\n(Startup Phase Analysis)')\n",
    "        plt.xlabel('Time (minutes)')\n",
    "        plt.ylabel('Speed (km/h)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. é©¾é©¶è¡Œä¸ºèšç±»PCAè§†å›¾\n",
    "        ax2 = plt.subplot(3, 3, 2)\n",
    "        scatter = plt.scatter(self.results['pca_data'][:, 0], self.results['pca_data'][:, 1], \n",
    "                             c=self.results['clusters'], cmap='viridis', alpha=0.7, s=30)\n",
    "        plt.title('Driver Behavior Clusters\\n(PCA Visualization)')\n",
    "        plt.xlabel('PCA Component 1')\n",
    "        plt.ylabel('PCA Component 2')\n",
    "        plt.colorbar(scatter, label='Cluster')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. åŠ é€Ÿåº¦åˆ†å¸ƒ\n",
    "        ax3 = plt.subplot(3, 3, 3)\n",
    "        colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown']\n",
    "        for cluster in range(len(cluster_profiles)):\n",
    "            cluster_data = data[data['driver_cluster'] == cluster]\n",
    "            if not cluster_data.empty and 'acceleration' in cluster_data.columns:\n",
    "                plt.hist(cluster_data['acceleration'], bins=15, alpha=0.6, \n",
    "                        label=f'Cluster {cluster}', density=True, \n",
    "                        color=colors[cluster % len(colors)])\n",
    "        plt.title('Acceleration Distribution by Cluster\\n(Startup Phase)')\n",
    "        plt.xlabel('Acceleration (m/sÂ²)')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Jerkåˆ†å¸ƒ\n",
    "        ax4 = plt.subplot(3, 3, 4)\n",
    "        for cluster in range(len(cluster_profiles)):\n",
    "            cluster_data = data[data['driver_cluster'] == cluster]\n",
    "            if not cluster_data.empty and 'jerk' in cluster_data.columns:\n",
    "                plt.hist(cluster_data['jerk'], bins=15, alpha=0.6, \n",
    "                        label=f'Cluster {cluster}', density=True,\n",
    "                        color=colors[cluster % len(colors)])\n",
    "        plt.title('Jerk Distribution by Cluster\\n(Instantaneous Values)')\n",
    "        plt.xlabel('Jerk (m/sÂ³)')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 5. é©¾é©¶ç±»å‹åˆ†å¸ƒ\n",
    "        ax5 = plt.subplot(3, 3, 5)\n",
    "        driver_types = [cluster_profiles[cid]['driver_type'] for cid in cluster_profiles.keys()]\n",
    "        type_counts = {}\n",
    "        for dtype in driver_types:\n",
    "            type_counts[dtype] = type_counts.get(dtype, 0) + 1\n",
    "        \n",
    "        colors_pie = {'aggressive': 'red', 'dynamic': 'orange', 'cornering': 'purple', \n",
    "                      'efficient': 'green', 'cautious': 'blue', 'normal': 'cyan', 'unknown': 'gray'}\n",
    "        pie_colors = [colors_pie.get(dtype, 'gray') for dtype in type_counts.keys()]\n",
    "        \n",
    "        plt.pie(type_counts.values(), labels=type_counts.keys(), colors=pie_colors,\n",
    "                autopct='%1.1f%%', startangle=90)\n",
    "        plt.title('Driver Type Distribution\\n(Startup Phase)')\n",
    "        \n",
    "        # 6. èƒ½è€—æ•ˆç‡å¯¹æ¯”\n",
    "        ax6 = plt.subplot(3, 3, 6)\n",
    "        cluster_ids = list(cluster_profiles.keys())\n",
    "        energy_effs = [cluster_profiles[cid]['energy_efficiency'] for cid in cluster_ids]\n",
    "        driver_types_list = [cluster_profiles[cid]['driver_type'] for cid in cluster_ids]\n",
    "        \n",
    "        bar_colors = [colors_pie.get(dtype, 'gray') for dtype in driver_types_list]\n",
    "        bars = plt.bar(range(len(cluster_ids)), energy_effs, color=bar_colors, alpha=0.8)\n",
    "        plt.title('Energy Efficiency by Cluster\\n(Startup Phase)')\n",
    "        plt.xlabel('Cluster')\n",
    "        plt.ylabel('Energy Efficiency (kWh/100km)')\n",
    "        plt.xticks(range(len(cluster_ids)), [f'C{cid}\\n({dtype})' for cid, dtype in zip(cluster_ids, driver_types_list)])\n",
    "        \n",
    "        for bar, eff in zip(bars, energy_effs):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(energy_effs)*0.01, \n",
    "                    f'{eff:.1f}', ha='center', va='bottom')\n",
    "        \n",
    "        # 7. é€Ÿåº¦vsåŠ é€Ÿåº¦æ•£ç‚¹å›¾\n",
    "        ax7 = plt.subplot(3, 3, 7)\n",
    "        scatter = plt.scatter(data['speed_kmh'], data['acceleration'], \n",
    "                             c=data['driver_cluster'], cmap='viridis', alpha=0.6, s=20)\n",
    "        plt.title('Speed vs Acceleration\\n(Startup Phase)')\n",
    "        plt.xlabel('Speed (km/h)')\n",
    "        plt.ylabel('Acceleration (m/sÂ²)')\n",
    "        plt.colorbar(scatter, label='Cluster')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 8. æ—¶é—´åºåˆ—åŠ é€Ÿåº¦\n",
    "        ax8 = plt.subplot(3, 3, 8)\n",
    "        sample_size = min(200, len(data))\n",
    "        sample_data = data.head(sample_size)\n",
    "        sample_times = sample_data['relative_time_s'] / 60\n",
    "        \n",
    "        plt.plot(sample_times, sample_data['acceleration'], 'g-', alpha=0.7, linewidth=1)\n",
    "        plt.title(f'Acceleration Time Series\\n(First {sample_size} points)')\n",
    "        plt.xlabel('Time (minutes)')\n",
    "        plt.ylabel('Acceleration (m/sÂ²)')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 9. ç»¼åˆè¯„åˆ†ä»ªè¡¨ç›˜\n",
    "        ax9 = plt.subplot(3, 3, 9)\n",
    "        \n",
    "        # è®¡ç®—è¯„åˆ† - é€‚åº”èµ·æ­¥é˜¶æ®µ\n",
    "        total_events = len(hard_brake_events)\n",
    "        total_time_hours = data['relative_time_s'].max() / 3600\n",
    "        events_per_hour = total_events / max(total_time_hours, 0.1)\n",
    "        \n",
    "        avg_energy_eff = np.mean([p['energy_efficiency'] for p in cluster_profiles.values()])\n",
    "        \n",
    "        # è¯„åˆ†è®¡ç®—ï¼ˆé’ˆå¯¹èµ·æ­¥é˜¶æ®µè°ƒæ•´ï¼‰\n",
    "        safety_score = max(0, 100 - events_per_hour * 15)  # èµ·æ­¥é˜¶æ®µé™ä½æƒ©ç½š\n",
    "        efficiency_score = max(0, 100 - max(0, avg_energy_eff - 25) * 2)  # èµ·æ­¥é˜¶æ®µèƒ½è€—å¯èƒ½è¾ƒé«˜\n",
    "        smoothness_score = 100 - min(50, np.mean([abs(p['avg_jerk']) for p in cluster_profiles.values()]) * 2)\n",
    "        overall_score = (safety_score + efficiency_score + smoothness_score) / 3\n",
    "        \n",
    "        # ç»˜åˆ¶ä»ªè¡¨ç›˜\n",
    "        scores = [safety_score, efficiency_score, smoothness_score, overall_score]\n",
    "        labels = ['Safety', 'Efficiency', 'Smoothness', 'Overall']\n",
    "        colors_gauge = ['red', 'green', 'blue', 'purple']\n",
    "        \n",
    "        bars = plt.bar(labels, scores, color=colors_gauge, alpha=0.7)\n",
    "        plt.ylim(0, 100)\n",
    "        plt.title('Eco-Driving Score Dashboard\\n(Startup Phase)')\n",
    "        plt.ylabel('Score (0-100)')\n",
    "        \n",
    "        for bar, score in zip(bars, scores):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2, \n",
    "                    f'{score:.0f}', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_plots:\n",
    "            plt.savefig('eco_driving_startup_analysis.png', dpi=300, bbox_inches='tight')\n",
    "            logger.info(\"Saved startup phase analysis plot\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def save_results(self, output_dir='eco_driving_results'):\n",
    "        \"\"\"ä¿å­˜åˆ†æç»“æœ\"\"\"\n",
    "        if not self.results:\n",
    "            logger.error(\"No results to save\")\n",
    "            return False\n",
    "        \n",
    "        # åˆ›å»ºè¾“å‡ºç›®å½•\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            # ä¿å­˜ä¸»è¦æ•°æ®\n",
    "            self.results['data'].to_csv(f'{output_dir}/processed_data.csv', index=False)\n",
    "            \n",
    "            if not self.results['hard_brake_events'].empty:\n",
    "                self.results['hard_brake_events'].to_csv(f'{output_dir}/hard_brake_events.csv', index=False)\n",
    "            \n",
    "            # ä¿å­˜JSONæŠ¥å‘Š\n",
    "            with open(f'{output_dir}/analysis_report.json', 'w', encoding='utf-8') as f:\n",
    "                json.dump(self.results['report'], f, indent=2, ensure_ascii=False, default=str)\n",
    "            \n",
    "            # ä¿å­˜æ–‡æœ¬æŠ¥å‘Š\n",
    "            self._save_text_report(f'{output_dir}/eco_driving_report.txt')\n",
    "            \n",
    "            logger.info(f\"Results saved to {output_dir}/\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving results: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def _save_text_report(self, filepath):\n",
    "        \"\"\"ä¿å­˜è¯¦ç»†æ–‡æœ¬æŠ¥å‘Š\"\"\"\n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            report = self.results['report']\n",
    "            cluster_profiles = self.results['cluster_profiles']\n",
    "            hard_brake_events = self.results['hard_brake_events']\n",
    "            \n",
    "            f.write(\"=\" * 80 + \"\\n\")\n",
    "            f.write(\"ECO-DRIVING ANALYSIS REPORT - STARTUP PHASE\\n\")\n",
    "            f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "            \n",
    "            # åŸºæœ¬ä¿¡æ¯\n",
    "            f.write(f\"Analysis Date: {report['metadata']['analysis_date']}\\n\")\n",
    "            f.write(f\"System Version: {report['metadata']['version']} (Microsecond Precision)\\n\")\n",
    "            f.write(f\"Data Points: {report['metadata']['data_points']}\\n\")\n",
    "            f.write(f\"Duration: {report['metadata']['duration_minutes']:.1f} minutes\\n\")\n",
    "            f.write(f\"Total Distance: {report['metadata']['total_distance_km']:.3f} km\\n\\n\")\n",
    "            \n",
    "            # é©¾é©¶æ‘˜è¦\n",
    "            f.write(\"DRIVING SUMMARY (STARTUP PHASE):\\n\")\n",
    "            f.write(\"-\" * 40 + \"\\n\")\n",
    "            f.write(f\"Maximum Speed: {report['driving_summary']['max_speed_kmh']:.1f} km/h\\n\")\n",
    "            f.write(f\"Average Speed: {report['driving_summary']['avg_speed_kmh']:.1f} km/h\\n\")\n",
    "            f.write(f\"Total Hard Brakes: {report['driving_summary']['total_hard_brakes']}\\n\")\n",
    "            f.write(f\"Hard Brakes per Hour: {report['driving_summary']['hard_brakes_per_hour']:.1f}\\n\\n\")\n",
    "            \n",
    "            # èšç±»åˆ†æ\n",
    "            f.write(\"DRIVER BEHAVIOR CLUSTERS (STARTUP PHASE):\\n\")\n",
    "            f.write(\"-\" * 40 + \"\\n\")\n",
    "            for cid, profile in cluster_profiles.items():\n",
    "                f.write(f\"\\nCluster {cid} - {profile['driver_type'].upper()}:\\n\")\n",
    "                f.write(f\"  Sample Size: {profile['size']} points\\n\")\n",
    "                f.write(f\"  Average Speed: {profile['avg_speed']*3.6:.1f} km/h\\n\")\n",
    "                f.write(f\"  Average Acceleration: {profile['avg_acceleration']:.3f} m/sÂ²\\n\")\n",
    "                f.write(f\"  Average Jerk: {profile['avg_jerk']:.3f} m/sÂ³ (instantaneous)\\n\")\n",
    "                f.write(f\"  Average Turning Rate: {profile['avg_turning_rate']:.3f} rad/s\\n\")\n",
    "                f.write(f\"  Energy Efficiency: {profile['energy_efficiency']:.2f} kWh/100km\\n\")\n",
    "                f.write(f\"  Total Distance: {profile['total_distance_km']:.4f} km\\n\")\n",
    "                f.write(f\"  Total Time: {profile['total_time_s']:.1f} seconds\\n\")\n",
    "            \n",
    "            # æ€¥åˆ¹è½¦è¯¦æƒ…\n",
    "            f.write(f\"\\nHARD BRAKE EVENTS DETAIL:\\n\")\n",
    "            f.write(\"-\" * 40 + \"\\n\")\n",
    "            if not hard_brake_events.empty:\n",
    "                for i, (idx, event) in enumerate(hard_brake_events.iterrows()):\n",
    "                    time_min = event['relative_time_s'] / 60\n",
    "                    f.write(f\"  Event {i+1}: {time_min:.1f} min - Speed: {event['speed_kmh']:.1f} km/h, \"\n",
    "                           f\"Acceleration: {event['acceleration']:.2f} m/sÂ²\\n\")\n",
    "            else:\n",
    "                f.write(\"  No hard brake events detected - Excellent smooth driving!\\n\")\n",
    "            \n",
    "            # å»ºè®®\n",
    "            f.write(f\"\\nRECOMMENDATIONS:\\n\")\n",
    "            f.write(\"-\" * 40 + \"\\n\")\n",
    "            for i, rec in enumerate(report['recommendations']):\n",
    "                f.write(f\"{i+1}. [{rec['category']} - {rec['priority']}] {rec['message']}\\n\")\n",
    "                f.write(f\"   Impact: {rec['impact']}\\n\\n\")\n",
    "            \n",
    "            # æŠ€æœ¯è¯´æ˜\n",
    "            f.write(\"TECHNICAL NOTES:\\n\")\n",
    "            f.write(\"-\" * 20 + \"\\n\")\n",
    "            f.write(\"â€¢ Timestamp precision: Microseconds\\n\")\n",
    "            f.write(\"â€¢ Analysis focus: Vehicle startup phase\\n\")\n",
    "            f.write(\"â€¢ Jerk calculation: Instantaneous values preserved\\n\")\n",
    "            f.write(\"â€¢ Acceleration: Real GPS-based calculation with synthetic backup\\n\")\n",
    "            f.write(\"â€¢ Energy model: Adapted for low-speed urban driving\\n\")\n",
    "\n",
    "# ä¸»è¦ä½¿ç”¨æ¥å£\n",
    "def run_complete_eco_driving_analysis(data_file, config=None):\n",
    "    \"\"\"\n",
    "    è¿è¡Œå®Œæ•´çš„ç”Ÿæ€é©¾é©¶åˆ†æ - å¾®ç§’æ—¶é—´æˆ³ç‰ˆæœ¬\n",
    "    \n",
    "    Args:\n",
    "        data_file: ä¼ æ„Ÿå™¨æ•°æ®æ–‡ä»¶è·¯å¾„\n",
    "        config: å¯é€‰é…ç½®å­—å…¸\n",
    "    \n",
    "    Returns:\n",
    "        EcoDrivingAnalyzerå®ä¾‹ï¼ŒåŒ…å«æ‰€æœ‰åˆ†æç»“æœ\n",
    "    \"\"\"\n",
    "    print(\"ğŸš— Starting Complete Eco-Driving Analysis System v2.1\")\n",
    "    print(\"ğŸ“ Optimized for startup phase analysis with microsecond precision\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # åˆå§‹åŒ–åˆ†æå™¨\n",
    "    analyzer = EcoDrivingAnalyzer(config)\n",
    "    \n",
    "    # 1. è§£ææ•°æ®\n",
    "    print(\"ğŸ“Š Step 1: Parsing sensor data (microsecond timestamps)...\")\n",
    "    if not analyzer.parse_sensor_data(data_file):\n",
    "        print(\"âŒ Failed to parse sensor data\")\n",
    "        return None\n",
    "    \n",
    "    # 2. æå–ç‰¹å¾\n",
    "    print(\"ğŸ” Step 2: Extracting driving features...\")\n",
    "    if not analyzer.extract_driving_features():\n",
    "        print(\"âŒ Failed to extract features\")\n",
    "        return None\n",
    "    \n",
    "    # 3. æ•°æ®åŒæ­¥å’Œèƒ½è€—å»ºæ¨¡\n",
    "    print(\"âš¡ Step 3: Synchronizing data and modeling energy...\")\n",
    "    combined_data = analyzer.synchronize_and_model_energy()\n",
    "    if combined_data.empty:\n",
    "        print(\"âŒ Failed to synchronize data\")\n",
    "        return None\n",
    "    \n",
    "    # 4. ç”Ÿæˆç»¼åˆæŠ¥å‘Š\n",
    "    print(\"ğŸ“‹ Step 4: Generating comprehensive report...\")\n",
    "    report = analyzer.generate_comprehensive_report()\n",
    "    if not report:\n",
    "        print(\"âŒ Failed to generate report\")\n",
    "        return None\n",
    "    \n",
    "    # 5. å¯è§†åŒ–ç»“æœ\n",
    "    print(\"ğŸ“ˆ Step 5: Creating visualizations...\")\n",
    "    analyzer.visualize_results()\n",
    "    \n",
    "    # 6. ä¿å­˜ç»“æœ\n",
    "    print(\"ğŸ’¾ Step 6: Saving results...\")\n",
    "    analyzer.save_results()\n",
    "    \n",
    "    print(\"\\nâœ… Analysis Complete!\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # æ‰“å°å…³é”®ç»“æœ\n",
    "    print(f\"ğŸ“Š Key Results (Startup Phase):\")\n",
    "    print(f\"  â€¢ Duration: {report['metadata']['duration_minutes']:.1f} minutes\")\n",
    "    print(f\"  â€¢ Max Speed: {report['driving_summary']['max_speed_kmh']:.1f} km/h\")\n",
    "    print(f\"  â€¢ Hard Brake Events: {len(analyzer.results['hard_brake_events'])}\")\n",
    "    print(f\"  â€¢ Driver Behavior Types: {len(set(p['driver_type'] for p in analyzer.results['cluster_profiles'].values()))}\")\n",
    "    print(f\"  â€¢ Average Energy Efficiency: {np.mean([p['energy_efficiency'] for p in analyzer.results['cluster_profiles'].values()]):.1f} kWh/100km\")\n",
    "    \n",
    "    return analyzer\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•ä»£ç \n",
    "if __name__ == \"__main__\":\n",
    "    # é’ˆå¯¹èµ·æ­¥é˜¶æ®µä¼˜åŒ–çš„é…ç½®\n",
    "    startup_config = {\n",
    "        'hard_brake_threshold': -2.0,  # é™ä½é˜ˆå€¼é€‚åº”èµ·æ­¥\n",
    "        'speed_drop_threshold': 6,     # é™ä½é€Ÿåº¦ä¸‹é™é˜ˆå€¼\n",
    "        'min_brake_speed': 8,          # é™ä½æœ€å°åˆ¹è½¦é€Ÿåº¦\n",
    "        'energy_model': {\n",
    "            'vehicle_mass': 1600,      # ç´§å‡‘å‹è½¿è½¦\n",
    "            'drag_coefficient': 0.26,  # ç°ä»£è½¿è½¦ä¼˜ç§€é£é˜»\n",
    "            'frontal_area': 2.2,       # ç´§å‡‘å‹è½¦è¿é£é¢ç§¯\n",
    "            'rolling_resistance': 0.010 # ä¼˜è´¨è½®èƒ\n",
    "        },\n",
    "        'clustering': {\n",
    "            'n_clusters': 3,\n",
    "            'features': ['speed', 'acceleration', 'jerk', 'turning_rate']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # è¿è¡Œåˆ†æ\n",
    "    data_file = \"ts_1747221572.csv\"  # ä½ çš„æ•°æ®æ–‡ä»¶\n",
    "    \n",
    "    print(\"ğŸš€ Running Eco-Driving Analysis - Startup Phase Optimized\")\n",
    "    print(f\"ğŸ“ Data file: {data_file}\")\n",
    "    print(\"ğŸ”§ Configuration: Optimized for startup phase with microsecond precision\")\n",
    "    print(\"â±ï¸  Expected analysis time: 30-60 seconds\")\n",
    "    print()\n",
    "    \n",
    "    # æ‰§è¡Œå®Œæ•´åˆ†æ\n",
    "    analyzer = run_complete_eco_driving_analysis(data_file, startup_config)\n",
    "    \n",
    "    if analyzer:\n",
    "        print(\"\\nğŸ‰ Analysis completed successfully!\")\n",
    "        print(\"ğŸ“ Check 'eco_driving_results' folder for detailed outputs:\")\n",
    "        print(\"   â€¢ processed_data.csv - Complete processed dataset\")\n",
    "        print(\"   â€¢ hard_brake_events.csv - Hard brake event details\") \n",
    "        print(\"   â€¢ analysis_report.json - Structured analysis results\")\n",
    "        print(\"   â€¢ eco_driving_report.txt - Human-readable report\")\n",
    "        print(\"   â€¢ eco_driving_startup_analysis.png - Comprehensive visualization\")\n",
    "        \n",
    "        # æ˜¾ç¤ºå¿«é€Ÿæ‘˜è¦\n",
    "        print(f\"\\nğŸ” Quick Analysis Summary:\")\n",
    "        report = analyzer.results['report']\n",
    "        print(f\"  â±ï¸  Duration: {report['metadata']['duration_minutes']:.1f} minutes\")\n",
    "        print(f\"  ğŸš— Max Speed: {report['driving_summary']['max_speed_kmh']:.1f} km/h\")\n",
    "        print(f\"  ğŸš¨ Hard Brakes: {report['driving_summary']['total_hard_brakes']}\")\n",
    "        \n",
    "        # æ˜¾ç¤ºé©¾é©¶ç±»å‹åˆ†å¸ƒ\n",
    "        cluster_types = [p['driver_type'] for p in analyzer.results['cluster_profiles'].values()]\n",
    "        type_counts = {}\n",
    "        for dtype in cluster_types:\n",
    "            type_counts[dtype] = type_counts.get(dtype, 0) + 1\n",
    "        \n",
    "        print(f\"  ğŸ¯ Driving Types Found: {', '.join(type_counts.keys())}\")\n",
    "        \n",
    "        # æ˜¾ç¤ºä¸»è¦å»ºè®®\n",
    "        print(f\"\\nğŸ’¡ Top Recommendations:\")\n",
    "        for i, rec in enumerate(report['recommendations'][:2]):\n",
    "            print(f\"  {i+1}. [{rec['priority']}] {rec['message'][:80]}...\")\n",
    "        \n",
    "        # æ•°æ®è´¨é‡æŠ¥å‘Š\n",
    "        data = analyzer.results['data']\n",
    "        print(f\"\\nğŸ“Š Data Quality Summary:\")\n",
    "        print(f\"  â€¢ Total Data Points: {len(data):,}\")\n",
    "        print(f\"  â€¢ GPS-Accelerometer Sync: {(data['sync_error_us'] < 100000).sum()}/{len(data)} points < 100ms\")\n",
    "        print(f\"  â€¢ Acceleration Range: {data['acceleration'].min():.2f} to {data['acceleration'].max():.2f} m/sÂ²\")\n",
    "        print(f\"  â€¢ Jerk Range: {data['jerk'].min():.2f} to {data['jerk'].max():.2f} m/sÂ³\")\n",
    "        print(f\"  â€¢ Speed Range: {data['speed_kmh'].min():.1f} to {data['speed_kmh'].max():.1f} km/h\")\n",
    "        \n",
    "        # æ€§èƒ½è¯„ä¼°\n",
    "        if 'hard_brake_events' in analyzer.results:\n",
    "            safety_rating = \"ğŸŸ¢ Excellent\" if len(analyzer.results['hard_brake_events']) == 0 else \\\n",
    "                           \"ğŸŸ¡ Good\" if len(analyzer.results['hard_brake_events']) <= 2 else \\\n",
    "                           \"ğŸŸ  Needs Improvement\"\n",
    "            print(f\"  â€¢ Safety Rating: {safety_rating}\")\n",
    "        \n",
    "        avg_energy = np.mean([p['energy_efficiency'] for p in analyzer.results['cluster_profiles'].values()])\n",
    "        efficiency_rating = \"ğŸŸ¢ Excellent\" if avg_energy < 20 else \\\n",
    "                           \"ğŸŸ¡ Good\" if avg_energy < 30 else \\\n",
    "                           \"ğŸŸ  Moderate\"\n",
    "        print(f\"  â€¢ Efficiency Rating: {efficiency_rating} ({avg_energy:.1f} kWh/100km)\")\n",
    "        \n",
    "        print(f\"\\nâœ¨ Analysis Features Highlights:\")\n",
    "        print(f\"  âœ… Microsecond timestamp precision\")\n",
    "        print(f\"  âœ… Real GPS-based acceleration calculation\")\n",
    "        print(f\"  âœ… Instantaneous jerk values (not averaged)\")\n",
    "        print(f\"  âœ… Startup phase optimized thresholds\")\n",
    "        print(f\"  âœ… Intelligent hard brake detection\")\n",
    "        print(f\"  âœ… Multi-dimensional driver behavior clustering\")\n",
    "        print(f\"  âœ… Personalized driving recommendations\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ Analysis failed. Please check your data file and try again.\")\n",
    "        print(\"\\nğŸ”§ Troubleshooting Tips:\")\n",
    "        print(\"  â€¢ Ensure your CSV file exists and is readable\")\n",
    "        print(\"  â€¢ Check that the data format matches the expected structure:\")\n",
    "        print(\"    - GPS: 0,timestamp,lat,lon,alt,speed_kmh,satellites\")\n",
    "        print(\"    - Accelerometer: 1,timestamp,timestamp_us,x,y,z\")\n",
    "        print(\"    - Gyroscope: 2,timestamp,timestamp_us,x,y,z\")\n",
    "        print(\"  â€¢ Verify that timestamps are in microseconds\")\n",
    "        print(\"  â€¢ Make sure the file contains sufficient data points\")\n",
    "\n",
    "# è¾…åŠ©å‡½æ•°ï¼šæ•°æ®æ ¼å¼éªŒè¯\n",
    "def validate_data_format(file_path, sample_lines=10):\n",
    "    \"\"\"\n",
    "    éªŒè¯æ•°æ®æ–‡ä»¶æ ¼å¼\n",
    "    Args:\n",
    "        file_path: æ•°æ®æ–‡ä»¶è·¯å¾„\n",
    "        sample_lines: æ£€æŸ¥çš„æ ·æœ¬è¡Œæ•°\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ” Validating data format for {file_path}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = [f.readline().strip() for _ in range(sample_lines)]\n",
    "        \n",
    "        format_counts = {'gps': 0, 'acc': 0, 'gyro': 0, 'rot': 0, 'unknown': 0}\n",
    "        \n",
    "        print(\"Sample data lines:\")\n",
    "        for i, line in enumerate(lines):\n",
    "            if not line:\n",
    "                continue\n",
    "            values = line.split(',')\n",
    "            print(f\"  {i+1}: {line}\")\n",
    "            \n",
    "            if len(values) >= 2:\n",
    "                try:\n",
    "                    data_type = int(values[0])\n",
    "                    if data_type == 0:\n",
    "                        format_counts['gps'] += 1\n",
    "                        if len(values) < 6:\n",
    "                            print(f\"    âš ï¸  GPS line has only {len(values)} columns, expected 6+\")\n",
    "                    elif data_type == 1:\n",
    "                        format_counts['acc'] += 1\n",
    "                        if len(values) < 5:\n",
    "                            print(f\"    âš ï¸  Accelerometer line has only {len(values)} columns, expected 5+\")\n",
    "                    elif data_type == 2:\n",
    "                        format_counts['gyro'] += 1\n",
    "                        if len(values) < 5:\n",
    "                            print(f\"    âš ï¸  Gyroscope line has only {len(values)} columns, expected 5+\")\n",
    "                    elif data_type == 3:\n",
    "                        format_counts['rot'] += 1\n",
    "                        if len(values) < 6:\n",
    "                            print(f\"    âš ï¸  Rotation line has only {len(values)} columns, expected 6+\")\n",
    "                    else:\n",
    "                        format_counts['unknown'] += 1\n",
    "                        print(f\"    âš ï¸  Unknown data type: {data_type}\")\n",
    "                except ValueError:\n",
    "                    format_counts['unknown'] += 1\n",
    "                    print(f\"    âŒ Invalid data type: {values[0]}\")\n",
    "        \n",
    "        print(f\"\\nData type distribution in sample:\")\n",
    "        for dtype, count in format_counts.items():\n",
    "            if count > 0:\n",
    "                print(f\"  {dtype}: {count} lines\")\n",
    "        \n",
    "        # éªŒè¯æ—¶é—´æˆ³\n",
    "        if format_counts['gps'] > 0 or format_counts['acc'] > 0:\n",
    "            print(f\"\\nTimestamp validation:\")\n",
    "            for line in lines:\n",
    "                if not line:\n",
    "                    continue\n",
    "                values = line.split(',')\n",
    "                if len(values) >= 2:\n",
    "                    try:\n",
    "                        timestamp = int(values[1])\n",
    "                        if timestamp > 1000000000000:  # å¾®ç§’çº§æ—¶é—´æˆ³\n",
    "                            print(f\"  âœ… Microsecond timestamp detected: {timestamp}\")\n",
    "                        elif timestamp > 1000000000:   # æ¯«ç§’çº§æ—¶é—´æˆ³\n",
    "                            print(f\"  âš ï¸  Millisecond timestamp detected: {timestamp}\")\n",
    "                        else:\n",
    "                            print(f\"  âŒ Unusual timestamp: {timestamp}\")\n",
    "                        break\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error validating file: {e}\")\n",
    "        return False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
