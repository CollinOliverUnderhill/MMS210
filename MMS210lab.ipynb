{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88ebdb41",
   "metadata": {},
   "source": [
    "# Lab work: Eco-driving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211650fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.signal import savgol_filter\n",
    "import math\n",
    "from geopy.distance import geodesic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8444d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(file_path):\n",
    "    gps_data = []\n",
    "    acc_data = []\n",
    "    gyro_data = []\n",
    "    rot_data = []\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(file_path, header=None)\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            values = row.tolist()\n",
    "            \n",
    "            if len(values) < 2:\n",
    "                continue\n",
    "                \n",
    "            data_type = int(values[0])\n",
    "            \n",
    "            if data_type == 0:  \n",
    "                if len(values) >= 7:\n",
    "                    gps_data.append({\n",
    "                        'timestamp': int(values[1]),\n",
    "                        'latitude': float(values[2]),\n",
    "                        'longitude': float(values[3]),\n",
    "                        'altitude': float(values[4]),\n",
    "                        'speed': float(values[5]),\n",
    "                        'satellites': int(values[6])\n",
    "                    })\n",
    "            elif data_type == 1: \n",
    "                if len(values) >= 6:\n",
    "                    acc_data.append({\n",
    "                        'timestamp': int(values[1]),\n",
    "                        'timestamp_us': int(values[2]),\n",
    "                        'x': float(values[3]),\n",
    "                        'y': float(values[4]),\n",
    "                        'z': float(values[5])\n",
    "                    })\n",
    "            elif data_type == 2:  \n",
    "                if len(values) >= 6:\n",
    "                    gyro_data.append({\n",
    "                        'timestamp': int(values[1]),\n",
    "                        'timestamp_us': int(values[2]),\n",
    "                        'x': float(values[3]),\n",
    "                        'y': float(values[4]),\n",
    "                        'z': float(values[5])\n",
    "                    })\n",
    "            elif data_type == 3:  \n",
    "                if len(values) >= 7:\n",
    "                    rot_data.append({\n",
    "                        'timestamp': int(values[1]),\n",
    "                        'timestamp_us': int(values[2]),\n",
    "                        'i': float(values[3]),\n",
    "                        'j': float(values[4]),\n",
    "                        'k': float(values[5]),\n",
    "                        'real': float(values[6])\n",
    "                    })\n",
    "                elif len(values) >= 6:\n",
    "                    rot_data.append({\n",
    "                        'timestamp': int(values[1]),\n",
    "                        'timestamp_us': int(values[2]),\n",
    "                        'i': float(values[3]),\n",
    "                        'j': float(values[4]),\n",
    "                        'k': float(values[5]),\n",
    "                        'real': 0.0\n",
    "                    })\n",
    "        \n",
    "        return {\n",
    "            'gps': pd.DataFrame(gps_data) if gps_data else pd.DataFrame(),\n",
    "            'acc': pd.DataFrame(acc_data) if acc_data else pd.DataFrame(),\n",
    "            'gyro': pd.DataFrame(gyro_data) if gyro_data else pd.DataFrame(),\n",
    "            'rot': pd.DataFrame(rot_data) if rot_data else pd.DataFrame()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing CSV file: {e}\")\n",
    "        return {\n",
    "            'gps': pd.DataFrame(),\n",
    "            'acc': pd.DataFrame(),\n",
    "            'gyro': pd.DataFrame(),\n",
    "            'rot': pd.DataFrame()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7653331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data_dict):\n",
    "    features = {}\n",
    "    \n",
    "    if not data_dict['gps'].empty:\n",
    "        gps_df = data_dict['gps']\n",
    "        \n",
    "        distances = []\n",
    "        gradients = []\n",
    "        \n",
    "        for i in range(1, len(gps_df)):\n",
    "            point1 = (gps_df['latitude'].iloc[i-1], gps_df['longitude'].iloc[i-1])\n",
    "            point2 = (gps_df['latitude'].iloc[i], gps_df['longitude'].iloc[i])\n",
    "            distance = geodesic(point1, point2).meters\n",
    "            distances.append(distance)\n",
    "            \n",
    "            if distance > 0:\n",
    "                elevation_change = gps_df['altitude'].iloc[i] - gps_df['altitude'].iloc[i-1]\n",
    "                gradient = elevation_change / distance\n",
    "            else:\n",
    "                gradient = 0\n",
    "            gradients.append(gradient)\n",
    "        \n",
    "        gps_df.loc[1:, 'distance'] = distances\n",
    "        gps_df.loc[1:, 'gradient'] = gradients\n",
    "        gps_df.loc[0, 'distance'] = 0\n",
    "        gps_df.loc[0, 'gradient'] = 0\n",
    "        \n",
    "        gps_df['speed_change'] = gps_df['speed'].diff().fillna(0)\n",
    "        gps_df['acceleration'] = gps_df['speed_change'] / (gps_df['timestamp'].diff().fillna(1) / 1000)\n",
    "        \n",
    "        features['route'] = gps_df\n",
    "    \n",
    "    if not data_dict['acc'].empty:\n",
    "        acc_df = data_dict['acc']\n",
    "        \n",
    "        acc_df['magnitude'] = np.sqrt(acc_df['x']**2 + acc_df['y']**2 + acc_df['z']**2)\n",
    "        \n",
    "        acc_df['jerk'] = acc_df['magnitude'].diff().fillna(0) / (acc_df['timestamp'].diff().fillna(1) / 1000)\n",
    "        \n",
    "        acc_df['jerk_smooth'] = savgol_filter(acc_df['jerk'], \n",
    "                                              min(21, len(acc_df) - (len(acc_df) % 2) - 1), \n",
    "                                              3)\n",
    "        \n",
    "        features['behavior'] = acc_df\n",
    "    \n",
    "    if not data_dict['gyro'].empty:\n",
    "        gyro_df = data_dict['gyro']\n",
    "        \n",
    "        gyro_df['turning_rate'] = np.abs(gyro_df['z'])\n",
    "        \n",
    "        features['turning'] = gyro_df\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffba752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_energy_consumption(features):\n",
    "    \n",
    "    if 'route' in features and 'behavior' in features:\n",
    "        route_times = features['route']['timestamp'].values\n",
    "        behavior_times = features['behavior']['timestamp'].values\n",
    "        \n",
    "        combined_data = []\n",
    "        \n",
    "        for i, row in features['route'].iterrows():\n",
    "            gps_time = row['timestamp']\n",
    "            closest_acc_idx = np.argmin(np.abs(behavior_times - gps_time))\n",
    "            \n",
    "            entry = {\n",
    "                'timestamp': gps_time,\n",
    "                'speed': row['speed'],\n",
    "                'acceleration': row['acceleration'],\n",
    "                'gradient': row['gradient'],\n",
    "                'acc_x': features['behavior']['x'].iloc[closest_acc_idx],\n",
    "                'acc_y': features['behavior']['y'].iloc[closest_acc_idx],\n",
    "                'acc_z': features['behavior']['z'].iloc[closest_acc_idx],\n",
    "                'jerk': features['behavior']['jerk_smooth'].iloc[closest_acc_idx]\n",
    "            }\n",
    "            \n",
    "            if 'turning' in features:\n",
    "                turning_times = features['turning']['timestamp'].values\n",
    "                closest_turn_idx = np.argmin(np.abs(turning_times - gps_time))\n",
    "                entry['turning_rate'] = features['turning']['turning_rate'].iloc[closest_turn_idx]\n",
    "            else:\n",
    "                entry['turning_rate'] = 0\n",
    "                \n",
    "            combined_data.append(entry)\n",
    "        \n",
    "        combined_df = pd.DataFrame(combined_data)\n",
    "        \n",
    "        combined_df['energy_factor'] = calculate_energy_factors(combined_df)\n",
    "        \n",
    "        return combined_df\n",
    "    \n",
    "    return pd.DataFrame()\n",
    "\n",
    "def calculate_energy_factors(df):\n",
    "    mass = 1500\n",
    "    g = 9.81\n",
    "    rho = 1.225\n",
    "    Cd = 0.3\n",
    "    A = 2.2\n",
    "    Cr = 0.013\n",
    "    \n",
    "    energy_factors = np.zeros(len(df))\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        speed = df['speed'].iloc[i] / 3.6\n",
    "        \n",
    "        gradient_angle = np.arctan(df['gradient'].iloc[i])\n",
    "        rolling_resistance = Cr * mass * g * np.cos(gradient_angle)\n",
    "        \n",
    "        aero_drag = 0.5 * rho * Cd * A * speed**2\n",
    "        \n",
    "        gradient_resistance = mass * g * np.sin(gradient_angle)\n",
    "        \n",
    "        acceleration_resistance = mass * df['acceleration'].iloc[i]\n",
    "        \n",
    "        total_resistance = rolling_resistance + aero_drag + gradient_resistance + acceleration_resistance\n",
    "        \n",
    "        energy_factors[i] = total_resistance * speed\n",
    "    \n",
    "    energy_factors = energy_factors - np.min(energy_factors)\n",
    "    \n",
    "    return energy_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c413b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_driving_behaviors(combined_data, n_clusters=3):\n",
    "    \n",
    "    features = ['speed', 'acceleration', 'jerk', 'turning_rate']\n",
    "    X = combined_data[features]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    combined_data['driver_cluster'] = clusters\n",
    "    \n",
    "    cluster_profiles = {}\n",
    "    for cluster in range(n_clusters):\n",
    "        cluster_data = combined_data[combined_data['driver_cluster'] == cluster]\n",
    "        \n",
    "        profile = {\n",
    "            'avg_speed': cluster_data['speed'].mean(),\n",
    "            'avg_acceleration': cluster_data['acceleration'].mean(),\n",
    "            'avg_jerk': cluster_data['jerk'].mean(),\n",
    "            'avg_turning_rate': cluster_data['turning_rate'].mean(),\n",
    "            'energy_efficiency': cluster_data['energy_factor'].mean()\n",
    "        }\n",
    "        \n",
    "        cluster_profiles[cluster] = profile\n",
    "    \n",
    "    return combined_data, cluster_profiles, X_pca, clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef30bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def develop_control_strategy(combined_data, cluster_profiles):\n",
    "    \n",
    "    features = ['speed', 'acceleration', 'gradient', 'turning_rate', 'driver_cluster']\n",
    "    X = pd.get_dummies(combined_data[features], columns=['driver_cluster'])\n",
    "    y = combined_data['energy_factor']\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    feature_importance = dict(zip(X.columns, model.feature_importances_))\n",
    "    \n",
    "    control_strategies = {}\n",
    "    \n",
    "    for cluster, profile in cluster_profiles.items():\n",
    "        if profile['avg_jerk'] > 0.5:\n",
    "            strategy = {\n",
    "                'acceleration_smoothing': True,\n",
    "                'smooth_factor': min(1.0, profile['avg_jerk'] / 2),\n",
    "                'anticipation_distance': 100 + (profile['avg_speed'] * 5),\n",
    "                'eco_mode_bias': 0.7\n",
    "            }\n",
    "        elif profile['avg_acceleration'] > 1.0:\n",
    "            strategy = {\n",
    "                'acceleration_smoothing': True,\n",
    "                'smooth_factor': 0.4,\n",
    "                'anticipation_distance': 80 + (profile['avg_speed'] * 3),\n",
    "                'eco_mode_bias': 0.8\n",
    "            }\n",
    "        elif profile['avg_turning_rate'] > 0.3:\n",
    "            strategy = {\n",
    "                'acceleration_smoothing': False,\n",
    "                'smooth_factor': 0.2,\n",
    "                'anticipation_distance': 120 + (profile['avg_speed'] * 4),\n",
    "                'eco_mode_bias': 0.5\n",
    "            }\n",
    "        else:\n",
    "            strategy = {\n",
    "                'acceleration_smoothing': False,\n",
    "                'smooth_factor': 0.1,\n",
    "                'anticipation_distance': 60 + (profile['avg_speed'] * 2),\n",
    "                'eco_mode_bias': 0.3\n",
    "            }\n",
    "        \n",
    "        control_strategies[cluster] = strategy\n",
    "    \n",
    "    return model, feature_importance, control_strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130f19b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "def run_eco_driving_analysis(data_file):\n",
    "    data_dict = parse_data(data_file)\n",
    "    \n",
    "    features = extract_features(data_dict)\n",
    "    \n",
    "    combined_data = model_energy_consumption(features)\n",
    "    \n",
    "    if combined_data.empty:\n",
    "        return \"Insufficient data for analysis\"\n",
    "    \n",
    "    n_clusters = 3\n",
    "    clustered_data, cluster_profiles, X_pca, clusters = cluster_driving_behaviors(combined_data, n_clusters)\n",
    "    \n",
    "    model, feature_importance, control_strategies = develop_control_strategy(clustered_data, cluster_profiles)\n",
    "    \n",
    "    results = {\n",
    "        'data': clustered_data,\n",
    "        'cluster_profiles': cluster_profiles,\n",
    "        'pca_data': X_pca,\n",
    "        'clusters': clusters,\n",
    "        'energy_model': model,\n",
    "        'feature_importance': feature_importance,\n",
    "        'control_strategies': control_strategies\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caff1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization function\n",
    "def visualize_results(results):\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    scatter = plt.scatter(results['pca_data'][:, 0], results['pca_data'][:, 1], \n",
    "                         c=results['clusters'], cmap='viridis', alpha=0.8)\n",
    "    plt.title('Driver Behavior Clusters')\n",
    "    plt.xlabel('PCA Component 1')\n",
    "    plt.ylabel('PCA Component 2')\n",
    "    plt.colorbar(scatter, label='Cluster')\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    cluster_energy = results['data'].groupby('driver_cluster')['energy_factor'].mean()\n",
    "    cluster_energy.plot(kind='bar', color='teal')\n",
    "    plt.title('Average Energy Consumption by Driver Cluster')\n",
    "    plt.xlabel('Driver Cluster')\n",
    "    plt.ylabel('Energy Factor')\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': list(results['feature_importance'].keys()),\n",
    "        'Importance': list(results['feature_importance'].values())\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    importance_df.plot(x='Feature', y='Importance', kind='bar', color='coral')\n",
    "    plt.title('Feature Importance for Energy Consumption')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.scatter(results['data']['timestamp'], results['data']['energy_factor'], \n",
    "               c=results['data']['driver_cluster'], cmap='viridis', alpha=0.7)\n",
    "    plt.title('Energy Consumption Over Time')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Energy Factor')\n",
    "    plt.colorbar(label='Driver Cluster')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('eco_driving_results.png')\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    strategies = results['control_strategies']\n",
    "    clusters = list(strategies.keys())\n",
    "    \n",
    "    metrics = ['smooth_factor', 'eco_mode_bias']\n",
    "    for i, metric in enumerate(metrics):\n",
    "        values = [strategies[c][metric] for c in clusters]\n",
    "        plt.subplot(1, 2, i+1)\n",
    "        plt.bar(clusters, values, color='darkgreen')\n",
    "        plt.title(f'Control Strategy: {metric}')\n",
    "        plt.xlabel('Driver Cluster')\n",
    "        plt.ylabel('Value')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('control_strategies.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2c1bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation method\n",
    "class AdaptiveEcoDrivingController:\n",
    "    def __init__(self, energy_model, control_strategies):\n",
    "        self.energy_model = energy_model\n",
    "        self.control_strategies = control_strategies\n",
    "        self.current_cluster = None\n",
    "        self.driver_history = []\n",
    "        self.strategy = None\n",
    "    \n",
    "    def update_driver_profile(self, recent_driving_data):\n",
    "        features = ['speed', 'acceleration', 'jerk', 'turning_rate']\n",
    "        X = recent_driving_data[features]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=len(self.control_strategies), random_state=42)\n",
    "        kmeans.fit(X_scaled)\n",
    "        \n",
    "        clusters = kmeans.predict(X_scaled)\n",
    "        self.current_cluster = np.bincount(clusters).argmax()\n",
    "        \n",
    "        self.strategy = self.control_strategies[self.current_cluster]\n",
    "        \n",
    "        return self.current_cluster\n",
    "    def recommend_actions(self, current_state):\n",
    "        if self.strategy is None:\n",
    "            return None\n",
    "        \n",
    "        state = {\n",
    "            'speed': current_state.get('speed', 0),\n",
    "            'gradient': current_state.get('gradient', 0),\n",
    "            'turning_rate': current_state.get('turning_rate', 0),\n",
    "            'acceleration': current_state.get('acceleration', 0)\n",
    "        }\n",
    "        \n",
    "        actions = {}\n",
    "        \n",
    "        target_acceleration = state['acceleration']\n",
    "        if self.strategy['acceleration_smoothing']:\n",
    "            if target_acceleration > 0:\n",
    "                target_acceleration *= (1 - self.strategy['smooth_factor'])\n",
    "        \n",
    "        actions['target_acceleration'] = target_acceleration\n",
    "        \n",
    "        if state['gradient'] > 0.03:\n",
    "            actions['speed_adjustment'] = -max(0, state['speed'] * 0.1 * self.strategy['eco_mode_bias'])\n",
    "        elif state['gradient'] < -0.03:\n",
    "            actions['speed_adjustment'] = min(5, state['speed'] * 0.05 * (1 - self.strategy['eco_mode_bias']))\n",
    "        else:\n",
    "            actions['speed_adjustment'] = 0\n",
    "        \n",
    "        if state['turning_rate'] > 0.2:\n",
    "            actions['speed_adjustment'] -= state['turning_rate'] * 5 * self.strategy['smooth_factor']\n",
    "        \n",
    "        base_energy = self.predict_energy_consumption(state)\n",
    "        adjusted_state = state.copy()\n",
    "        adjusted_state['acceleration'] = target_acceleration\n",
    "        adjusted_state['speed'] += actions['speed_adjustment']\n",
    "        adjusted_energy = self.predict_energy_consumption(adjusted_state)\n",
    "        \n",
    "        actions['expected_energy_saving'] = max(0, base_energy - adjusted_energy)\n",
    "        \n",
    "        return actions\n",
    "    \n",
    "    def predict_energy_consumption(self, state):\n",
    "        X = pd.DataFrame([state])\n",
    "        \n",
    "        for i in range(len(self.control_strategies)):\n",
    "            X[f'driver_cluster_{i}'] = 1 if i == self.current_cluster else 0\n",
    "        \n",
    "        energy = self.energy_model.predict(X)[0]\n",
    "        \n",
    "        return energy\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_file = \"sensor_data.txt\"\n",
    "    \n",
    "    results = run_eco_driving_analysis(data_file)\n",
    "    \n",
    "    visualize_results(results)\n",
    "    \n",
    "    controller = AdaptiveEcoDrivingController(\n",
    "        results['energy_model'],\n",
    "        results['control_strategies']\n",
    "    )\n",
    "    \n",
    "    sample_state = {\n",
    "        'speed': 60,\n",
    "        'gradient': 0.02,\n",
    "        'turning_rate': 0.1,\n",
    "        'acceleration': 1.2\n",
    "    }\n",
    "    \n",
    "    sample_recent_data = results['data'].tail(100)\n",
    "    driver_cluster = controller.update_driver_profile(sample_recent_data)\n",
    "    \n",
    "    actions = controller.recommend_actions(sample_state)\n",
    "    \n",
    "    print(f\"Driver Cluster: {driver_cluster}\")\n",
    "    print(f\"Recommended Actions: {actions}\")\n",
    "    \n",
    "    results['data'].to_csv('eco_driving_data.csv', index=False)\n",
    "    \n",
    "    with open('cluster_profiles.txt', 'w') as f:\n",
    "        for cluster, profile in results['cluster_profiles'].items():\n",
    "            f.write(f\"Cluster {cluster}:\\n\")\n",
    "            for key, value in profile.items():\n",
    "                f.write(f\"  {key}: {value:.4f}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "    \n",
    "    with open('control_strategies.txt', 'w') as f:\n",
    "        for cluster, strategy in results['control_strategies'].items():\n",
    "            f.write(f\"Cluster {cluster}:\\n\")\n",
    "            for key, value in strategy.items():\n",
    "                f.write(f\"  {key}: {value}\\n\")\n",
    "            f.write(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
