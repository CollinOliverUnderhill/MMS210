{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27315b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 15:22:06,499 - INFO - EcoDrivingAnalyzer v2.1 initialized (microsecond timestamps)\n",
      "2025-05-27 15:22:06,499 - INFO - Parsing sensor data from ts_1747221572.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Running Eco-Driving Analysis - Startup Phase Optimized\n",
      "📁 Data file: ts_1747221572.csv\n",
      "🔧 Configuration: Optimized for startup phase with microsecond precision\n",
      "⏱️  Expected analysis time: 30-60 seconds\n",
      "\n",
      "🚗 Starting Complete Eco-Driving Analysis System v2.1\n",
      "📍 Optimized for startup phase analysis with microsecond precision\n",
      "======================================================================\n",
      "📊 Step 1: Parsing sensor data (microsecond timestamps)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 15:22:06,978 - INFO - Parsed 100000 lines from ts_1747221572.csv\n",
      "2025-05-27 15:22:07,134 - INFO - Extracting driving features with microsecond precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GPS数据解析 ===\n",
      "GPS原始行数: 667\n",
      "样本数据: ['0', '1747221671', '57.687946', '11.980719', '56.200001', '2.857636', '12']\n",
      "GPS数据质量检查:\n",
      "  数据点数: 667\n",
      "  时间跨度: 0.0 秒 (0.0 分钟)\n",
      "  速度范围: 0.0 - 91.8 km/h\n",
      "  位置变化: 纬度 0.038410°, 经度 0.017737°\n",
      "\n",
      "=== 加速度传感器数据解析 ===\n",
      "加速度原始行数: 84489\n",
      "样本数据: ['1', '1747221671', '3809', '-1.800781', '-0.957031', '9.539062']\n",
      "加速度数据质量检查:\n",
      "  数据点数: 84489\n",
      "  时间跨度: 1.0 秒\n",
      "  原始加速度最大值: 14.90\n",
      "\n",
      "=== 陀螺仪数据解析 ===\n",
      "  数据点数: 12051\n",
      "  Z轴角速度范围: -0.529 - 0.596 rad/s\n",
      "🔍 Step 2: Extracting driving features...\n",
      "\n",
      "=== GPS特征提取 ===\n",
      "GPS加速度计算结果:\n",
      "  非零值: 0/667 (0.0%)\n",
      "  范围: 0.000 - 0.000 m/s²\n",
      "  平均: 0.000 m/s²\n",
      "  标准差: 0.000 m/s²\n",
      "⚠️  GPS加速度计算异常，使用改进的合成方法...\n",
      "  合成加速度范围: -12.000 - 12.000 m/s²\n",
      "\n",
      "=== 加速度传感器特征提取 ===\n",
      "原始加速度数据统计:\n",
      "  X: -5.055 - 2.758\n",
      "  Y: -5.785 - 4.367\n",
      "  Z: 3.523 - 14.902\n",
      "Magnitude统计: 4.599 - 14.913\n",
      "Magnitude变化统计: -5.348178 - 5.949456\n",
      "时间间隔统计: 0.000000 - 0.000221 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 15:22:07,509 - INFO - Synchronizing data and modeling energy consumption (microsecond precision)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jerk计算结果:\n",
      "  原始范围: -500.000 - 500.000 m/s³\n",
      "  平滑后范围: 0.000 - 0.000 m/s³\n",
      "  非零值: 96/84489\n",
      "  99%分位数: ±0.000 m/s³\n",
      "\n",
      "=== 陀螺仪特征提取 ===\n",
      "陀螺仪原始数据:\n",
      "  X: -0.264 - 0.252\n",
      "  Y: -0.387 - 0.428\n",
      "  Z: -0.529 - 0.596\n",
      "转向率统计: 0.000 - 0.596\n",
      "⚡ Step 3: Synchronizing data and modeling energy...\n",
      "\n",
      "=== 数据同步 (微秒精度) ===\n",
      "GPS数据点: 667\n",
      "加速度数据点: 84489\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'EcoDrivingAnalyzer' object has no attribute '_calculate_energy_consumption'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1246\u001b[0m\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;66;03m# 执行完整分析\u001b[39;00m\n\u001b[0;32m-> 1246\u001b[0m analyzer \u001b[38;5;241m=\u001b[39m run_complete_eco_driving_analysis(data_file, startup_config)\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m analyzer:\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m🎉 Analysis completed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[24], line 1184\u001b[0m, in \u001b[0;36mrun_complete_eco_driving_analysis\u001b[0;34m(data_file, config)\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;66;03m# 3. 数据同步和能耗建模\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⚡ Step 3: Synchronizing data and modeling energy...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1184\u001b[0m combined_data \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39msynchronize_and_model_energy()\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m combined_data\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m❌ Failed to synchronize data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[24], line 598\u001b[0m, in \u001b[0;36mEcoDrivingAnalyzer.synchronize_and_model_energy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    595\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(combined_data)\n\u001b[1;32m    597\u001b[0m \u001b[38;5;66;03m# 能耗计算\u001b[39;00m\n\u001b[0;32m--> 598\u001b[0m combined_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergy_factor\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_energy_consumption(combined_df)\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m同步结果:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  完美匹配: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mperfect_matches\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EcoDrivingAnalyzer' object has no attribute '_calculate_energy_consumption'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.signal import savgol_filter\n",
    "from geopy.distance import geodesic\n",
    "import warnings\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "# 配置日志和常量\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 系统常量 - 修正为微秒\n",
    "GRAVITY = 9.81\n",
    "MAX_TIME_DIFF = 5000000  # 最大时间差（微秒）5秒\n",
    "MAX_SAMPLES = 100000     # 增加最大样本数\n",
    "VERSION = \"2.1\"\n",
    "\n",
    "class EcoDrivingAnalyzer:\n",
    "    \"\"\"生态驾驶分析主类 - 微秒时间戳版本\"\"\"\n",
    "    \n",
    "    def __init__(self, config=None):\n",
    "        \"\"\"初始化分析器\"\"\"\n",
    "        self.config = config or self._default_config()\n",
    "        self.raw_data = {}\n",
    "        self.processed_data = None\n",
    "        self.features = {}\n",
    "        self.results = {}\n",
    "        self.time_offset = None  # 用于计算相对时间\n",
    "        \n",
    "        logger.info(f\"EcoDrivingAnalyzer v{VERSION} initialized (microsecond timestamps)\")\n",
    "    \n",
    "    def _default_config(self):\n",
    "        \"\"\"默认配置\"\"\"\n",
    "        return {\n",
    "            'hard_brake_threshold': -2.5,\n",
    "            'speed_drop_threshold': 8,\n",
    "            'min_brake_speed': 15,\n",
    "            'energy_model': {\n",
    "                'vehicle_mass': 1800,          # 更轻的乘用车\n",
    "                'drag_coefficient': 0.28,      # 现代轿车风阻系数\n",
    "                'frontal_area': 2.3,           # 现代轿车迎风面积\n",
    "                'rolling_resistance': 0.012    # 现代轮胎滚动阻力\n",
    "            },\n",
    "            'clustering': {\n",
    "                'n_clusters': 3,\n",
    "                'features': ['speed', 'acceleration', 'jerk', 'turning_rate']\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def parse_sensor_data(self, file_path):\n",
    "        \"\"\"解析传感器数据文件 - 修正微秒时间戳处理\"\"\"\n",
    "        logger.info(f\"Parsing sensor data from {file_path}\")\n",
    "        \n",
    "        gps_rows, acc_rows, gyro_rows, rot_rows = [], [], [], []\n",
    "        total_rows = 0\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, \"r\") as file:\n",
    "                for line_num, line in enumerate(file):\n",
    "                    values = line.strip().split(\",\")\n",
    "                    if len(values) < 2:\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        data_type = int(values[0])\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                    \n",
    "                    # 修正数据解析逻辑\n",
    "                    if data_type == 0 and len(values) >= 6:  # GPS数据\n",
    "                        gps_rows.append(values)\n",
    "                    elif data_type == 1 and len(values) >= 5:  # 加速度计数据\n",
    "                        acc_rows.append(values)\n",
    "                    elif data_type == 2 and len(values) >= 5:  # 陀螺仪数据\n",
    "                        gyro_rows.append(values)\n",
    "                    elif data_type == 3 and len(values) >= 6:  # 四元数数据\n",
    "                        rot_rows.append(values)\n",
    "                    \n",
    "                    total_rows += 1\n",
    "                    if total_rows >= MAX_SAMPLES:\n",
    "                        break\n",
    "            \n",
    "            logger.info(f\"Parsed {total_rows} lines from {file_path}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading file: {e}\")\n",
    "            return False\n",
    "        \n",
    "        # 处理GPS数据\n",
    "        if gps_rows:\n",
    "            print(f\"\\n=== GPS数据解析 ===\")\n",
    "            print(f\"GPS原始行数: {len(gps_rows)}\")\n",
    "            print(f\"样本数据: {gps_rows[0]}\")\n",
    "            \n",
    "            # 处理GPS数据格式：0,timestamp,lat,lon,alt,speed_kmh,satellites\n",
    "            gps_data = []\n",
    "            for row in gps_rows:\n",
    "                try:\n",
    "                    if len(row) >= 6:\n",
    "                        gps_data.append([\n",
    "                            int(row[0]),      # data_type\n",
    "                            int(row[1]),      # timestamp (微秒)\n",
    "                            float(row[2]),    # latitude\n",
    "                            float(row[3]),    # longitude\n",
    "                            float(row[4]),    # altitude\n",
    "                            float(row[5]),    # speed_kmh\n",
    "                            int(row[6]) if len(row) > 6 else 12  # satellites\n",
    "                        ])\n",
    "                except (ValueError, IndexError) as e:\n",
    "                    continue\n",
    "            \n",
    "            if gps_data:\n",
    "                gps_df = pd.DataFrame(gps_data, columns=[\n",
    "                    \"data_type\", \"timestamp\", \"latitude\", \"longitude\", \n",
    "                    \"altitude\", \"speed_kmh\", \"satellites\"\n",
    "                ])\n",
    "                \n",
    "                gps_df[\"speed_ms\"] = gps_df[\"speed_kmh\"] / 3.6\n",
    "                \n",
    "                # 设置时间偏移量\n",
    "                if self.time_offset is None:\n",
    "                    self.time_offset = gps_df['timestamp'].min()\n",
    "                \n",
    "                # 计算相对时间（秒）\n",
    "                gps_df['relative_time_s'] = (gps_df['timestamp'] - self.time_offset) / 1000000.0\n",
    "                \n",
    "                print(f\"GPS数据质量检查:\")\n",
    "                print(f\"  数据点数: {len(gps_df)}\")\n",
    "                print(f\"  时间跨度: {gps_df['relative_time_s'].max():.1f} 秒 ({gps_df['relative_time_s'].max()/60:.1f} 分钟)\")\n",
    "                print(f\"  速度范围: {gps_df['speed_kmh'].min():.1f} - {gps_df['speed_kmh'].max():.1f} km/h\")\n",
    "                print(f\"  位置变化: 纬度 {gps_df['latitude'].max()-gps_df['latitude'].min():.6f}°, 经度 {gps_df['longitude'].max()-gps_df['longitude'].min():.6f}°\")\n",
    "                \n",
    "                # 数据清洗\n",
    "                gps_df = gps_df[gps_df[\"speed_kmh\"] <= 200]\n",
    "                gps_df = gps_df[gps_df[\"latitude\"].between(-90, 90)]\n",
    "                gps_df = gps_df[gps_df[\"longitude\"].between(-180, 180)]\n",
    "                \n",
    "                self.raw_data['gps'] = gps_df\n",
    "        \n",
    "        # 处理加速度传感器数据\n",
    "        if acc_rows:\n",
    "            print(f\"\\n=== 加速度传感器数据解析 ===\")\n",
    "            print(f\"加速度原始行数: {len(acc_rows)}\")\n",
    "            print(f\"样本数据: {acc_rows[0]}\")\n",
    "            \n",
    "            # 处理加速度数据格式：1,timestamp,timestamp_us,x,y,z\n",
    "            acc_data = []\n",
    "            for row in acc_rows:\n",
    "                try:\n",
    "                    if len(row) >= 5:\n",
    "                        acc_data.append([\n",
    "                            int(row[0]),      # data_type\n",
    "                            int(row[1]),      # timestamp (微秒)\n",
    "                            int(row[2]),      # timestamp_us (额外的微秒)\n",
    "                            float(row[3]),    # x\n",
    "                            float(row[4]),    # y\n",
    "                            float(row[5]) if len(row) > 5 else 0.0  # z\n",
    "                        ])\n",
    "                except (ValueError, IndexError):\n",
    "                    continue\n",
    "            \n",
    "            if acc_data:\n",
    "                acc_df = pd.DataFrame(acc_data, columns=[\n",
    "                    \"data_type\", \"timestamp\", \"timestamp_us\", \"x\", \"y\", \"z\"\n",
    "                ])\n",
    "                \n",
    "                # 计算完整时间戳（主时间戳 + 微秒偏移）\n",
    "                acc_df['full_timestamp'] = acc_df['timestamp'] + acc_df['timestamp_us']\n",
    "                \n",
    "                if self.time_offset is None:\n",
    "                    self.time_offset = acc_df['full_timestamp'].min()\n",
    "                \n",
    "                acc_df['relative_time_s'] = (acc_df['full_timestamp'] - self.time_offset) / 1000000.0\n",
    "                \n",
    "                print(f\"加速度数据质量检查:\")\n",
    "                print(f\"  数据点数: {len(acc_df)}\")\n",
    "                print(f\"  时间跨度: {acc_df['relative_time_s'].max():.1f} 秒\")\n",
    "                \n",
    "                # 检查加速度范围和缩放\n",
    "                max_acc = max(acc_df['x'].abs().max(), acc_df['y'].abs().max(), acc_df['z'].abs().max())\n",
    "                print(f\"  原始加速度最大值: {max_acc:.2f}\")\n",
    "                \n",
    "                # 智能缩放 - 根据数据范围判断单位\n",
    "                if max_acc > 50:  # 如果数值很大，可能需要缩放\n",
    "                    if max_acc > 1000:\n",
    "                        scale_factor = 1000.0\n",
    "                        print(\"  检测到加速度单位可能是 mg，应用1000x缩放\")\n",
    "                    else:\n",
    "                        scale_factor = 10.0\n",
    "                        print(\"  检测到加速度单位异常，应用10x缩放\")\n",
    "                    \n",
    "                    acc_df[[\"x\", \"y\", \"z\"]] = acc_df[[\"x\", \"y\", \"z\"]] / scale_factor\n",
    "                    print(f\"  缩放后范围: {acc_df['x'].min():.2f} - {acc_df['x'].max():.2f}\")\n",
    "                \n",
    "                acc_df[\"magnitude\"] = np.sqrt(acc_df[\"x\"]**2 + acc_df[\"y\"]**2 + acc_df[\"z\"]**2)\n",
    "                self.raw_data['acc'] = acc_df\n",
    "        \n",
    "        # 处理陀螺仪数据\n",
    "        if gyro_rows:\n",
    "            print(f\"\\n=== 陀螺仪数据解析 ===\")\n",
    "            gyro_data = []\n",
    "            for row in gyro_rows:\n",
    "                try:\n",
    "                    if len(row) >= 5:\n",
    "                        gyro_data.append([\n",
    "                            int(row[0]),      # data_type\n",
    "                            int(row[1]),      # timestamp\n",
    "                            int(row[2]),      # timestamp_us\n",
    "                            float(row[3]),    # x\n",
    "                            float(row[4]),    # y\n",
    "                            float(row[5]) if len(row) > 5 else 0.0  # z\n",
    "                        ])\n",
    "                except (ValueError, IndexError):\n",
    "                    continue\n",
    "            \n",
    "            if gyro_data:\n",
    "                gyro_df = pd.DataFrame(gyro_data, columns=[\n",
    "                    \"data_type\", \"timestamp\", \"timestamp_us\", \"x\", \"y\", \"z\"\n",
    "                ])\n",
    "                gyro_df['full_timestamp'] = gyro_df['timestamp'] + gyro_df['timestamp_us']\n",
    "                \n",
    "                if self.time_offset is None:\n",
    "                    self.time_offset = gyro_df['full_timestamp'].min()\n",
    "                \n",
    "                gyro_df['relative_time_s'] = (gyro_df['full_timestamp'] - self.time_offset) / 1000000.0\n",
    "                gyro_df[\"turning_rate\"] = gyro_df[\"z\"].abs()\n",
    "                \n",
    "                print(f\"  数据点数: {len(gyro_df)}\")\n",
    "                print(f\"  Z轴角速度范围: {gyro_df['z'].min():.3f} - {gyro_df['z'].max():.3f} rad/s\")\n",
    "                \n",
    "                self.raw_data['gyro'] = gyro_df\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def extract_driving_features(self):\n",
    "        \"\"\"提取驾驶特征 - 修正时间处理和Jerk计算\"\"\"\n",
    "        logger.info(\"Extracting driving features with microsecond precision\")\n",
    "        \n",
    "        # GPS路线特征\n",
    "        if 'gps' in self.raw_data and not self.raw_data['gps'].empty:\n",
    "            gps_df = self.raw_data['gps'].copy().sort_values('timestamp').reset_index(drop=True)\n",
    "            \n",
    "            print(f\"\\n=== GPS特征提取 ===\")\n",
    "            \n",
    "            # 计算距离和坡度\n",
    "            distances, gradients = [], []\n",
    "            for i in range(1, len(gps_df)):\n",
    "                p1 = (gps_df[\"latitude\"].iloc[i-1], gps_df[\"longitude\"].iloc[i-1])\n",
    "                p2 = (gps_df[\"latitude\"].iloc[i], gps_df[\"longitude\"].iloc[i])\n",
    "                try:\n",
    "                    d = geodesic(p1, p2).meters\n",
    "                except Exception:\n",
    "                    d = 0\n",
    "                distances.append(d)\n",
    "                \n",
    "                alt_diff = gps_df[\"altitude\"].iloc[i] - gps_df[\"altitude\"].iloc[i-1]\n",
    "                gradient = alt_diff / d if d > 0.5 else 0  # 距离>0.5米才计算坡度\n",
    "                gradients.append(gradient)\n",
    "            \n",
    "            if distances:\n",
    "                gps_df.loc[1:, \"distance\"] = distances\n",
    "                gps_df.loc[1:, \"gradient\"] = gradients\n",
    "            gps_df[\"distance\"] = gps_df.get(\"distance\", 0).fillna(0)\n",
    "            gps_df[\"gradient\"] = gps_df.get(\"gradient\", 0).fillna(0)\n",
    "            \n",
    "            # 修正的加速度计算 - 使用微秒精度，放宽限制\n",
    "            dt_values = gps_df[\"timestamp\"].diff() / 1000000.0  # 转换为秒\n",
    "            speed_changes_ms = gps_df[\"speed_ms\"].diff()\n",
    "            \n",
    "            accelerations = []\n",
    "            for i in range(len(gps_df)):\n",
    "                if i == 0:\n",
    "                    accelerations.append(0.0)\n",
    "                else:\n",
    "                    dt = dt_values.iloc[i]\n",
    "                    speed_change = speed_changes_ms.iloc[i]\n",
    "                    \n",
    "                    # 修正时间范围检查，放宽加速度限制\n",
    "                    if 0.01 < dt < 300:  # 10ms 到 5分钟\n",
    "                        acc = speed_change / dt\n",
    "                        acc = max(-15, min(15, acc))  # 放宽加速度范围到±15 m/s²\n",
    "                        accelerations.append(acc)\n",
    "                    else:\n",
    "                        # 对于异常时间间隔，使用前一个加速度的衰减值\n",
    "                        if i > 1:\n",
    "                            accelerations.append(accelerations[-1] * 0.8)\n",
    "                        else:\n",
    "                            accelerations.append(0.0)\n",
    "            \n",
    "            gps_df[\"acceleration\"] = accelerations\n",
    "            \n",
    "            # 检查GPS加速度计算结果\n",
    "            acc_nonzero = (np.array(accelerations) != 0).sum()\n",
    "            acc_range = [min(accelerations), max(accelerations)]\n",
    "            \n",
    "            print(f\"GPS加速度计算结果:\")\n",
    "            print(f\"  非零值: {acc_nonzero}/{len(accelerations)} ({acc_nonzero/len(accelerations)*100:.1f}%)\")\n",
    "            print(f\"  范围: {acc_range[0]:.3f} - {acc_range[1]:.3f} m/s²\")\n",
    "            print(f\"  平均: {np.mean(accelerations):.3f} m/s²\")\n",
    "            print(f\"  标准差: {np.std(accelerations):.3f} m/s²\")\n",
    "            \n",
    "            # 如果GPS加速度仍然问题很大，使用改进的合成方法\n",
    "            if abs(max(accelerations)) < 0.01 or acc_nonzero < len(accelerations) * 0.1:\n",
    "                print(\"⚠️  GPS加速度计算异常，使用改进的合成方法...\")\n",
    "                \n",
    "                # 使用速度的变化趋势生成更真实的加速度\n",
    "                speed_smooth = gps_df['speed_ms'].rolling(window=3, center=True).mean().fillna(gps_df['speed_ms'])\n",
    "                speed_diff = speed_smooth.diff()\n",
    "                time_diff = gps_df['relative_time_s'].diff()\n",
    "                \n",
    "                synthetic_acc = []\n",
    "                for i in range(len(gps_df)):\n",
    "                    if i == 0:\n",
    "                        synthetic_acc.append(0.0)\n",
    "                    else:\n",
    "                        dt = time_diff.iloc[i]\n",
    "                        if dt > 0:\n",
    "                            acc = speed_diff.iloc[i] / dt\n",
    "                            acc = max(-12, min(12, acc))  # 合成加速度限制稍微严格一些\n",
    "                            synthetic_acc.append(acc)\n",
    "                        else:\n",
    "                            synthetic_acc.append(0.0)\n",
    "                \n",
    "                gps_df['acceleration'] = synthetic_acc\n",
    "                print(f\"  合成加速度范围: {min(synthetic_acc):.3f} - {max(synthetic_acc):.3f} m/s²\")\n",
    "            \n",
    "            self.features['route'] = gps_df\n",
    "        \n",
    "        # 加速度传感器特征 - 修正时间处理和Jerk计算\n",
    "        if 'acc' in self.raw_data and not self.raw_data['acc'].empty:\n",
    "            acc_df = self.raw_data['acc'].copy().sort_values('full_timestamp').reset_index(drop=True)\n",
    "            \n",
    "            print(f\"\\n=== 加速度传感器特征提取 ===\")\n",
    "            \n",
    "            # 重新计算magnitude，确保单位正确\n",
    "            print(f\"原始加速度数据统计:\")\n",
    "            print(f\"  X: {acc_df['x'].min():.3f} - {acc_df['x'].max():.3f}\")\n",
    "            print(f\"  Y: {acc_df['y'].min():.3f} - {acc_df['y'].max():.3f}\")\n",
    "            print(f\"  Z: {acc_df['z'].min():.3f} - {acc_df['z'].max():.3f}\")\n",
    "            \n",
    "            # 重新计算magnitude\n",
    "            acc_df[\"magnitude\"] = np.sqrt(acc_df[\"x\"]**2 + acc_df[\"y\"]**2 + acc_df[\"z\"]**2)\n",
    "            \n",
    "            # 计算Jerk（急动度）- 修正版本\n",
    "            dt_acc = acc_df[\"full_timestamp\"].diff() / 1000000.0  # 转换为秒\n",
    "            magnitude_changes = acc_df[\"magnitude\"].diff()\n",
    "\n",
    "            # 调试：检查magnitude变化\n",
    "            print(f\"Magnitude统计: {acc_df['magnitude'].min():.3f} - {acc_df['magnitude'].max():.3f}\")\n",
    "            print(f\"Magnitude变化统计: {magnitude_changes.min():.6f} - {magnitude_changes.max():.6f}\")\n",
    "            print(f\"时间间隔统计: {dt_acc.min():.6f} - {dt_acc.max():.6f} 秒\")\n",
    "            \n",
    "            # 初始化jerks列表\n",
    "            jerks = []\n",
    "            \n",
    "            for i in range(len(acc_df)):\n",
    "                if i == 0:\n",
    "                    jerks.append(0.0)\n",
    "                else:\n",
    "                    dt = dt_acc.iloc[i]\n",
    "                    mag_change = magnitude_changes.iloc[i]\n",
    "                    \n",
    "                    # 修正时间范围 - 加速度计采样频率更高\n",
    "                    if 0.0001 < dt < 1.0:  # 0.1ms 到 1秒，放宽时间范围\n",
    "                        jerk = mag_change / dt\n",
    "                        # 放宽jerk范围，允许更大的瞬时变化\n",
    "                        jerk = max(-500, min(500, jerk))  # 扩大jerk范围到±500\n",
    "                        jerks.append(jerk)\n",
    "                    else:\n",
    "                        # 对于异常时间间隔，使用0而不是跳过\n",
    "                        jerks.append(0.0)\n",
    "            \n",
    "            acc_df[\"jerk\"] = jerks\n",
    "            \n",
    "            # 改进的平滑处理 - 使用更保守的平滑\n",
    "            if len(acc_df) > 5:\n",
    "                # 使用更小的窗口保持瞬时特性\n",
    "                win = min(5, len(acc_df)//10*2+1)  # 减少窗口大小\n",
    "                if win >= 3:\n",
    "                    try:\n",
    "                        acc_df[\"jerk_smooth\"] = savgol_filter(acc_df[\"jerk\"], win, 1)\n",
    "                    except:\n",
    "                        # 如果平滑失败，使用简单的滑动平均\n",
    "                        acc_df[\"jerk_smooth\"] = acc_df[\"jerk\"].rolling(window=3, center=True).mean().fillna(acc_df[\"jerk\"])\n",
    "                else:\n",
    "                    acc_df[\"jerk_smooth\"] = acc_df[\"jerk\"]\n",
    "            else:\n",
    "                acc_df[\"jerk_smooth\"] = acc_df[\"jerk\"]\n",
    "            \n",
    "            # 去除极端异常值\n",
    "            jerk_p99 = np.percentile(np.abs(acc_df[\"jerk_smooth\"]), 99)\n",
    "            acc_df[\"jerk_smooth\"] = np.clip(acc_df[\"jerk_smooth\"], -jerk_p99, jerk_p99)\n",
    "            \n",
    "            print(f\"Jerk计算结果:\")\n",
    "            print(f\"  原始范围: {min(jerks):.3f} - {max(jerks):.3f} m/s³\")\n",
    "            print(f\"  平滑后范围: {acc_df['jerk_smooth'].min():.3f} - {acc_df['jerk_smooth'].max():.3f} m/s³\")\n",
    "            print(f\"  非零值: {(np.array(jerks) != 0).sum()}/{len(jerks)}\")\n",
    "            print(f\"  99%分位数: ±{jerk_p99:.3f} m/s³\")\n",
    "            \n",
    "            self.features['behavior'] = acc_df\n",
    "        \n",
    "        # 陀螺仪转向特征 - 修正计算\n",
    "        if 'gyro' in self.raw_data and not self.raw_data['gyro'].empty:\n",
    "            gyro_df = self.raw_data['gyro'].copy()\n",
    "            \n",
    "            print(f\"\\n=== 陀螺仪特征提取 ===\")\n",
    "            print(f\"陀螺仪原始数据:\")\n",
    "            print(f\"  X: {gyro_df['x'].min():.3f} - {gyro_df['x'].max():.3f}\")\n",
    "            print(f\"  Y: {gyro_df['y'].min():.3f} - {gyro_df['y'].max():.3f}\")\n",
    "            print(f\"  Z: {gyro_df['z'].min():.3f} - {gyro_df['z'].max():.3f}\")\n",
    "            \n",
    "            # 重新计算转向率 - 使用所有轴的信息\n",
    "            gyro_df[\"turning_rate\"] = np.sqrt(gyro_df[\"x\"]**2 + gyro_df[\"y\"]**2 + gyro_df[\"z\"]**2)\n",
    "            \n",
    "            print(f\"转向率统计: {gyro_df['turning_rate'].min():.3f} - {gyro_df['turning_rate'].max():.3f}\")\n",
    "            \n",
    "            self.features['turning'] = gyro_df\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def detect_hard_brake_events(self):\n",
    "        \"\"\"检测急刹车事件 - 修正版\"\"\"\n",
    "        logger.info(\"Detecting hard brake events with improved algorithm\")\n",
    "        \n",
    "        if 'route' not in self.features:\n",
    "            logger.warning(\"No route data available for hard brake detection\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        df = self.features['route'].copy()\n",
    "        \n",
    "        # 数据平滑\n",
    "        if len(df) > 5:\n",
    "            window_size = min(5, len(df) // 2 * 2 + 1)\n",
    "            df['speed_smooth'] = savgol_filter(df['speed_kmh'], window_size, 2)\n",
    "        else:\n",
    "            df['speed_smooth'] = df['speed_kmh']\n",
    "        \n",
    "        # 速度变化分析 - 使用相对时间\n",
    "        df['speed_change'] = df['speed_smooth'].diff()\n",
    "        time_diff_s = df['relative_time_s'].diff()\n",
    "        df['speed_change_rate'] = df['speed_change'] / time_diff_s\n",
    "        df['speed_change_pct'] = df['speed_change'] / (df['speed_smooth'].shift(1) + 1)\n",
    "        \n",
    "        # 针对低速场景调整的急刹车检测条件\n",
    "        conditions = [\n",
    "            # 条件1: 适应低速的绝对速度下降\n",
    "            (df['speed_change'] < -5) & (df['speed_smooth'] > 10),  # 降低速度阈值\n",
    "            \n",
    "            # 条件2: 相对速度变化\n",
    "            (df['speed_change_pct'] < -0.20) & (df['speed_smooth'] > 8),  # 提高相对变化敏感度\n",
    "            \n",
    "            # 条件3: 速度变化率（针对起步阶段）\n",
    "            (df['speed_change_rate'] < -8) & (df['speed_smooth'] > 5),  # 降低速度阈值\n",
    "        ]\n",
    "        \n",
    "        df['hard_brake_candidate'] = np.logical_or.reduce(conditions)\n",
    "        \n",
    "        # 速度峰值检测 - 针对低速优化\n",
    "        df['is_speed_peak'] = False\n",
    "        df['hard_brake_refined'] = False\n",
    "        \n",
    "        # 寻找局部速度峰值（降低阈值适应低速）\n",
    "        for i in range(2, len(df) - 2):\n",
    "            current_speed = df['speed_smooth'].iloc[i]\n",
    "            prev_speed = df['speed_smooth'].iloc[i-1]\n",
    "            next_speed = df['speed_smooth'].iloc[i+1]\n",
    "            \n",
    "            if (current_speed > prev_speed and current_speed > next_speed and current_speed > 8):  # 降低峰值阈值\n",
    "                df.loc[i, 'is_speed_peak'] = True\n",
    "        \n",
    "        # 在峰值后检测急刹车\n",
    "        for i in range(len(df)):\n",
    "            if df['is_speed_peak'].iloc[i]:\n",
    "                peak_speed = df['speed_smooth'].iloc[i]\n",
    "                \n",
    "                for j in range(i+1, min(i+6, len(df))):\n",
    "                    current_speed = df['speed_smooth'].iloc[j]\n",
    "                    speed_drop = peak_speed - current_speed\n",
    "                    time_span = df['relative_time_s'].iloc[j] - df['relative_time_s'].iloc[i]\n",
    "                    \n",
    "                    # 针对低速调整的急刹车条件\n",
    "                    if speed_drop > 8 and time_span < 5:  # 降低速度下降阈值\n",
    "                        df.loc[j, 'hard_brake_refined'] = True\n",
    "                        break\n",
    "        \n",
    "        # 最终急刹车事件\n",
    "        df['hard_brake_final'] = df['hard_brake_candidate'] | df['hard_brake_refined']\n",
    "        \n",
    "        # 去重处理\n",
    "        df['hard_brake_filtered'] = False\n",
    "        if df['hard_brake_final'].any():\n",
    "            brake_indices = df[df['hard_brake_final']].index\n",
    "            filtered_indices = [brake_indices[0]] if len(brake_indices) > 0 else []\n",
    "            \n",
    "            for i in range(1, len(brake_indices)):\n",
    "                time_gap = df['relative_time_s'].iloc[brake_indices[i]] - df['relative_time_s'].iloc[brake_indices[i-1]]\n",
    "                if time_gap > 2.0:  # 2秒间隔\n",
    "                    filtered_indices.append(brake_indices[i])\n",
    "            \n",
    "            if filtered_indices:\n",
    "                df.loc[filtered_indices, 'hard_brake_filtered'] = True\n",
    "        \n",
    "        hard_brake_events = df[df['hard_brake_filtered']]\n",
    "        \n",
    "        print(f\"\\n=== 急刹车检测结果 ===\")\n",
    "        print(f\"候选事件: {df['hard_brake_candidate'].sum()}\")\n",
    "        print(f\"精炼事件: {df['hard_brake_refined'].sum()}\")\n",
    "        print(f\"最终检测到: {len(hard_brake_events)} 个急刹车事件\")\n",
    "        \n",
    "        if not hard_brake_events.empty:\n",
    "            print(\"急刹车事件详情:\")\n",
    "            for i, (idx, event) in enumerate(hard_brake_events.iterrows()):\n",
    "                time_min = event['relative_time_s'] / 60\n",
    "                print(f\"  事件{i+1}: {time_min:.1f}分钟 - 速度: {event['speed_kmh']:.1f} km/h, 加速度: {event['acceleration']:.2f} m/s²\")\n",
    "        \n",
    "        # 更新路线数据\n",
    "        self.features['route'] = df\n",
    "        \n",
    "        return hard_brake_events\n",
    "    \n",
    "    def synchronize_and_model_energy(self):\n",
    "        \"\"\"数据同步和能耗建模 - 微秒精度版本\"\"\"\n",
    "        logger.info(\"Synchronizing data and modeling energy consumption (microsecond precision)\")\n",
    "        \n",
    "        if 'route' not in self.features or 'behavior' not in self.features:\n",
    "            logger.warning(\"Missing required data for energy modeling\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        route_df = self.features['route']\n",
    "        behavior_df = self.features['behavior']\n",
    "        \n",
    "        # 使用微秒时间戳进行同步\n",
    "        route_times = route_df['timestamp'].values\n",
    "        behavior_times = behavior_df['full_timestamp'].values\n",
    "        \n",
    "        print(f\"\\n=== 数据同步 (微秒精度) ===\")\n",
    "        print(f\"GPS数据点: {len(route_df)}\")\n",
    "        print(f\"加速度数据点: {len(behavior_df)}\")\n",
    "        \n",
    "        combined_data = []\n",
    "        sync_errors = 0\n",
    "        perfect_matches = 0\n",
    "        \n",
    "        for i, row in route_df.iterrows():\n",
    "            gps_time = row['timestamp']\n",
    "            time_diffs = np.abs(behavior_times - gps_time)\n",
    "            closest_acc_idx = np.argmin(time_diffs)\n",
    "            min_time_diff = time_diffs[closest_acc_idx]\n",
    "            \n",
    "            if min_time_diff == 0:\n",
    "                perfect_matches += 1\n",
    "            elif min_time_diff > MAX_TIME_DIFF:\n",
    "                sync_errors += 1\n",
    "                continue\n",
    "            \n",
    "            entry = {\n",
    "                'timestamp': gps_time,\n",
    "                'relative_time_s': row['relative_time_s'],\n",
    "                'speed': row['speed_ms'],\n",
    "                'speed_kmh': row['speed_kmh'],\n",
    "                'acceleration': row['acceleration'],\n",
    "                'gradient': row['gradient'],\n",
    "                'jerk': behavior_df['jerk_smooth'].iloc[closest_acc_idx],\n",
    "                'sync_error_us': min_time_diff  # 微秒\n",
    "            }\n",
    "            \n",
    "            # 添加转向数据\n",
    "            if 'turning' in self.features:\n",
    "                turning_times = self.features['turning']['full_timestamp'].values\n",
    "                closest_turn_idx = np.argmin(np.abs(turning_times - gps_time))\n",
    "                turn_time_diff = np.abs(turning_times[closest_turn_idx] - gps_time)\n",
    "                \n",
    "                if turn_time_diff <= MAX_TIME_DIFF:\n",
    "                    entry['turning_rate'] = self.features['turning']['turning_rate'].iloc[closest_turn_idx]\n",
    "                else:\n",
    "                    entry['turning_rate'] = 0\n",
    "            else:\n",
    "                entry['turning_rate'] = 0\n",
    "            \n",
    "            combined_data.append(entry)\n",
    "        \n",
    "        if not combined_data:\n",
    "            logger.warning(\"No synchronized data points found\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        combined_df = pd.DataFrame(combined_data)\n",
    "        \n",
    "        # 能耗计算\n",
    "        combined_df['energy_factor'] = self._calculate_energy_consumption(combined_df)\n",
    "        \n",
    "        print(f\"同步结果:\")\n",
    "        print(f\"  完美匹配: {perfect_matches}\")\n",
    "        print(f\"  成功同步: {len(combined_data)}\")\n",
    "        print(f\"  同步错误: {sync_errors}\")\n",
    "        print(f\"  平均同步误差: {combined_df['sync_error_us'].mean():.0f} 微秒\")\n",
    "        \n",
    "        self.processed_data = combined_df\n",
    "        return combined_df\n",
    "    \n",
    "    def _calculate_energy_consumption_fixed(self, df):\n",
    "        \"\"\"计算能耗 - 修正版，调整参数使结果更合理\"\"\"\n",
    "        config = self.config['energy_model']\n",
    "        mass = config['vehicle_mass']\n",
    "        g = GRAVITY\n",
    "        rho = 1.225  # 空气密度\n",
    "        Cd = config['drag_coefficient']\n",
    "        A = config['frontal_area']\n",
    "        Cr = config['rolling_resistance']\n",
    "        \n",
    "        power_W = np.zeros(len(df))\n",
    "        \n",
    "        for i in range(len(df)):\n",
    "            v = max(0.1, df['speed'].iloc[i])\n",
    "            θ = np.arctan(df['gradient'].iloc[i]) if abs(df['gradient'].iloc[i]) < 1 else 0\n",
    "            \n",
    "            F_roll = Cr * mass * g * np.cos(θ)\n",
    "            F_aero = 0.5 * rho * Cd * A * v**2\n",
    "            F_grad = mass * g * np.sin(θ)\n",
    "            F_acc = mass * df['acceleration'].iloc[i]\n",
    "            \n",
    "            F_total = F_roll + F_aero + F_grad + F_acc\n",
    "            F_traction = max(F_total, 0)\n",
    "            \n",
    "            # 添加电机效率因子，使能耗更合理\n",
    "            motor_efficiency = 0.85  # 电机效率85%\n",
    "            power_W[i] = F_traction * v / motor_efficiency\n",
    "        \n",
    "        # 计算能耗 - 使用相对时间，添加合理性检查\n",
    "        if len(df) > 1:\n",
    "            dt = df['relative_time_s'].diff().fillna(1.0)\n",
    "            dt = np.clip(dt, 0.01, 10.0)  # 限制时间间隔\n",
    "        else:\n",
    "            dt = np.array([1.0])\n",
    "        \n",
    "        energy_J = power_W * dt.values\n",
    "        \n",
    "        # 限制单个数据点的能耗，避免异常值\n",
    "        energy_J = np.clip(energy_J, 0, 50000)  # 限制单点最大能耗50kJ\n",
    "        \n",
    "        df['energy_J'] = energy_J\n",
    "        \n",
    "        return power_W\n",
    "    \n",
    "    def cluster_driving_behaviors(self):\n",
    "        \"\"\"驾驶行为聚类 - 改进版\"\"\"\n",
    "        logger.info(\"Clustering driving behaviors with improved classification\")\n",
    "        \n",
    "        if self.processed_data is None or self.processed_data.empty:\n",
    "            logger.error(\"No processed data available for clustering\")\n",
    "            return {}, pd.DataFrame(), np.array([])\n",
    "        \n",
    "        data = self.processed_data.copy()\n",
    "        \n",
    "        # 确保所需列存在\n",
    "        required_cols = self.config['clustering']['features'] + ['energy_J']\n",
    "        for col in required_cols:\n",
    "            if col not in data.columns:\n",
    "                data[col] = 0.0\n",
    "        \n",
    "        print(f\"\\n=== 驾驶行为聚类 ===\")\n",
    "        for col in self.config['clustering']['features']:\n",
    "            if col in data.columns:\n",
    "                print(f\"{col}: {data[col].min():.3f} - {data[col].max():.3f} (均值: {data[col].mean():.3f})\")\n",
    "        \n",
    "        # K-Means聚类\n",
    "        feats = self.config['clustering']['features']\n",
    "        X = data[feats].fillna(0)\n",
    "        \n",
    "        # 数据标准化\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        # PCA降维\n",
    "        try:\n",
    "            pca = PCA(n_components=2)\n",
    "            X_pca = pca.fit_transform(X_scaled)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"PCA failed: {e}\")\n",
    "            X_pca = X_scaled[:, :2] if X_scaled.shape[1] >= 2 else np.column_stack([X_scaled[:, 0], X_scaled[:, 0]])\n",
    "        \n",
    "        n_clusters = min(self.config['clustering']['n_clusters'], max(1, len(X) - 1))\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        clusters = kmeans.fit_predict(X_scaled)\n",
    "        \n",
    "        data['driver_cluster'] = clusters\n",
    "        \n",
    "        # 生成聚类配置文件\n",
    "        cluster_profiles = {}\n",
    "        for cid in range(n_clusters):\n",
    "            data_c = data[data['driver_cluster'] == cid]\n",
    "            if data_c.empty:\n",
    "                cluster_profiles[cid] = {'size': 0, 'driver_type': 'unknown'}\n",
    "                continue\n",
    "            \n",
    "            # 计算统计指标\n",
    "            if len(data_c) > 1:\n",
    "                dt = data_c['relative_time_s'].diff().fillna(1.0)\n",
    "                dt = np.clip(dt, 0.01, 10.0)\n",
    "                total_time = dt.sum()\n",
    "                total_distance = (data_c['speed'] * dt).sum() / 1000.0  # km\n",
    "            else:\n",
    "                total_time = 1.0\n",
    "                total_distance = 0.001\n",
    "            \n",
    "            total_energy = data_c['energy_J'].sum() / 3600000.0  # kWh (J->kWh)\n",
    "            energy_eff = total_energy / max(total_distance, 0.001) * 100  # kWh/100km\n",
    "            \n",
    "            profile = {\n",
    "                'size': len(data_c),\n",
    "                'avg_speed': data_c['speed'].mean(),\n",
    "                'std_speed': data_c['speed'].std(),\n",
    "                'avg_acceleration': data_c['acceleration'].mean(),\n",
    "                'std_acceleration': data_c['acceleration'].std(),\n",
    "                'avg_jerk': data_c['jerk'].mean(),\n",
    "                'std_jerk': data_c['jerk'].std(),\n",
    "                'avg_turning_rate': data_c['turning_rate'].mean(),\n",
    "                'std_turning_rate': data_c['turning_rate'].std(),\n",
    "                'energy_efficiency': energy_eff,\n",
    "                'total_time_s': total_time,\n",
    "                'total_distance_km': total_distance,\n",
    "            }\n",
    "            \n",
    "            # 改进的驾驶类型分类 - 适应起步阶段\n",
    "            abs_avg_jerk = abs(profile['avg_jerk'])\n",
    "            abs_avg_acc = abs(profile['avg_acceleration'])\n",
    "            avg_speed = profile['avg_speed']\n",
    "            avg_turning = profile['avg_turning_rate']\n",
    "            \n",
    "            # 针对起步阶段的分类逻辑\n",
    "            if abs_avg_jerk > 15.0 and abs_avg_acc > 2.0:\n",
    "                profile['driver_type'] = 'aggressive'\n",
    "            elif avg_turning > 0.15:\n",
    "                profile['driver_type'] = 'cornering'\n",
    "            elif avg_speed > 8.0 and abs_avg_acc > 1.0:  # 调整速度阈值\n",
    "                profile['driver_type'] = 'dynamic'\n",
    "            elif avg_speed < 5.0 and abs_avg_jerk < 8.0:\n",
    "                profile['driver_type'] = 'cautious'\n",
    "            elif abs_avg_acc < 0.5 and abs_avg_jerk < 5.0:\n",
    "                profile['driver_type'] = 'efficient'\n",
    "            else:\n",
    "                profile['driver_type'] = 'normal'\n",
    "            \n",
    "            cluster_profiles[cid] = profile\n",
    "        \n",
    "        print(f\"聚类结果:\")\n",
    "        for cid, profile in cluster_profiles.items():\n",
    "            print(f\"  Cluster {cid} ({profile['driver_type']}): {profile['size']} 样本\")\n",
    "            print(f\"    速度: {profile['avg_speed']*3.6:.1f} km/h, 加速度: {profile['avg_acceleration']:.2f} m/s²\")\n",
    "            print(f\"    Jerk: {profile['avg_jerk']:.2f} m/s³, 能耗: {profile['energy_efficiency']:.1f} kWh/100km\")\n",
    "        \n",
    "        # 更新处理后的数据\n",
    "        self.processed_data = data\n",
    "        \n",
    "        # 在 cluster_driving_behaviors() 方法的最后，return 语句之前添加：\n",
    "        print(f\"DEBUG: type of self.processed_data after clustering: {type(self.processed_data)}\")\n",
    "        print(f\"DEBUG: processed_data columns: {self.processed_data.columns.tolist() if isinstance(self.processed_data, pd.DataFrame) else 'Not DataFrame'}\")\n",
    "        \n",
    "        return cluster_profiles, X_pca, clusters\n",
    "    \n",
    "    def generate_comprehensive_report(self):\n",
    "        \"\"\"生成综合分析报告\"\"\"\n",
    "        logger.info(\"Generating comprehensive analysis report\")\n",
    "        \n",
    "        if self.processed_data is None:\n",
    "            logger.error(\"No processed data available for report generation\")\n",
    "            return None\n",
    "        \n",
    "        # 基本统计\n",
    "        data = self.processed_data\n",
    "        total_time = data['relative_time_s'].max()  # 使用相对时间\n",
    "        total_distance = (data['speed'] * data['relative_time_s'].diff().fillna(1.0)).sum() / 1000.0  # km\n",
    "        avg_speed = data['speed'].mean() * 3.6  # km/h\n",
    "        max_speed = data['speed_kmh'].max()\n",
    "        \n",
    "        # 急刹车分析\n",
    "        hard_brake_events = self.detect_hard_brake_events()\n",
    "        \n",
    "        # 驾驶行为聚类\n",
    "        cluster_profiles, X_pca, clusters = self.cluster_driving_behaviors()\n",
    "\n",
    "        # 确保processed_data被正确更新\n",
    "        if self.processed_data is not None:\n",
    "            data = self.processed_data  # 使用更新后的数据\n",
    "        else:\n",
    "            logger.error(\"processed_data is None after clustering\")\n",
    "            return None\n",
    "        \n",
    "        # 生成报告\n",
    "        report = {\n",
    "            'metadata': {\n",
    "                'analysis_date': datetime.now().isoformat(),\n",
    "                'version': VERSION,\n",
    "                'data_points': len(data),\n",
    "                'duration_minutes': total_time / 60,\n",
    "                'total_distance_km': total_distance\n",
    "            },\n",
    "            'driving_summary': {\n",
    "                'max_speed_kmh': max_speed,\n",
    "                'avg_speed_kmh': avg_speed,\n",
    "                'total_hard_brakes': len(hard_brake_events),\n",
    "                'hard_brakes_per_hour': len(hard_brake_events) / max(total_time / 3600, 0.1)\n",
    "            },\n",
    "            'cluster_analysis': cluster_profiles,\n",
    "            'recommendations': self._generate_recommendations(cluster_profiles, hard_brake_events)\n",
    "        }\n",
    "        \n",
    "        self.results = {\n",
    "            'report': report,\n",
    "            'data': self.processed_data.copy(),\n",
    "            'hard_brake_events': hard_brake_events,\n",
    "            'cluster_profiles': cluster_profiles,\n",
    "            'pca_data': X_pca,\n",
    "            'clusters': clusters\n",
    "        }\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def _generate_recommendations(self, cluster_profiles, hard_brake_events):\n",
    "        \"\"\"生成驾驶建议\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        # 基于急刹车的建议\n",
    "        if len(hard_brake_events) > 3:  # 降低阈值适应起步阶段\n",
    "            recommendations.append({\n",
    "                'category': 'Safety',\n",
    "                'priority': 'High',\n",
    "                'message': 'Multiple hard braking events detected during startup phase. Consider smoother acceleration and anticipating traffic conditions.',\n",
    "                'impact': 'Reduces brake wear and improves passenger comfort'\n",
    "            })\n",
    "        elif len(hard_brake_events) == 0:\n",
    "            recommendations.append({\n",
    "                'category': 'Positive',\n",
    "                'priority': 'Low',\n",
    "                'message': 'Excellent! No hard braking events detected. Very smooth driving style.',\n",
    "                'impact': 'Optimal brake system preservation and passenger comfort'\n",
    "            })\n",
    "        \n",
    "        # 基于聚类分析的建议\n",
    "        for cid, profile in cluster_profiles.items():\n",
    "            if profile['driver_type'] == 'aggressive':\n",
    "                recommendations.append({\n",
    "                    'category': 'Efficiency',\n",
    "                    'priority': 'Medium',\n",
    "                    'message': f'Cluster {cid} shows aggressive driving patterns. Gentler acceleration can improve efficiency by 15-20%.',\n",
    "                    'impact': f'Current energy efficiency: {profile[\"energy_efficiency\"]:.1f} kWh/100km'\n",
    "                })\n",
    "            elif profile['driver_type'] == 'efficient':\n",
    "                recommendations.append({\n",
    "                    'category': 'Positive',\n",
    "                    'priority': 'Low',\n",
    "                    'message': f'Cluster {cid} demonstrates efficient driving behavior. Excellent energy management!',\n",
    "                    'impact': f'Outstanding energy efficiency: {profile[\"energy_efficiency\"]:.1f} kWh/100km'\n",
    "                })\n",
    "            elif profile['driver_type'] == 'cautious':\n",
    "                recommendations.append({\n",
    "                    'category': 'Performance',\n",
    "                    'priority': 'Low',\n",
    "                    'message': f'Cluster {cid} shows very cautious driving. Consider slightly more dynamic acceleration when safe.',\n",
    "                    'impact': 'May improve traffic flow while maintaining safety'\n",
    "                })\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def visualize_results(self, save_plots=True):\n",
    "        if not self.results:\n",
    "            logger.error(\"No results available for visualization\")\n",
    "            return\n",
    "        \n",
    "        # 调试：检查数据类型\n",
    "        print(f\"DEBUG: self.results keys: {list(self.results.keys())}\")\n",
    "        print(f\"DEBUG: type of self.results['data']: {type(self.results['data'])}\")\n",
    "        print(f\"DEBUG: type of self.processed_data: {type(self.processed_data)}\")\n",
    "        \n",
    "        # 直接使用 processed_data\n",
    "        data = self.processed_data\n",
    "        if data is None or not isinstance(data, pd.DataFrame):\n",
    "            logger.error(f\"Invalid processed_data type: {type(data)}\")\n",
    "            return\n",
    "        \n",
    "        hard_brake_events = self.results['hard_brake_events']\n",
    "        cluster_profiles = self.results['cluster_profiles']\n",
    "        \n",
    "        # 创建综合仪表板\n",
    "        fig = plt.figure(figsize=(20, 16))\n",
    "        \n",
    "        # 1. 速度时间曲线（使用相对时间）\n",
    "        ax1 = plt.subplot(3, 3, 1)\n",
    "        time_minutes = data['relative_time_s'] / 60\n",
    "        \n",
    "        plt.plot(time_minutes, data['speed_kmh'], 'b-', alpha=0.7, linewidth=2, label='Speed (km/h)')\n",
    "        \n",
    "        if not hard_brake_events.empty:\n",
    "            brake_times = hard_brake_events['relative_time_s'] / 60\n",
    "            plt.scatter(brake_times, hard_brake_events['speed_kmh'], \n",
    "                       color='red', marker='X', s=100, zorder=5, \n",
    "                       label=f'Hard Brakes ({len(hard_brake_events)})')\n",
    "            \n",
    "            # 添加急刹车标注\n",
    "            for i, (idx, event) in enumerate(hard_brake_events.iterrows()):\n",
    "                plt.annotate(f'Brake {i+1}', \n",
    "                           xy=(event['relative_time_s']/60, event['speed_kmh']),\n",
    "                           xytext=(10, 20), textcoords='offset points',\n",
    "                           bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.8),\n",
    "                           arrowprops=dict(arrowstyle='->', color='red'))\n",
    "        \n",
    "        plt.title('Speed Profile with Hard Brake Events\\n(Startup Phase Analysis)')\n",
    "        plt.xlabel('Time (minutes)')\n",
    "        plt.ylabel('Speed (km/h)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. 驾驶行为聚类PCA视图\n",
    "        ax2 = plt.subplot(3, 3, 2)\n",
    "        scatter = plt.scatter(self.results['pca_data'][:, 0], self.results['pca_data'][:, 1], \n",
    "                             c=self.results['clusters'], cmap='viridis', alpha=0.7, s=30)\n",
    "        plt.title('Driver Behavior Clusters\\n(PCA Visualization)')\n",
    "        plt.xlabel('PCA Component 1')\n",
    "        plt.ylabel('PCA Component 2')\n",
    "        plt.colorbar(scatter, label='Cluster')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. 加速度分布\n",
    "        ax3 = plt.subplot(3, 3, 3)\n",
    "        colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown']\n",
    "        for cluster in range(len(cluster_profiles)):\n",
    "            cluster_data = data[data['driver_cluster'] == cluster]\n",
    "            if not cluster_data.empty and 'acceleration' in cluster_data.columns:\n",
    "                plt.hist(cluster_data['acceleration'], bins=15, alpha=0.6, \n",
    "                        label=f'Cluster {cluster}', density=True, \n",
    "                        color=colors[cluster % len(colors)])\n",
    "        plt.title('Acceleration Distribution by Cluster\\n(Startup Phase)')\n",
    "        plt.xlabel('Acceleration (m/s²)')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Jerk分布\n",
    "        ax4 = plt.subplot(3, 3, 4)\n",
    "        for cluster in range(len(cluster_profiles)):\n",
    "            cluster_data = data[data['driver_cluster'] == cluster]\n",
    "            if not cluster_data.empty and 'jerk' in cluster_data.columns:\n",
    "                plt.hist(cluster_data['jerk'], bins=15, alpha=0.6, \n",
    "                        label=f'Cluster {cluster}', density=True,\n",
    "                        color=colors[cluster % len(colors)])\n",
    "        plt.title('Jerk Distribution by Cluster\\n(Instantaneous Values)')\n",
    "        plt.xlabel('Jerk (m/s³)')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 5. 驾驶类型分布\n",
    "        ax5 = plt.subplot(3, 3, 5)\n",
    "        driver_types = [cluster_profiles[cid]['driver_type'] for cid in cluster_profiles.keys()]\n",
    "        type_counts = {}\n",
    "        for dtype in driver_types:\n",
    "            type_counts[dtype] = type_counts.get(dtype, 0) + 1\n",
    "        \n",
    "        colors_pie = {'aggressive': 'red', 'dynamic': 'orange', 'cornering': 'purple', \n",
    "                      'efficient': 'green', 'cautious': 'blue', 'normal': 'cyan', 'unknown': 'gray'}\n",
    "        pie_colors = [colors_pie.get(dtype, 'gray') for dtype in type_counts.keys()]\n",
    "        \n",
    "        plt.pie(type_counts.values(), labels=type_counts.keys(), colors=pie_colors,\n",
    "                autopct='%1.1f%%', startangle=90)\n",
    "        plt.title('Driver Type Distribution\\n(Startup Phase)')\n",
    "        \n",
    "        # 6. 能耗效率对比\n",
    "        ax6 = plt.subplot(3, 3, 6)\n",
    "        cluster_ids = list(cluster_profiles.keys())\n",
    "        energy_effs = [cluster_profiles[cid]['energy_efficiency'] for cid in cluster_ids]\n",
    "        driver_types_list = [cluster_profiles[cid]['driver_type'] for cid in cluster_ids]\n",
    "        \n",
    "        bar_colors = [colors_pie.get(dtype, 'gray') for dtype in driver_types_list]\n",
    "        bars = plt.bar(range(len(cluster_ids)), energy_effs, color=bar_colors, alpha=0.8)\n",
    "        plt.title('Energy Efficiency by Cluster\\n(Startup Phase)')\n",
    "        plt.xlabel('Cluster')\n",
    "        plt.ylabel('Energy Efficiency (kWh/100km)')\n",
    "        plt.xticks(range(len(cluster_ids)), [f'C{cid}\\n({dtype})' for cid, dtype in zip(cluster_ids, driver_types_list)])\n",
    "        \n",
    "        for bar, eff in zip(bars, energy_effs):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(energy_effs)*0.01, \n",
    "                    f'{eff:.1f}', ha='center', va='bottom')\n",
    "        \n",
    "        # 7. 速度vs加速度散点图\n",
    "        ax7 = plt.subplot(3, 3, 7)\n",
    "        scatter = plt.scatter(data['speed_kmh'], data['acceleration'], \n",
    "                             c=data['driver_cluster'], cmap='viridis', alpha=0.6, s=20)\n",
    "        plt.title('Speed vs Acceleration\\n(Startup Phase)')\n",
    "        plt.xlabel('Speed (km/h)')\n",
    "        plt.ylabel('Acceleration (m/s²)')\n",
    "        plt.colorbar(scatter, label='Cluster')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 8. 时间序列加速度\n",
    "        ax8 = plt.subplot(3, 3, 8)\n",
    "        sample_size = min(200, len(data))\n",
    "        sample_data = data.head(sample_size)\n",
    "        sample_times = sample_data['relative_time_s'] / 60\n",
    "        \n",
    "        plt.plot(sample_times, sample_data['acceleration'], 'g-', alpha=0.7, linewidth=1)\n",
    "        plt.title(f'Acceleration Time Series\\n(First {sample_size} points)')\n",
    "        plt.xlabel('Time (minutes)')\n",
    "        plt.ylabel('Acceleration (m/s²)')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 9. 综合评分仪表盘\n",
    "        ax9 = plt.subplot(3, 3, 9)\n",
    "        \n",
    "        # 计算评分 - 适应起步阶段\n",
    "        total_events = len(hard_brake_events)\n",
    "        total_time_hours = data['relative_time_s'].max() / 3600\n",
    "        events_per_hour = total_events / max(total_time_hours, 0.1)\n",
    "        \n",
    "        avg_energy_eff = np.mean([p['energy_efficiency'] for p in cluster_profiles.values()])\n",
    "        \n",
    "        # 评分计算（针对起步阶段调整）\n",
    "        safety_score = max(0, 100 - events_per_hour * 15)  # 起步阶段降低惩罚\n",
    "        efficiency_score = max(0, 100 - max(0, avg_energy_eff - 25) * 2)  # 起步阶段能耗可能较高\n",
    "        smoothness_score = 100 - min(50, np.mean([abs(p['avg_jerk']) for p in cluster_profiles.values()]) * 2)\n",
    "        overall_score = (safety_score + efficiency_score + smoothness_score) / 3\n",
    "        \n",
    "        # 绘制仪表盘\n",
    "        scores = [safety_score, efficiency_score, smoothness_score, overall_score]\n",
    "        labels = ['Safety', 'Efficiency', 'Smoothness', 'Overall']\n",
    "        colors_gauge = ['red', 'green', 'blue', 'purple']\n",
    "        \n",
    "        bars = plt.bar(labels, scores, color=colors_gauge, alpha=0.7)\n",
    "        plt.ylim(0, 100)\n",
    "        plt.title('Eco-Driving Score Dashboard\\n(Startup Phase)')\n",
    "        plt.ylabel('Score (0-100)')\n",
    "        \n",
    "        for bar, score in zip(bars, scores):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2, \n",
    "                    f'{score:.0f}', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_plots:\n",
    "            plt.savefig('eco_driving_startup_analysis.png', dpi=300, bbox_inches='tight')\n",
    "            logger.info(\"Saved startup phase analysis plot\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def save_results(self, output_dir='eco_driving_results'):\n",
    "        \"\"\"保存分析结果\"\"\"\n",
    "        if not self.results:\n",
    "            logger.error(\"No results to save\")\n",
    "            return False\n",
    "        \n",
    "        # 创建输出目录\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            # 保存主要数据\n",
    "            self.results['data'].to_csv(f'{output_dir}/processed_data.csv', index=False)\n",
    "            \n",
    "            if not self.results['hard_brake_events'].empty:\n",
    "                self.results['hard_brake_events'].to_csv(f'{output_dir}/hard_brake_events.csv', index=False)\n",
    "            \n",
    "            # 保存JSON报告\n",
    "            with open(f'{output_dir}/analysis_report.json', 'w', encoding='utf-8') as f:\n",
    "                json.dump(self.results['report'], f, indent=2, ensure_ascii=False, default=str)\n",
    "            \n",
    "            # 保存文本报告\n",
    "            self._save_text_report(f'{output_dir}/eco_driving_report.txt')\n",
    "            \n",
    "            logger.info(f\"Results saved to {output_dir}/\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving results: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def _save_text_report(self, filepath):\n",
    "        \"\"\"保存详细文本报告\"\"\"\n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            report = self.results['report']\n",
    "            cluster_profiles = self.results['cluster_profiles']\n",
    "            hard_brake_events = self.results['hard_brake_events']\n",
    "            \n",
    "            f.write(\"=\" * 80 + \"\\n\")\n",
    "            f.write(\"ECO-DRIVING ANALYSIS REPORT - STARTUP PHASE\\n\")\n",
    "            f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "            \n",
    "            # 基本信息\n",
    "            f.write(f\"Analysis Date: {report['metadata']['analysis_date']}\\n\")\n",
    "            f.write(f\"System Version: {report['metadata']['version']} (Microsecond Precision)\\n\")\n",
    "            f.write(f\"Data Points: {report['metadata']['data_points']}\\n\")\n",
    "            f.write(f\"Duration: {report['metadata']['duration_minutes']:.1f} minutes\\n\")\n",
    "            f.write(f\"Total Distance: {report['metadata']['total_distance_km']:.3f} km\\n\\n\")\n",
    "            \n",
    "            # 驾驶摘要\n",
    "            f.write(\"DRIVING SUMMARY (STARTUP PHASE):\\n\")\n",
    "            f.write(\"-\" * 40 + \"\\n\")\n",
    "            f.write(f\"Maximum Speed: {report['driving_summary']['max_speed_kmh']:.1f} km/h\\n\")\n",
    "            f.write(f\"Average Speed: {report['driving_summary']['avg_speed_kmh']:.1f} km/h\\n\")\n",
    "            f.write(f\"Total Hard Brakes: {report['driving_summary']['total_hard_brakes']}\\n\")\n",
    "            f.write(f\"Hard Brakes per Hour: {report['driving_summary']['hard_brakes_per_hour']:.1f}\\n\\n\")\n",
    "            \n",
    "            # 聚类分析\n",
    "            f.write(\"DRIVER BEHAVIOR CLUSTERS (STARTUP PHASE):\\n\")\n",
    "            f.write(\"-\" * 40 + \"\\n\")\n",
    "            for cid, profile in cluster_profiles.items():\n",
    "                f.write(f\"\\nCluster {cid} - {profile['driver_type'].upper()}:\\n\")\n",
    "                f.write(f\"  Sample Size: {profile['size']} points\\n\")\n",
    "                f.write(f\"  Average Speed: {profile['avg_speed']*3.6:.1f} km/h\\n\")\n",
    "                f.write(f\"  Average Acceleration: {profile['avg_acceleration']:.3f} m/s²\\n\")\n",
    "                f.write(f\"  Average Jerk: {profile['avg_jerk']:.3f} m/s³ (instantaneous)\\n\")\n",
    "                f.write(f\"  Average Turning Rate: {profile['avg_turning_rate']:.3f} rad/s\\n\")\n",
    "                f.write(f\"  Energy Efficiency: {profile['energy_efficiency']:.2f} kWh/100km\\n\")\n",
    "                f.write(f\"  Total Distance: {profile['total_distance_km']:.4f} km\\n\")\n",
    "                f.write(f\"  Total Time: {profile['total_time_s']:.1f} seconds\\n\")\n",
    "            \n",
    "            # 急刹车详情\n",
    "            f.write(f\"\\nHARD BRAKE EVENTS DETAIL:\\n\")\n",
    "            f.write(\"-\" * 40 + \"\\n\")\n",
    "            if not hard_brake_events.empty:\n",
    "                for i, (idx, event) in enumerate(hard_brake_events.iterrows()):\n",
    "                    time_min = event['relative_time_s'] / 60\n",
    "                    f.write(f\"  Event {i+1}: {time_min:.1f} min - Speed: {event['speed_kmh']:.1f} km/h, \"\n",
    "                           f\"Acceleration: {event['acceleration']:.2f} m/s²\\n\")\n",
    "            else:\n",
    "                f.write(\"  No hard brake events detected - Excellent smooth driving!\\n\")\n",
    "            \n",
    "            # 建议\n",
    "            f.write(f\"\\nRECOMMENDATIONS:\\n\")\n",
    "            f.write(\"-\" * 40 + \"\\n\")\n",
    "            for i, rec in enumerate(report['recommendations']):\n",
    "                f.write(f\"{i+1}. [{rec['category']} - {rec['priority']}] {rec['message']}\\n\")\n",
    "                f.write(f\"   Impact: {rec['impact']}\\n\\n\")\n",
    "            \n",
    "            # 技术说明\n",
    "            f.write(\"TECHNICAL NOTES:\\n\")\n",
    "            f.write(\"-\" * 20 + \"\\n\")\n",
    "            f.write(\"• Timestamp precision: Microseconds\\n\")\n",
    "            f.write(\"• Analysis focus: Vehicle startup phase\\n\")\n",
    "            f.write(\"• Jerk calculation: Instantaneous values preserved\\n\")\n",
    "            f.write(\"• Acceleration: Real GPS-based calculation with synthetic backup\\n\")\n",
    "            f.write(\"• Energy model: Adapted for low-speed urban driving\\n\")\n",
    "\n",
    "# 主要使用接口\n",
    "def run_complete_eco_driving_analysis(data_file, config=None):\n",
    "    \"\"\"\n",
    "    运行完整的生态驾驶分析 - 微秒时间戳版本\n",
    "    \n",
    "    Args:\n",
    "        data_file: 传感器数据文件路径\n",
    "        config: 可选配置字典\n",
    "    \n",
    "    Returns:\n",
    "        EcoDrivingAnalyzer实例，包含所有分析结果\n",
    "    \"\"\"\n",
    "    print(\"🚗 Starting Complete Eco-Driving Analysis System v2.1\")\n",
    "    print(\"📍 Optimized for startup phase analysis with microsecond precision\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # 初始化分析器\n",
    "    analyzer = EcoDrivingAnalyzer(config)\n",
    "    \n",
    "    # 1. 解析数据\n",
    "    print(\"📊 Step 1: Parsing sensor data (microsecond timestamps)...\")\n",
    "    if not analyzer.parse_sensor_data(data_file):\n",
    "        print(\"❌ Failed to parse sensor data\")\n",
    "        return None\n",
    "    \n",
    "    # 2. 提取特征\n",
    "    print(\"🔍 Step 2: Extracting driving features...\")\n",
    "    if not analyzer.extract_driving_features():\n",
    "        print(\"❌ Failed to extract features\")\n",
    "        return None\n",
    "    \n",
    "    # 3. 数据同步和能耗建模\n",
    "    print(\"⚡ Step 3: Synchronizing data and modeling energy...\")\n",
    "    combined_data = analyzer.synchronize_and_model_energy()\n",
    "    if combined_data.empty:\n",
    "        print(\"❌ Failed to synchronize data\")\n",
    "        return None\n",
    "    \n",
    "    # 4. 生成综合报告\n",
    "    print(\"📋 Step 4: Generating comprehensive report...\")\n",
    "    report = analyzer.generate_comprehensive_report()\n",
    "    if not report:\n",
    "        print(\"❌ Failed to generate report\")\n",
    "        return None\n",
    "    \n",
    "    # 5. 可视化结果\n",
    "    print(\"📈 Step 5: Creating visualizations...\")\n",
    "    analyzer.visualize_results()\n",
    "    \n",
    "    # 6. 保存结果\n",
    "    print(\"💾 Step 6: Saving results...\")\n",
    "    analyzer.save_results()\n",
    "    \n",
    "    print(\"\\n✅ Analysis Complete!\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # 打印关键结果\n",
    "    print(f\"📊 Key Results (Startup Phase):\")\n",
    "    print(f\"  • Duration: {report['metadata']['duration_minutes']:.1f} minutes\")\n",
    "    print(f\"  • Max Speed: {report['driving_summary']['max_speed_kmh']:.1f} km/h\")\n",
    "    print(f\"  • Hard Brake Events: {len(analyzer.results['hard_brake_events'])}\")\n",
    "    print(f\"  • Driver Behavior Types: {len(set(p['driver_type'] for p in analyzer.results['cluster_profiles'].values()))}\")\n",
    "    print(f\"  • Average Energy Efficiency: {np.mean([p['energy_efficiency'] for p in analyzer.results['cluster_profiles'].values()]):.1f} kWh/100km\")\n",
    "    \n",
    "    return analyzer\n",
    "\n",
    "# 使用示例和测试代码\n",
    "if __name__ == \"__main__\":\n",
    "    # 针对起步阶段优化的配置\n",
    "    startup_config = {\n",
    "        'hard_brake_threshold': -2.0,  # 降低阈值适应起步\n",
    "        'speed_drop_threshold': 6,     # 降低速度下降阈值\n",
    "        'min_brake_speed': 8,          # 降低最小刹车速度\n",
    "        'energy_model': {\n",
    "            'vehicle_mass': 1600,      # 紧凑型轿车\n",
    "            'drag_coefficient': 0.26,  # 现代轿车优秀风阻\n",
    "            'frontal_area': 2.2,       # 紧凑型车迎风面积\n",
    "            'rolling_resistance': 0.010 # 优质轮胎\n",
    "        },\n",
    "        'clustering': {\n",
    "            'n_clusters': 3,\n",
    "            'features': ['speed', 'acceleration', 'jerk', 'turning_rate']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 运行分析\n",
    "    data_file = \"ts_1747221572.csv\"  # 你的数据文件\n",
    "    \n",
    "    print(\"🚀 Running Eco-Driving Analysis - Startup Phase Optimized\")\n",
    "    print(f\"📁 Data file: {data_file}\")\n",
    "    print(\"🔧 Configuration: Optimized for startup phase with microsecond precision\")\n",
    "    print(\"⏱️  Expected analysis time: 30-60 seconds\")\n",
    "    print()\n",
    "    \n",
    "    # 执行完整分析\n",
    "    analyzer = run_complete_eco_driving_analysis(data_file, startup_config)\n",
    "    \n",
    "    if analyzer:\n",
    "        print(\"\\n🎉 Analysis completed successfully!\")\n",
    "        print(\"📁 Check 'eco_driving_results' folder for detailed outputs:\")\n",
    "        print(\"   • processed_data.csv - Complete processed dataset\")\n",
    "        print(\"   • hard_brake_events.csv - Hard brake event details\") \n",
    "        print(\"   • analysis_report.json - Structured analysis results\")\n",
    "        print(\"   • eco_driving_report.txt - Human-readable report\")\n",
    "        print(\"   • eco_driving_startup_analysis.png - Comprehensive visualization\")\n",
    "        \n",
    "        # 显示快速摘要\n",
    "        print(f\"\\n🔍 Quick Analysis Summary:\")\n",
    "        report = analyzer.results['report']\n",
    "        print(f\"  ⏱️  Duration: {report['metadata']['duration_minutes']:.1f} minutes\")\n",
    "        print(f\"  🚗 Max Speed: {report['driving_summary']['max_speed_kmh']:.1f} km/h\")\n",
    "        print(f\"  🚨 Hard Brakes: {report['driving_summary']['total_hard_brakes']}\")\n",
    "        \n",
    "        # 显示驾驶类型分布\n",
    "        cluster_types = [p['driver_type'] for p in analyzer.results['cluster_profiles'].values()]\n",
    "        type_counts = {}\n",
    "        for dtype in cluster_types:\n",
    "            type_counts[dtype] = type_counts.get(dtype, 0) + 1\n",
    "        \n",
    "        print(f\"  🎯 Driving Types Found: {', '.join(type_counts.keys())}\")\n",
    "        \n",
    "        # 显示主要建议\n",
    "        print(f\"\\n💡 Top Recommendations:\")\n",
    "        for i, rec in enumerate(report['recommendations'][:2]):\n",
    "            print(f\"  {i+1}. [{rec['priority']}] {rec['message'][:80]}...\")\n",
    "        \n",
    "        # 数据质量报告\n",
    "        data = analyzer.results['data']\n",
    "        print(f\"\\n📊 Data Quality Summary:\")\n",
    "        print(f\"  • Total Data Points: {len(data):,}\")\n",
    "        print(f\"  • GPS-Accelerometer Sync: {(data['sync_error_us'] < 100000).sum()}/{len(data)} points < 100ms\")\n",
    "        print(f\"  • Acceleration Range: {data['acceleration'].min():.2f} to {data['acceleration'].max():.2f} m/s²\")\n",
    "        print(f\"  • Jerk Range: {data['jerk'].min():.2f} to {data['jerk'].max():.2f} m/s³\")\n",
    "        print(f\"  • Speed Range: {data['speed_kmh'].min():.1f} to {data['speed_kmh'].max():.1f} km/h\")\n",
    "        \n",
    "        # 性能评估\n",
    "        if 'hard_brake_events' in analyzer.results:\n",
    "            safety_rating = \"🟢 Excellent\" if len(analyzer.results['hard_brake_events']) == 0 else \\\n",
    "                           \"🟡 Good\" if len(analyzer.results['hard_brake_events']) <= 2 else \\\n",
    "                           \"🟠 Needs Improvement\"\n",
    "            print(f\"  • Safety Rating: {safety_rating}\")\n",
    "        \n",
    "        avg_energy = np.mean([p['energy_efficiency'] for p in analyzer.results['cluster_profiles'].values()])\n",
    "        efficiency_rating = \"🟢 Excellent\" if avg_energy < 20 else \\\n",
    "                           \"🟡 Good\" if avg_energy < 30 else \\\n",
    "                           \"🟠 Moderate\"\n",
    "        print(f\"  • Efficiency Rating: {efficiency_rating} ({avg_energy:.1f} kWh/100km)\")\n",
    "        \n",
    "        print(f\"\\n✨ Analysis Features Highlights:\")\n",
    "        print(f\"  ✅ Microsecond timestamp precision\")\n",
    "        print(f\"  ✅ Real GPS-based acceleration calculation\")\n",
    "        print(f\"  ✅ Instantaneous jerk values (not averaged)\")\n",
    "        print(f\"  ✅ Startup phase optimized thresholds\")\n",
    "        print(f\"  ✅ Intelligent hard brake detection\")\n",
    "        print(f\"  ✅ Multi-dimensional driver behavior clustering\")\n",
    "        print(f\"  ✅ Personalized driving recommendations\")\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ Analysis failed. Please check your data file and try again.\")\n",
    "        print(\"\\n🔧 Troubleshooting Tips:\")\n",
    "        print(\"  • Ensure your CSV file exists and is readable\")\n",
    "        print(\"  • Check that the data format matches the expected structure:\")\n",
    "        print(\"    - GPS: 0,timestamp,lat,lon,alt,speed_kmh,satellites\")\n",
    "        print(\"    - Accelerometer: 1,timestamp,timestamp_us,x,y,z\")\n",
    "        print(\"    - Gyroscope: 2,timestamp,timestamp_us,x,y,z\")\n",
    "        print(\"  • Verify that timestamps are in microseconds\")\n",
    "        print(\"  • Make sure the file contains sufficient data points\")\n",
    "\n",
    "# 辅助函数：数据格式验证\n",
    "def validate_data_format(file_path, sample_lines=10):\n",
    "    \"\"\"\n",
    "    验证数据文件格式\n",
    "    Args:\n",
    "        file_path: 数据文件路径\n",
    "        sample_lines: 检查的样本行数\n",
    "    \"\"\"\n",
    "    print(f\"🔍 Validating data format for {file_path}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = [f.readline().strip() for _ in range(sample_lines)]\n",
    "        \n",
    "        format_counts = {'gps': 0, 'acc': 0, 'gyro': 0, 'rot': 0, 'unknown': 0}\n",
    "        \n",
    "        print(\"Sample data lines:\")\n",
    "        for i, line in enumerate(lines):\n",
    "            if not line:\n",
    "                continue\n",
    "            values = line.split(',')\n",
    "            print(f\"  {i+1}: {line}\")\n",
    "            \n",
    "            if len(values) >= 2:\n",
    "                try:\n",
    "                    data_type = int(values[0])\n",
    "                    if data_type == 0:\n",
    "                        format_counts['gps'] += 1\n",
    "                        if len(values) < 6:\n",
    "                            print(f\"    ⚠️  GPS line has only {len(values)} columns, expected 6+\")\n",
    "                    elif data_type == 1:\n",
    "                        format_counts['acc'] += 1\n",
    "                        if len(values) < 5:\n",
    "                            print(f\"    ⚠️  Accelerometer line has only {len(values)} columns, expected 5+\")\n",
    "                    elif data_type == 2:\n",
    "                        format_counts['gyro'] += 1\n",
    "                        if len(values) < 5:\n",
    "                            print(f\"    ⚠️  Gyroscope line has only {len(values)} columns, expected 5+\")\n",
    "                    elif data_type == 3:\n",
    "                        format_counts['rot'] += 1\n",
    "                        if len(values) < 6:\n",
    "                            print(f\"    ⚠️  Rotation line has only {len(values)} columns, expected 6+\")\n",
    "                    else:\n",
    "                        format_counts['unknown'] += 1\n",
    "                        print(f\"    ⚠️  Unknown data type: {data_type}\")\n",
    "                except ValueError:\n",
    "                    format_counts['unknown'] += 1\n",
    "                    print(f\"    ❌ Invalid data type: {values[0]}\")\n",
    "        \n",
    "        print(f\"\\nData type distribution in sample:\")\n",
    "        for dtype, count in format_counts.items():\n",
    "            if count > 0:\n",
    "                print(f\"  {dtype}: {count} lines\")\n",
    "        \n",
    "        # 验证时间戳\n",
    "        if format_counts['gps'] > 0 or format_counts['acc'] > 0:\n",
    "            print(f\"\\nTimestamp validation:\")\n",
    "            for line in lines:\n",
    "                if not line:\n",
    "                    continue\n",
    "                values = line.split(',')\n",
    "                if len(values) >= 2:\n",
    "                    try:\n",
    "                        timestamp = int(values[1])\n",
    "                        if timestamp > 1000000000000:  # 微秒级时间戳\n",
    "                            print(f\"  ✅ Microsecond timestamp detected: {timestamp}\")\n",
    "                        elif timestamp > 1000000000:   # 毫秒级时间戳\n",
    "                            print(f\"  ⚠️  Millisecond timestamp detected: {timestamp}\")\n",
    "                        else:\n",
    "                            print(f\"  ❌ Unusual timestamp: {timestamp}\")\n",
    "                        break\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error validating file: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d42759cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 15:26:56,544 - INFO - EcoDrivingAnalyzer v2.1 initialized (microsecond timestamps)\n",
      "2025-05-27 15:26:56,544 - INFO - Parsing sensor data from ts_1747221572.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Running Eco-Driving Analysis - Startup Phase Optimized\n",
      "📁 Data file: ts_1747221572.csv\n",
      "🔧 Configuration: Optimized for startup phase with microsecond precision\n",
      "⏱️  Expected analysis time: 30-60 seconds\n",
      "\n",
      "🚗 Starting Complete Eco-Driving Analysis System v2.1\n",
      "📍 Optimized for startup phase analysis with microsecond precision\n",
      "======================================================================\n",
      "📊 Step 1: Parsing sensor data (microsecond timestamps)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 15:26:57,076 - INFO - Parsed 100000 lines from ts_1747221572.csv\n",
      "2025-05-27 15:26:57,209 - INFO - Extracting driving features with microsecond precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GPS数据解析 ===\n",
      "GPS原始行数: 667\n",
      "样本数据: ['0', '1747221671', '57.687946', '11.980719', '56.200001', '2.857636', '12']\n",
      "GPS数据质量检查:\n",
      "  数据点数: 667\n",
      "  时间跨度: 0.0 秒 (0.0 分钟)\n",
      "  速度范围: 0.0 - 91.8 km/h\n",
      "  位置变化: 纬度 0.038410°, 经度 0.017737°\n",
      "\n",
      "=== 加速度传感器数据解析 ===\n",
      "加速度原始行数: 84489\n",
      "样本数据: ['1', '1747221671', '3809', '-1.800781', '-0.957031', '9.539062']\n",
      "加速度数据质量检查:\n",
      "  数据点数: 84489\n",
      "  时间跨度: 1.0 秒\n",
      "  原始加速度最大值: 14.90\n",
      "\n",
      "=== 陀螺仪数据解析 ===\n",
      "  数据点数: 12051\n",
      "  Z轴角速度范围: -0.529 - 0.596 rad/s\n",
      "🔍 Step 2: Extracting driving features...\n",
      "\n",
      "=== GPS特征提取 ===\n",
      "GPS加速度计算结果:\n",
      "  非零值: 0/667 (0.0%)\n",
      "  范围: 0.000 - 0.000 m/s²\n",
      "  平均: 0.000 m/s²\n",
      "  标准差: 0.000 m/s²\n",
      "⚠️  GPS加速度计算异常，使用改进的合成方法...\n",
      "  合成加速度范围: -8.000 - 8.000 m/s²\n",
      "\n",
      "=== 加速度传感器特征提取 ===\n",
      "Magnitude统计: 4.599 - 14.913\n",
      "Magnitude变化统计: -5.348178 - 5.949456\n",
      "时间间隔统计: 0.000000 - 0.000221 秒\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'jerks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1202\u001b[0m\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;66;03m# 执行完整分析\u001b[39;00m\n\u001b[0;32m-> 1202\u001b[0m analyzer \u001b[38;5;241m=\u001b[39m run_complete_eco_driving_analysis(data_file, startup_config)\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m analyzer:\n\u001b[1;32m   1205\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m🎉 Analysis completed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[25], line 1134\u001b[0m, in \u001b[0;36mrun_complete_eco_driving_analysis\u001b[0;34m(data_file, config)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;66;03m# 2. 提取特征\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🔍 Step 2: Extracting driving features...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m analyzer\u001b[38;5;241m.\u001b[39mextract_driving_features():\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m❌ Failed to extract features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[25], line 355\u001b[0m, in \u001b[0;36mEcoDrivingAnalyzer.extract_driving_features\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(acc_df)):\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 355\u001b[0m         jerks\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m0.0\u001b[39m)\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    357\u001b[0m         dt \u001b[38;5;241m=\u001b[39m dt_acc\u001b[38;5;241m.\u001b[39miloc[i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jerks' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.signal import savgol_filter\n",
    "from geopy.distance import geodesic\n",
    "import warnings\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "# 配置日志和常量\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 系统常量 - 修正为微秒\n",
    "GRAVITY = 9.81\n",
    "MAX_TIME_DIFF = 5000000  # 最大时间差（微秒）5秒\n",
    "MAX_SAMPLES = 100000     # 增加最大样本数\n",
    "VERSION = \"2.1\"\n",
    "\n",
    "class EcoDrivingAnalyzer:\n",
    "    \"\"\"生态驾驶分析主类 - 微秒时间戳版本\"\"\"\n",
    "    \n",
    "    def __init__(self, config=None):\n",
    "        \"\"\"初始化分析器\"\"\"\n",
    "        self.config = config or self._default_config()\n",
    "        self.raw_data = {}\n",
    "        self.processed_data = None\n",
    "        self.features = {}\n",
    "        self.results = {}\n",
    "        self.time_offset = None  # 用于计算相对时间\n",
    "        \n",
    "        logger.info(f\"EcoDrivingAnalyzer v{VERSION} initialized (microsecond timestamps)\")\n",
    "    \n",
    "    def _default_config(self):\n",
    "        \"\"\"默认配置\"\"\"\n",
    "        return {\n",
    "            'hard_brake_threshold': -2.5,\n",
    "            'speed_drop_threshold': 8,\n",
    "            'min_brake_speed': 15,\n",
    "            'energy_model': {\n",
    "                'vehicle_mass': 1800,          # 更轻的乘用车\n",
    "                'drag_coefficient': 0.28,      # 现代轿车风阻系数\n",
    "                'frontal_area': 2.3,           # 现代轿车迎风面积\n",
    "                'rolling_resistance': 0.012    # 现代轮胎滚动阻力\n",
    "            },\n",
    "            'clustering': {\n",
    "                'n_clusters': 3,\n",
    "                'features': ['speed', 'acceleration', 'jerk', 'turning_rate']\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def parse_sensor_data(self, file_path):\n",
    "        \"\"\"解析传感器数据文件 - 修正微秒时间戳处理\"\"\"\n",
    "        logger.info(f\"Parsing sensor data from {file_path}\")\n",
    "        \n",
    "        gps_rows, acc_rows, gyro_rows, rot_rows = [], [], [], []\n",
    "        total_rows = 0\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, \"r\") as file:\n",
    "                for line_num, line in enumerate(file):\n",
    "                    values = line.strip().split(\",\")\n",
    "                    if len(values) < 2:\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        data_type = int(values[0])\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                    \n",
    "                    # 修正数据解析逻辑\n",
    "                    if data_type == 0 and len(values) >= 6:  # GPS数据\n",
    "                        gps_rows.append(values)\n",
    "                    elif data_type == 1 and len(values) >= 5:  # 加速度计数据\n",
    "                        acc_rows.append(values)\n",
    "                    elif data_type == 2 and len(values) >= 5:  # 陀螺仪数据\n",
    "                        gyro_rows.append(values)\n",
    "                    elif data_type == 3 and len(values) >= 6:  # 四元数数据\n",
    "                        rot_rows.append(values)\n",
    "                    \n",
    "                    total_rows += 1\n",
    "                    if total_rows >= MAX_SAMPLES:\n",
    "                        break\n",
    "            \n",
    "            logger.info(f\"Parsed {total_rows} lines from {file_path}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading file: {e}\")\n",
    "            return False\n",
    "        \n",
    "        # 处理GPS数据\n",
    "        if gps_rows:\n",
    "            print(f\"\\n=== GPS数据解析 ===\")\n",
    "            print(f\"GPS原始行数: {len(gps_rows)}\")\n",
    "            print(f\"样本数据: {gps_rows[0]}\")\n",
    "            \n",
    "            # 处理GPS数据格式：0,timestamp,lat,lon,alt,speed_kmh,satellites\n",
    "            gps_data = []\n",
    "            for row in gps_rows:\n",
    "                try:\n",
    "                    if len(row) >= 6:\n",
    "                        gps_data.append([\n",
    "                            int(row[0]),      # data_type\n",
    "                            int(row[1]),      # timestamp (微秒)\n",
    "                            float(row[2]),    # latitude\n",
    "                            float(row[3]),    # longitude\n",
    "                            float(row[4]),    # altitude\n",
    "                            float(row[5]),    # speed_kmh\n",
    "                            int(row[6]) if len(row) > 6 else 12  # satellites\n",
    "                        ])\n",
    "                except (ValueError, IndexError) as e:\n",
    "                    continue\n",
    "            \n",
    "            if gps_data:\n",
    "                gps_df = pd.DataFrame(gps_data, columns=[\n",
    "                    \"data_type\", \"timestamp\", \"latitude\", \"longitude\", \n",
    "                    \"altitude\", \"speed_kmh\", \"satellites\"\n",
    "                ])\n",
    "                \n",
    "                gps_df[\"speed_ms\"] = gps_df[\"speed_kmh\"] / 3.6\n",
    "                \n",
    "                # 设置时间偏移量\n",
    "                if self.time_offset is None:\n",
    "                    self.time_offset = gps_df['timestamp'].min()\n",
    "                \n",
    "                # 计算相对时间（秒）\n",
    "                gps_df['relative_time_s'] = (gps_df['timestamp'] - self.time_offset) / 1000000.0\n",
    "                \n",
    "                print(f\"GPS数据质量检查:\")\n",
    "                print(f\"  数据点数: {len(gps_df)}\")\n",
    "                print(f\"  时间跨度: {gps_df['relative_time_s'].max():.1f} 秒 ({gps_df['relative_time_s'].max()/60:.1f} 分钟)\")\n",
    "                print(f\"  速度范围: {gps_df['speed_kmh'].min():.1f} - {gps_df['speed_kmh'].max():.1f} km/h\")\n",
    "                print(f\"  位置变化: 纬度 {gps_df['latitude'].max()-gps_df['latitude'].min():.6f}°, 经度 {gps_df['longitude'].max()-gps_df['longitude'].min():.6f}°\")\n",
    "                \n",
    "                # 数据清洗\n",
    "                gps_df = gps_df[gps_df[\"speed_kmh\"] <= 200]\n",
    "                gps_df = gps_df[gps_df[\"latitude\"].between(-90, 90)]\n",
    "                gps_df = gps_df[gps_df[\"longitude\"].between(-180, 180)]\n",
    "                \n",
    "                self.raw_data['gps'] = gps_df\n",
    "        \n",
    "        # 处理加速度传感器数据\n",
    "        if acc_rows:\n",
    "            print(f\"\\n=== 加速度传感器数据解析 ===\")\n",
    "            print(f\"加速度原始行数: {len(acc_rows)}\")\n",
    "            print(f\"样本数据: {acc_rows[0]}\")\n",
    "            \n",
    "            # 处理加速度数据格式：1,timestamp,timestamp_us,x,y,z\n",
    "            acc_data = []\n",
    "            for row in acc_rows:\n",
    "                try:\n",
    "                    if len(row) >= 5:\n",
    "                        acc_data.append([\n",
    "                            int(row[0]),      # data_type\n",
    "                            int(row[1]),      # timestamp (微秒)\n",
    "                            int(row[2]),      # timestamp_us (额外的微秒)\n",
    "                            float(row[3]),    # x\n",
    "                            float(row[4]),    # y\n",
    "                            float(row[5]) if len(row) > 5 else 0.0  # z\n",
    "                        ])\n",
    "                except (ValueError, IndexError):\n",
    "                    continue\n",
    "            \n",
    "            if acc_data:\n",
    "                acc_df = pd.DataFrame(acc_data, columns=[\n",
    "                    \"data_type\", \"timestamp\", \"timestamp_us\", \"x\", \"y\", \"z\"\n",
    "                ])\n",
    "                \n",
    "                # 计算完整时间戳（主时间戳 + 微秒偏移）\n",
    "                acc_df['full_timestamp'] = acc_df['timestamp'] + acc_df['timestamp_us']\n",
    "                \n",
    "                if self.time_offset is None:\n",
    "                    self.time_offset = acc_df['full_timestamp'].min()\n",
    "                \n",
    "                acc_df['relative_time_s'] = (acc_df['full_timestamp'] - self.time_offset) / 1000000.0\n",
    "                \n",
    "                print(f\"加速度数据质量检查:\")\n",
    "                print(f\"  数据点数: {len(acc_df)}\")\n",
    "                print(f\"  时间跨度: {acc_df['relative_time_s'].max():.1f} 秒\")\n",
    "                \n",
    "                # 检查加速度范围和缩放\n",
    "                max_acc = max(acc_df['x'].abs().max(), acc_df['y'].abs().max(), acc_df['z'].abs().max())\n",
    "                print(f\"  原始加速度最大值: {max_acc:.2f}\")\n",
    "                \n",
    "                # 智能缩放 - 根据数据范围判断单位\n",
    "                if max_acc > 50:  # 如果数值很大，可能需要缩放\n",
    "                    if max_acc > 1000:\n",
    "                        scale_factor = 1000.0\n",
    "                        print(\"  检测到加速度单位可能是 mg，应用1000x缩放\")\n",
    "                    else:\n",
    "                        scale_factor = 10.0\n",
    "                        print(\"  检测到加速度单位异常，应用10x缩放\")\n",
    "                    \n",
    "                    acc_df[[\"x\", \"y\", \"z\"]] = acc_df[[\"x\", \"y\", \"z\"]] / scale_factor\n",
    "                    print(f\"  缩放后范围: {acc_df['x'].min():.2f} - {acc_df['x'].max():.2f}\")\n",
    "                \n",
    "                acc_df[\"magnitude\"] = np.sqrt(acc_df[\"x\"]**2 + acc_df[\"y\"]**2 + acc_df[\"z\"]**2)\n",
    "                self.raw_data['acc'] = acc_df\n",
    "        \n",
    "        # 处理陀螺仪数据\n",
    "        if gyro_rows:\n",
    "            print(f\"\\n=== 陀螺仪数据解析 ===\")\n",
    "            gyro_data = []\n",
    "            for row in gyro_rows:\n",
    "                try:\n",
    "                    if len(row) >= 5:\n",
    "                        gyro_data.append([\n",
    "                            int(row[0]),      # data_type\n",
    "                            int(row[1]),      # timestamp\n",
    "                            int(row[2]),      # timestamp_us\n",
    "                            float(row[3]),    # x\n",
    "                            float(row[4]),    # y\n",
    "                            float(row[5]) if len(row) > 5 else 0.0  # z\n",
    "                        ])\n",
    "                except (ValueError, IndexError):\n",
    "                    continue\n",
    "            \n",
    "            if gyro_data:\n",
    "                gyro_df = pd.DataFrame(gyro_data, columns=[\n",
    "                    \"data_type\", \"timestamp\", \"timestamp_us\", \"x\", \"y\", \"z\"\n",
    "                ])\n",
    "                gyro_df['full_timestamp'] = gyro_df['timestamp'] + gyro_df['timestamp_us']\n",
    "                \n",
    "                if self.time_offset is None:\n",
    "                    self.time_offset = gyro_df['full_timestamp'].min()\n",
    "                \n",
    "                gyro_df['relative_time_s'] = (gyro_df['full_timestamp'] - self.time_offset) / 1000000.0\n",
    "                gyro_df[\"turning_rate\"] = gyro_df[\"z\"].abs()\n",
    "                \n",
    "                print(f\"  数据点数: {len(gyro_df)}\")\n",
    "                print(f\"  Z轴角速度范围: {gyro_df['z'].min():.3f} - {gyro_df['z'].max():.3f} rad/s\")\n",
    "                \n",
    "                self.raw_data['gyro'] = gyro_df\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def extract_driving_features(self):\n",
    "        \"\"\"提取驾驶特征 - 修正时间处理\"\"\"\n",
    "        logger.info(\"Extracting driving features with microsecond precision\")\n",
    "        \n",
    "        # GPS路线特征\n",
    "        if 'gps' in self.raw_data and not self.raw_data['gps'].empty:\n",
    "            gps_df = self.raw_data['gps'].copy().sort_values('timestamp').reset_index(drop=True)\n",
    "            \n",
    "            print(f\"\\n=== GPS特征提取 ===\")\n",
    "            \n",
    "            # 计算距离和坡度\n",
    "            distances, gradients = [], []\n",
    "            for i in range(1, len(gps_df)):\n",
    "                p1 = (gps_df[\"latitude\"].iloc[i-1], gps_df[\"longitude\"].iloc[i-1])\n",
    "                p2 = (gps_df[\"latitude\"].iloc[i], gps_df[\"longitude\"].iloc[i])\n",
    "                try:\n",
    "                    d = geodesic(p1, p2).meters\n",
    "                except Exception:\n",
    "                    d = 0\n",
    "                distances.append(d)\n",
    "                \n",
    "                alt_diff = gps_df[\"altitude\"].iloc[i] - gps_df[\"altitude\"].iloc[i-1]\n",
    "                gradient = alt_diff / d if d > 0.5 else 0  # 距离>0.5米才计算坡度\n",
    "                gradients.append(gradient)\n",
    "            \n",
    "            if distances:\n",
    "                gps_df.loc[1:, \"distance\"] = distances\n",
    "                gps_df.loc[1:, \"gradient\"] = gradients\n",
    "            gps_df[\"distance\"] = gps_df.get(\"distance\", 0).fillna(0)\n",
    "            gps_df[\"gradient\"] = gps_df.get(\"gradient\", 0).fillna(0)\n",
    "            \n",
    "            # 修正的加速度计算 - 使用微秒精度\n",
    "            dt_values = gps_df[\"timestamp\"].diff() / 1000000.0  # 转换为秒\n",
    "            speed_changes_ms = gps_df[\"speed_ms\"].diff()\n",
    "            \n",
    "            accelerations = []\n",
    "            for i in range(len(gps_df)):\n",
    "                if i == 0:\n",
    "                    accelerations.append(0.0)\n",
    "                else:\n",
    "                    dt = dt_values.iloc[i]\n",
    "                    speed_change = speed_changes_ms.iloc[i]\n",
    "                    \n",
    "                    # 修正时间范围检查\n",
    "                    if 0.01 < dt < 300:  # 10ms 到 5分钟\n",
    "                        acc = speed_change / dt\n",
    "                        acc = max(-12, min(12, acc))  # 合理的加速度范围\n",
    "                        accelerations.append(acc)\n",
    "                    else:\n",
    "                        # 对于异常时间间隔，使用前一个加速度的衰减值\n",
    "                        if i > 1:\n",
    "                            accelerations.append(accelerations[-1] * 0.8)\n",
    "                        else:\n",
    "                            accelerations.append(0.0)\n",
    "            \n",
    "            gps_df[\"acceleration\"] = accelerations\n",
    "            \n",
    "            # 检查GPS加速度计算结果\n",
    "            acc_nonzero = (np.array(accelerations) != 0).sum()\n",
    "            acc_range = [min(accelerations), max(accelerations)]\n",
    "            \n",
    "            print(f\"GPS加速度计算结果:\")\n",
    "            print(f\"  非零值: {acc_nonzero}/{len(accelerations)} ({acc_nonzero/len(accelerations)*100:.1f}%)\")\n",
    "            print(f\"  范围: {acc_range[0]:.3f} - {acc_range[1]:.3f} m/s²\")\n",
    "            print(f\"  平均: {np.mean(accelerations):.3f} m/s²\")\n",
    "            print(f\"  标准差: {np.std(accelerations):.3f} m/s²\")\n",
    "            \n",
    "            # 如果GPS加速度仍然问题很大，使用改进的合成方法\n",
    "            if abs(max(accelerations)) < 0.01 or acc_nonzero < len(accelerations) * 0.1:\n",
    "                print(\"⚠️  GPS加速度计算异常，使用改进的合成方法...\")\n",
    "                \n",
    "                # 使用速度的变化趋势生成更真实的加速度\n",
    "                speed_smooth = gps_df['speed_ms'].rolling(window=3, center=True).mean().fillna(gps_df['speed_ms'])\n",
    "                speed_diff = speed_smooth.diff()\n",
    "                time_diff = gps_df['relative_time_s'].diff()\n",
    "                \n",
    "                synthetic_acc = []\n",
    "                for i in range(len(gps_df)):\n",
    "                    if i == 0:\n",
    "                        synthetic_acc.append(0.0)\n",
    "                    else:\n",
    "                        dt = time_diff.iloc[i]\n",
    "                        if dt > 0:\n",
    "                            acc = speed_diff.iloc[i] / dt\n",
    "                            acc = max(-8, min(8, acc))\n",
    "                            synthetic_acc.append(acc)\n",
    "                        else:\n",
    "                            synthetic_acc.append(0.0)\n",
    "                \n",
    "                gps_df['acceleration'] = synthetic_acc\n",
    "                print(f\"  合成加速度范围: {min(synthetic_acc):.3f} - {max(synthetic_acc):.3f} m/s²\")\n",
    "            \n",
    "            self.features['route'] = gps_df\n",
    "        \n",
    "        # 加速度传感器特征 - 修正时间处理\n",
    "        if 'acc' in self.raw_data and not self.raw_data['acc'].empty:\n",
    "            acc_df = self.raw_data['acc'].copy().sort_values('full_timestamp').reset_index(drop=True)\n",
    "            \n",
    "            print(f\"\\n=== 加速度传感器特征提取 ===\")\n",
    "            \n",
    "            # 计算Jerk（急动度）- 使用微秒精度\n",
    "            dt_acc = acc_df[\"full_timestamp\"].diff() / 1000000.0  # 转换为秒\n",
    "            magnitude_changes = acc_df[\"magnitude\"].diff()\n",
    "\n",
    "            # 调试：检查magnitude变化\n",
    "            print(f\"Magnitude统计: {acc_df['magnitude'].min():.3f} - {acc_df['magnitude'].max():.3f}\")\n",
    "            print(f\"Magnitude变化统计: {magnitude_changes.min():.6f} - {magnitude_changes.max():.6f}\")\n",
    "            print(f\"时间间隔统计: {dt_acc.min():.6f} - {dt_acc.max():.6f} 秒\")\n",
    "            \n",
    "            for i in range(len(acc_df)):\n",
    "                if i == 0:\n",
    "                    jerks.append(0.0)\n",
    "                else:\n",
    "                    dt = dt_acc.iloc[i]\n",
    "                    mag_change = magnitude_changes.iloc[i]\n",
    "                    \n",
    "                    # 修正时间范围 - 加速度计采样频率更高\n",
    "                    if 0.001 < dt < 1.0:  # 1ms 到 1秒\n",
    "                        jerk = mag_change / dt\n",
    "                        jerk = max(-100, min(100, jerk))  # 扩大jerk范围\n",
    "                        jerks.append(jerk)\n",
    "                    else:\n",
    "                        jerks.append(0.0)\n",
    "            \n",
    "            acc_df[\"jerk\"] = jerks\n",
    "            \n",
    "            # 改进的平滑处理\n",
    "            if len(acc_df) > 5:\n",
    "                # 使用更小的窗口保持瞬时特性\n",
    "                win = min(3, len(acc_df)//2*2+1)\n",
    "                if win >= 3:\n",
    "                    acc_df[\"jerk_smooth\"] = savgol_filter(acc_df[\"jerk\"], win, 1)\n",
    "                else:\n",
    "                    acc_df[\"jerk_smooth\"] = acc_df[\"jerk\"]\n",
    "            else:\n",
    "                acc_df[\"jerk_smooth\"] = acc_df[\"jerk\"]\n",
    "            \n",
    "            print(f\"Jerk计算结果:\")\n",
    "            print(f\"  原始范围: {min(jerks):.3f} - {max(jerks):.3f} m/s³\")\n",
    "            print(f\"  平滑后范围: {acc_df['jerk_smooth'].min():.3f} - {acc_df['jerk_smooth'].max():.3f} m/s³\")\n",
    "            print(f\"  非零值: {(np.array(jerks) != 0).sum()}/{len(jerks)}\")\n",
    "            \n",
    "            self.features['behavior'] = acc_df\n",
    "        \n",
    "        # 陀螺仪转向特征\n",
    "        if 'gyro' in self.raw_data and not self.raw_data['gyro'].empty:\n",
    "            self.features['turning'] = self.raw_data['gyro'].copy()\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def detect_hard_brake_events(self):\n",
    "        \"\"\"检测急刹车事件 - 修正版\"\"\"\n",
    "        logger.info(\"Detecting hard brake events with improved algorithm\")\n",
    "        \n",
    "        if 'route' not in self.features:\n",
    "            logger.warning(\"No route data available for hard brake detection\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        df = self.features['route'].copy()\n",
    "        \n",
    "        # 数据平滑\n",
    "        if len(df) > 5:\n",
    "            window_size = min(5, len(df) // 2 * 2 + 1)\n",
    "            df['speed_smooth'] = savgol_filter(df['speed_kmh'], window_size, 2)\n",
    "        else:\n",
    "            df['speed_smooth'] = df['speed_kmh']\n",
    "        \n",
    "        # 速度变化分析 - 使用相对时间\n",
    "        df['speed_change'] = df['speed_smooth'].diff()\n",
    "        time_diff_s = df['relative_time_s'].diff()\n",
    "        df['speed_change_rate'] = df['speed_change'] / time_diff_s\n",
    "        df['speed_change_pct'] = df['speed_change'] / (df['speed_smooth'].shift(1) + 1)\n",
    "        \n",
    "        # 针对低速场景调整的急刹车检测条件\n",
    "        conditions = [\n",
    "            # 条件1: 适应低速的绝对速度下降\n",
    "            (df['speed_change'] < -5) & (df['speed_smooth'] > 10),  # 降低速度阈值\n",
    "            \n",
    "            # 条件2: 相对速度变化\n",
    "            (df['speed_change_pct'] < -0.20) & (df['speed_smooth'] > 8),  # 提高相对变化敏感度\n",
    "            \n",
    "            # 条件3: 速度变化率（针对起步阶段）\n",
    "            (df['speed_change_rate'] < -8) & (df['speed_smooth'] > 5),  # 降低速度阈值\n",
    "        ]\n",
    "        \n",
    "        df['hard_brake_candidate'] = np.logical_or.reduce(conditions)\n",
    "        \n",
    "        # 速度峰值检测 - 针对低速优化\n",
    "        df['is_speed_peak'] = False\n",
    "        df['hard_brake_refined'] = False\n",
    "        \n",
    "        # 寻找局部速度峰值（降低阈值适应低速）\n",
    "        for i in range(2, len(df) - 2):\n",
    "            current_speed = df['speed_smooth'].iloc[i]\n",
    "            prev_speed = df['speed_smooth'].iloc[i-1]\n",
    "            next_speed = df['speed_smooth'].iloc[i+1]\n",
    "            \n",
    "            if (current_speed > prev_speed and current_speed > next_speed and current_speed > 8):  # 降低峰值阈值\n",
    "                df.loc[i, 'is_speed_peak'] = True\n",
    "        \n",
    "        # 在峰值后检测急刹车\n",
    "        for i in range(len(df)):\n",
    "            if df['is_speed_peak'].iloc[i]:\n",
    "                peak_speed = df['speed_smooth'].iloc[i]\n",
    "                \n",
    "                for j in range(i+1, min(i+6, len(df))):\n",
    "                    current_speed = df['speed_smooth'].iloc[j]\n",
    "                    speed_drop = peak_speed - current_speed\n",
    "                    time_span = df['relative_time_s'].iloc[j] - df['relative_time_s'].iloc[i]\n",
    "                    \n",
    "                    # 针对低速调整的急刹车条件\n",
    "                    if speed_drop > 8 and time_span < 5:  # 降低速度下降阈值\n",
    "                        df.loc[j, 'hard_brake_refined'] = True\n",
    "                        break\n",
    "        \n",
    "        # 最终急刹车事件\n",
    "        df['hard_brake_final'] = df['hard_brake_candidate'] | df['hard_brake_refined']\n",
    "        \n",
    "        # 去重处理\n",
    "        df['hard_brake_filtered'] = False\n",
    "        if df['hard_brake_final'].any():\n",
    "            brake_indices = df[df['hard_brake_final']].index\n",
    "            filtered_indices = [brake_indices[0]] if len(brake_indices) > 0 else []\n",
    "            \n",
    "            for i in range(1, len(brake_indices)):\n",
    "                time_gap = df['relative_time_s'].iloc[brake_indices[i]] - df['relative_time_s'].iloc[brake_indices[i-1]]\n",
    "                if time_gap > 2.0:  # 2秒间隔\n",
    "                    filtered_indices.append(brake_indices[i])\n",
    "            \n",
    "            if filtered_indices:\n",
    "                df.loc[filtered_indices, 'hard_brake_filtered'] = True\n",
    "        \n",
    "        hard_brake_events = df[df['hard_brake_filtered']]\n",
    "        \n",
    "        print(f\"\\n=== 急刹车检测结果 ===\")\n",
    "        print(f\"候选事件: {df['hard_brake_candidate'].sum()}\")\n",
    "        print(f\"精炼事件: {df['hard_brake_refined'].sum()}\")\n",
    "        print(f\"最终检测到: {len(hard_brake_events)} 个急刹车事件\")\n",
    "        \n",
    "        if not hard_brake_events.empty:\n",
    "            print(\"急刹车事件详情:\")\n",
    "            for i, (idx, event) in enumerate(hard_brake_events.iterrows()):\n",
    "                time_min = event['relative_time_s'] / 60\n",
    "                print(f\"  事件{i+1}: {time_min:.1f}分钟 - 速度: {event['speed_kmh']:.1f} km/h, 加速度: {event['acceleration']:.2f} m/s²\")\n",
    "        \n",
    "        # 更新路线数据\n",
    "        self.features['route'] = df\n",
    "        \n",
    "        return hard_brake_events\n",
    "    \n",
    "    def synchronize_and_model_energy(self):\n",
    "        \"\"\"数据同步和能耗建模 - 微秒精度版本\"\"\"\n",
    "        logger.info(\"Synchronizing data and modeling energy consumption (microsecond precision)\")\n",
    "        \n",
    "        if 'route' not in self.features or 'behavior' not in self.features:\n",
    "            logger.warning(\"Missing required data for energy modeling\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        route_df = self.features['route']\n",
    "        behavior_df = self.features['behavior']\n",
    "        \n",
    "        # 使用微秒时间戳进行同步\n",
    "        route_times = route_df['timestamp'].values\n",
    "        behavior_times = behavior_df['full_timestamp'].values\n",
    "        \n",
    "        print(f\"\\n=== 数据同步 (微秒精度) ===\")\n",
    "        print(f\"GPS数据点: {len(route_df)}\")\n",
    "        print(f\"加速度数据点: {len(behavior_df)}\")\n",
    "        \n",
    "        combined_data = []\n",
    "        sync_errors = 0\n",
    "        perfect_matches = 0\n",
    "        \n",
    "        for i, row in route_df.iterrows():\n",
    "            gps_time = row['timestamp']\n",
    "            time_diffs = np.abs(behavior_times - gps_time)\n",
    "            closest_acc_idx = np.argmin(time_diffs)\n",
    "            min_time_diff = time_diffs[closest_acc_idx]\n",
    "            \n",
    "            if min_time_diff == 0:\n",
    "                perfect_matches += 1\n",
    "            elif min_time_diff > MAX_TIME_DIFF:\n",
    "                sync_errors += 1\n",
    "                continue\n",
    "            \n",
    "            entry = {\n",
    "                'timestamp': gps_time,\n",
    "                'relative_time_s': row['relative_time_s'],\n",
    "                'speed': row['speed_ms'],\n",
    "                'speed_kmh': row['speed_kmh'],\n",
    "                'acceleration': row['acceleration'],\n",
    "                'gradient': row['gradient'],\n",
    "                'jerk': behavior_df['jerk_smooth'].iloc[closest_acc_idx],\n",
    "                'sync_error_us': min_time_diff  # 微秒\n",
    "            }\n",
    "            \n",
    "            # 添加转向数据\n",
    "            if 'turning' in self.features:\n",
    "                turning_times = self.features['turning']['full_timestamp'].values\n",
    "                closest_turn_idx = np.argmin(np.abs(turning_times - gps_time))\n",
    "                turn_time_diff = np.abs(turning_times[closest_turn_idx] - gps_time)\n",
    "                \n",
    "                if turn_time_diff <= MAX_TIME_DIFF:\n",
    "                    entry['turning_rate'] = self.features['turning']['turning_rate'].iloc[closest_turn_idx]\n",
    "                else:\n",
    "                    entry['turning_rate'] = 0\n",
    "            else:\n",
    "                entry['turning_rate'] = 0\n",
    "            \n",
    "            combined_data.append(entry)\n",
    "        \n",
    "        if not combined_data:\n",
    "            logger.warning(\"No synchronized data points found\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        combined_df = pd.DataFrame(combined_data)\n",
    "        \n",
    "        # 能耗计算\n",
    "        combined_df['energy_factor'] = self._calculate_energy_consumption(combined_df)\n",
    "        \n",
    "        print(f\"同步结果:\")\n",
    "        print(f\"  完美匹配: {perfect_matches}\")\n",
    "        print(f\"  成功同步: {len(combined_data)}\")\n",
    "        print(f\"  同步错误: {sync_errors}\")\n",
    "        print(f\"  平均同步误差: {combined_df['sync_error_us'].mean():.0f} 微秒\")\n",
    "        \n",
    "        self.processed_data = combined_df\n",
    "        return combined_df\n",
    "    \n",
    "    def _calculate_energy_consumption(self, df):\n",
    "        \"\"\"计算能耗 - 修正版\"\"\"\n",
    "        config = self.config['energy_model']\n",
    "        mass = config['vehicle_mass']\n",
    "        g = GRAVITY\n",
    "        rho = 1.225  # 空气密度\n",
    "        Cd = config['drag_coefficient']\n",
    "        A = config['frontal_area']\n",
    "        Cr = config['rolling_resistance']\n",
    "        \n",
    "        power_W = np.zeros(len(df))\n",
    "        \n",
    "        for i in range(len(df)):\n",
    "            v = max(0.1, df['speed'].iloc[i])\n",
    "            θ = np.arctan(df['gradient'].iloc[i]) if abs(df['gradient'].iloc[i]) < 1 else 0\n",
    "            \n",
    "            F_roll = Cr * mass * g * np.cos(θ)\n",
    "            F_aero = 0.5 * rho * Cd * A * v**2\n",
    "            F_grad = mass * g * np.sin(θ)\n",
    "            F_acc = mass * df['acceleration'].iloc[i]\n",
    "            \n",
    "            F_total = F_roll + F_aero + F_grad + F_acc\n",
    "            F_traction = max(F_total, 0)\n",
    "            power_W[i] = F_traction * v\n",
    "        \n",
    "        # 计算能耗 - 使用相对时间\n",
    "        if len(df) > 1:\n",
    "            dt = df['relative_time_s'].diff().fillna(1.0)\n",
    "            dt = np.clip(dt, 0.01, 10.0)  # 限制时间间隔\n",
    "        else:\n",
    "            dt = np.array([1.0])\n",
    "        \n",
    "        df['energy_J'] = power_W * dt.values\n",
    "        \n",
    "        return power_W\n",
    "    \n",
    "    def cluster_driving_behaviors(self):\n",
    "        \"\"\"驾驶行为聚类 - 改进版\"\"\"\n",
    "        logger.info(\"Clustering driving behaviors with improved classification\")\n",
    "        \n",
    "        if self.processed_data is None or self.processed_data.empty:\n",
    "            logger.error(\"No processed data available for clustering\")\n",
    "            return {}, pd.DataFrame(), np.array([])\n",
    "        \n",
    "        data = self.processed_data.copy()\n",
    "        \n",
    "        # 确保所需列存在\n",
    "        required_cols = self.config['clustering']['features'] + ['energy_J']\n",
    "        for col in required_cols:\n",
    "            if col not in data.columns:\n",
    "                data[col] = 0.0\n",
    "        \n",
    "        print(f\"\\n=== 驾驶行为聚类 ===\")\n",
    "        for col in self.config['clustering']['features']:\n",
    "            if col in data.columns:\n",
    "                print(f\"{col}: {data[col].min():.3f} - {data[col].max():.3f} (均值: {data[col].mean():.3f})\")\n",
    "        \n",
    "        # K-Means聚类\n",
    "        feats = self.config['clustering']['features']\n",
    "        X = data[feats].fillna(0)\n",
    "        \n",
    "        # 数据标准化\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        # PCA降维\n",
    "        try:\n",
    "            pca = PCA(n_components=2)\n",
    "            X_pca = pca.fit_transform(X_scaled)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"PCA failed: {e}\")\n",
    "            X_pca = X_scaled[:, :2] if X_scaled.shape[1] >= 2 else np.column_stack([X_scaled[:, 0], X_scaled[:, 0]])\n",
    "        \n",
    "        n_clusters = min(self.config['clustering']['n_clusters'], max(1, len(X) - 1))\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        clusters = kmeans.fit_predict(X_scaled)\n",
    "        \n",
    "        data['driver_cluster'] = clusters\n",
    "        \n",
    "        # 生成聚类配置文件\n",
    "        cluster_profiles = {}\n",
    "        for cid in range(n_clusters):\n",
    "            data_c = data[data['driver_cluster'] == cid]\n",
    "            if data_c.empty:\n",
    "                cluster_profiles[cid] = {'size': 0, 'driver_type': 'unknown'}\n",
    "                continue\n",
    "            \n",
    "            # 计算统计指标\n",
    "            if len(data_c) > 1:\n",
    "                dt = data_c['relative_time_s'].diff().fillna(1.0)\n",
    "                dt = np.clip(dt, 0.01, 10.0)\n",
    "                total_time = dt.sum()\n",
    "                total_distance = (data_c['speed'] * dt).sum() / 1000.0  # km\n",
    "            else:\n",
    "                total_time = 1.0\n",
    "                total_distance = 0.001\n",
    "            \n",
    "            total_energy = data_c['energy_J'].sum() / 3600000.0  # kWh (J->kWh)\n",
    "            energy_eff = total_energy / max(total_distance, 0.001) * 100  # kWh/100km\n",
    "            \n",
    "            profile = {\n",
    "                'size': len(data_c),\n",
    "                'avg_speed': data_c['speed'].mean(),\n",
    "                'std_speed': data_c['speed'].std(),\n",
    "                'avg_acceleration': data_c['acceleration'].mean(),\n",
    "                'std_acceleration': data_c['acceleration'].std(),\n",
    "                'avg_jerk': data_c['jerk'].mean(),\n",
    "                'std_jerk': data_c['jerk'].std(),\n",
    "                'avg_turning_rate': data_c['turning_rate'].mean(),\n",
    "                'std_turning_rate': data_c['turning_rate'].std(),\n",
    "                'energy_efficiency': energy_eff,\n",
    "                'total_time_s': total_time,\n",
    "                'total_distance_km': total_distance,\n",
    "            }\n",
    "            \n",
    "            # 改进的驾驶类型分类 - 适应起步阶段\n",
    "            abs_avg_jerk = abs(profile['avg_jerk'])\n",
    "            abs_avg_acc = abs(profile['avg_acceleration'])\n",
    "            avg_speed = profile['avg_speed']\n",
    "            avg_turning = profile['avg_turning_rate']\n",
    "            \n",
    "            # 针对起步阶段的分类逻辑\n",
    "            if abs_avg_jerk > 15.0 and abs_avg_acc > 2.0:\n",
    "                profile['driver_type'] = 'aggressive'\n",
    "            elif avg_turning > 0.15:\n",
    "                profile['driver_type'] = 'cornering'\n",
    "            elif avg_speed > 8.0 and abs_avg_acc > 1.0:  # 调整速度阈值\n",
    "                profile['driver_type'] = 'dynamic'\n",
    "            elif avg_speed < 5.0 and abs_avg_jerk < 8.0:\n",
    "                profile['driver_type'] = 'cautious'\n",
    "            elif abs_avg_acc < 0.5 and abs_avg_jerk < 5.0:\n",
    "                profile['driver_type'] = 'efficient'\n",
    "            else:\n",
    "                profile['driver_type'] = 'normal'\n",
    "            \n",
    "            cluster_profiles[cid] = profile\n",
    "        \n",
    "        print(f\"聚类结果:\")\n",
    "        for cid, profile in cluster_profiles.items():\n",
    "            print(f\"  Cluster {cid} ({profile['driver_type']}): {profile['size']} 样本\")\n",
    "            print(f\"    速度: {profile['avg_speed']*3.6:.1f} km/h, 加速度: {profile['avg_acceleration']:.2f} m/s²\")\n",
    "            print(f\"    Jerk: {profile['avg_jerk']:.2f} m/s³, 能耗: {profile['energy_efficiency']:.1f} kWh/100km\")\n",
    "        \n",
    "        # 更新处理后的数据\n",
    "        self.processed_data = data\n",
    "        \n",
    "        # 在 cluster_driving_behaviors() 方法的最后，return 语句之前添加：\n",
    "        print(f\"DEBUG: type of self.processed_data after clustering: {type(self.processed_data)}\")\n",
    "        print(f\"DEBUG: processed_data columns: {self.processed_data.columns.tolist() if isinstance(self.processed_data, pd.DataFrame) else 'Not DataFrame'}\")\n",
    "        \n",
    "        return cluster_profiles, X_pca, clusters\n",
    "    \n",
    "    def generate_comprehensive_report(self):\n",
    "        \"\"\"生成综合分析报告\"\"\"\n",
    "        logger.info(\"Generating comprehensive analysis report\")\n",
    "        \n",
    "        if self.processed_data is None:\n",
    "            logger.error(\"No processed data available for report generation\")\n",
    "            return None\n",
    "        \n",
    "        # 基本统计\n",
    "        data = self.processed_data\n",
    "        total_time = data['relative_time_s'].max()  # 使用相对时间\n",
    "        total_distance = (data['speed'] * data['relative_time_s'].diff().fillna(1.0)).sum() / 1000.0  # km\n",
    "        avg_speed = data['speed'].mean() * 3.6  # km/h\n",
    "        max_speed = data['speed_kmh'].max()\n",
    "        \n",
    "        # 急刹车分析\n",
    "        hard_brake_events = self.detect_hard_brake_events()\n",
    "        \n",
    "        # 驾驶行为聚类\n",
    "        cluster_profiles, X_pca, clusters = self.cluster_driving_behaviors()\n",
    "\n",
    "        # 确保processed_data被正确更新\n",
    "        if self.processed_data is not None:\n",
    "            data = self.processed_data  # 使用更新后的数据\n",
    "        else:\n",
    "            logger.error(\"processed_data is None after clustering\")\n",
    "            return None\n",
    "        \n",
    "        # 生成报告\n",
    "        report = {\n",
    "            'metadata': {\n",
    "                'analysis_date': datetime.now().isoformat(),\n",
    "                'version': VERSION,\n",
    "                'data_points': len(data),\n",
    "                'duration_minutes': total_time / 60,\n",
    "                'total_distance_km': total_distance\n",
    "            },\n",
    "            'driving_summary': {\n",
    "                'max_speed_kmh': max_speed,\n",
    "                'avg_speed_kmh': avg_speed,\n",
    "                'total_hard_brakes': len(hard_brake_events),\n",
    "                'hard_brakes_per_hour': len(hard_brake_events) / max(total_time / 3600, 0.1)\n",
    "            },\n",
    "            'cluster_analysis': cluster_profiles,\n",
    "            'recommendations': self._generate_recommendations(cluster_profiles, hard_brake_events)\n",
    "        }\n",
    "        \n",
    "        self.results = {\n",
    "            'report': report,\n",
    "            'data': self.processed_data.copy(),\n",
    "            'hard_brake_events': hard_brake_events,\n",
    "            'cluster_profiles': cluster_profiles,\n",
    "            'pca_data': X_pca,\n",
    "            'clusters': clusters\n",
    "        }\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def _generate_recommendations(self, cluster_profiles, hard_brake_events):\n",
    "        \"\"\"生成驾驶建议\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        # 基于急刹车的建议\n",
    "        if len(hard_brake_events) > 3:  # 降低阈值适应起步阶段\n",
    "            recommendations.append({\n",
    "                'category': 'Safety',\n",
    "                'priority': 'High',\n",
    "                'message': 'Multiple hard braking events detected during startup phase. Consider smoother acceleration and anticipating traffic conditions.',\n",
    "                'impact': 'Reduces brake wear and improves passenger comfort'\n",
    "            })\n",
    "        elif len(hard_brake_events) == 0:\n",
    "            recommendations.append({\n",
    "                'category': 'Positive',\n",
    "                'priority': 'Low',\n",
    "                'message': 'Excellent! No hard braking events detected. Very smooth driving style.',\n",
    "                'impact': 'Optimal brake system preservation and passenger comfort'\n",
    "            })\n",
    "        \n",
    "        # 基于聚类分析的建议\n",
    "        for cid, profile in cluster_profiles.items():\n",
    "            if profile['driver_type'] == 'aggressive':\n",
    "                recommendations.append({\n",
    "                    'category': 'Efficiency',\n",
    "                    'priority': 'Medium',\n",
    "                    'message': f'Cluster {cid} shows aggressive driving patterns. Gentler acceleration can improve efficiency by 15-20%.',\n",
    "                    'impact': f'Current energy efficiency: {profile[\"energy_efficiency\"]:.1f} kWh/100km'\n",
    "                })\n",
    "            elif profile['driver_type'] == 'efficient':\n",
    "                recommendations.append({\n",
    "                    'category': 'Positive',\n",
    "                    'priority': 'Low',\n",
    "                    'message': f'Cluster {cid} demonstrates efficient driving behavior. Excellent energy management!',\n",
    "                    'impact': f'Outstanding energy efficiency: {profile[\"energy_efficiency\"]:.1f} kWh/100km'\n",
    "                })\n",
    "            elif profile['driver_type'] == 'cautious':\n",
    "                recommendations.append({\n",
    "                    'category': 'Performance',\n",
    "                    'priority': 'Low',\n",
    "                    'message': f'Cluster {cid} shows very cautious driving. Consider slightly more dynamic acceleration when safe.',\n",
    "                    'impact': 'May improve traffic flow while maintaining safety'\n",
    "                })\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def visualize_results(self, save_plots=True):\n",
    "        if not self.results:\n",
    "            logger.error(\"No results available for visualization\")\n",
    "            return\n",
    "        \n",
    "        # 调试：检查数据类型\n",
    "        print(f\"DEBUG: self.results keys: {list(self.results.keys())}\")\n",
    "        print(f\"DEBUG: type of self.results['data']: {type(self.results['data'])}\")\n",
    "        print(f\"DEBUG: type of self.processed_data: {type(self.processed_data)}\")\n",
    "        \n",
    "        # 直接使用 processed_data\n",
    "        data = self.processed_data\n",
    "        if data is None or not isinstance(data, pd.DataFrame):\n",
    "            logger.error(f\"Invalid processed_data type: {type(data)}\")\n",
    "            return\n",
    "        \n",
    "        hard_brake_events = self.results['hard_brake_events']\n",
    "        cluster_profiles = self.results['cluster_profiles']\n",
    "        \n",
    "        # 创建综合仪表板\n",
    "        fig = plt.figure(figsize=(20, 16))\n",
    "        \n",
    "        # 1. 速度时间曲线（使用相对时间）\n",
    "        ax1 = plt.subplot(3, 3, 1)\n",
    "        time_minutes = data['relative_time_s'] / 60\n",
    "        \n",
    "        plt.plot(time_minutes, data['speed_kmh'], 'b-', alpha=0.7, linewidth=2, label='Speed (km/h)')\n",
    "        \n",
    "        if not hard_brake_events.empty:\n",
    "            brake_times = hard_brake_events['relative_time_s'] / 60\n",
    "            plt.scatter(brake_times, hard_brake_events['speed_kmh'], \n",
    "                       color='red', marker='X', s=100, zorder=5, \n",
    "                       label=f'Hard Brakes ({len(hard_brake_events)})')\n",
    "            \n",
    "            # 添加急刹车标注\n",
    "            for i, (idx, event) in enumerate(hard_brake_events.iterrows()):\n",
    "                plt.annotate(f'Brake {i+1}', \n",
    "                           xy=(event['relative_time_s']/60, event['speed_kmh']),\n",
    "                           xytext=(10, 20), textcoords='offset points',\n",
    "                           bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.8),\n",
    "                           arrowprops=dict(arrowstyle='->', color='red'))\n",
    "        \n",
    "        plt.title('Speed Profile with Hard Brake Events\\n(Startup Phase Analysis)')\n",
    "        plt.xlabel('Time (minutes)')\n",
    "        plt.ylabel('Speed (km/h)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. 驾驶行为聚类PCA视图\n",
    "        ax2 = plt.subplot(3, 3, 2)\n",
    "        scatter = plt.scatter(self.results['pca_data'][:, 0], self.results['pca_data'][:, 1], \n",
    "                             c=self.results['clusters'], cmap='viridis', alpha=0.7, s=30)\n",
    "        plt.title('Driver Behavior Clusters\\n(PCA Visualization)')\n",
    "        plt.xlabel('PCA Component 1')\n",
    "        plt.ylabel('PCA Component 2')\n",
    "        plt.colorbar(scatter, label='Cluster')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. 加速度分布\n",
    "        ax3 = plt.subplot(3, 3, 3)\n",
    "        colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown']\n",
    "        for cluster in range(len(cluster_profiles)):\n",
    "            cluster_data = data[data['driver_cluster'] == cluster]\n",
    "            if not cluster_data.empty and 'acceleration' in cluster_data.columns:\n",
    "                plt.hist(cluster_data['acceleration'], bins=15, alpha=0.6, \n",
    "                        label=f'Cluster {cluster}', density=True, \n",
    "                        color=colors[cluster % len(colors)])\n",
    "        plt.title('Acceleration Distribution by Cluster\\n(Startup Phase)')\n",
    "        plt.xlabel('Acceleration (m/s²)')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Jerk分布\n",
    "        ax4 = plt.subplot(3, 3, 4)\n",
    "        for cluster in range(len(cluster_profiles)):\n",
    "            cluster_data = data[data['driver_cluster'] == cluster]\n",
    "            if not cluster_data.empty and 'jerk' in cluster_data.columns:\n",
    "                plt.hist(cluster_data['jerk'], bins=15, alpha=0.6, \n",
    "                        label=f'Cluster {cluster}', density=True,\n",
    "                        color=colors[cluster % len(colors)])\n",
    "        plt.title('Jerk Distribution by Cluster\\n(Instantaneous Values)')\n",
    "        plt.xlabel('Jerk (m/s³)')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 5. 驾驶类型分布\n",
    "        ax5 = plt.subplot(3, 3, 5)\n",
    "        driver_types = [cluster_profiles[cid]['driver_type'] for cid in cluster_profiles.keys()]\n",
    "        type_counts = {}\n",
    "        for dtype in driver_types:\n",
    "            type_counts[dtype] = type_counts.get(dtype, 0) + 1\n",
    "        \n",
    "        colors_pie = {'aggressive': 'red', 'dynamic': 'orange', 'cornering': 'purple', \n",
    "                      'efficient': 'green', 'cautious': 'blue', 'normal': 'cyan', 'unknown': 'gray'}\n",
    "        pie_colors = [colors_pie.get(dtype, 'gray') for dtype in type_counts.keys()]\n",
    "        \n",
    "        plt.pie(type_counts.values(), labels=type_counts.keys(), colors=pie_colors,\n",
    "                autopct='%1.1f%%', startangle=90)\n",
    "        plt.title('Driver Type Distribution\\n(Startup Phase)')\n",
    "        \n",
    "        # 6. 能耗效率对比\n",
    "        ax6 = plt.subplot(3, 3, 6)\n",
    "        cluster_ids = list(cluster_profiles.keys())\n",
    "        energy_effs = [cluster_profiles[cid]['energy_efficiency'] for cid in cluster_ids]\n",
    "        driver_types_list = [cluster_profiles[cid]['driver_type'] for cid in cluster_ids]\n",
    "        \n",
    "        bar_colors = [colors_pie.get(dtype, 'gray') for dtype in driver_types_list]\n",
    "        bars = plt.bar(range(len(cluster_ids)), energy_effs, color=bar_colors, alpha=0.8)\n",
    "        plt.title('Energy Efficiency by Cluster\\n(Startup Phase)')\n",
    "        plt.xlabel('Cluster')\n",
    "        plt.ylabel('Energy Efficiency (kWh/100km)')\n",
    "        plt.xticks(range(len(cluster_ids)), [f'C{cid}\\n({dtype})' for cid, dtype in zip(cluster_ids, driver_types_list)])\n",
    "        \n",
    "        for bar, eff in zip(bars, energy_effs):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(energy_effs)*0.01, \n",
    "                    f'{eff:.1f}', ha='center', va='bottom')\n",
    "        \n",
    "        # 7. 速度vs加速度散点图\n",
    "        ax7 = plt.subplot(3, 3, 7)\n",
    "        scatter = plt.scatter(data['speed_kmh'], data['acceleration'], \n",
    "                             c=data['driver_cluster'], cmap='viridis', alpha=0.6, s=20)\n",
    "        plt.title('Speed vs Acceleration\\n(Startup Phase)')\n",
    "        plt.xlabel('Speed (km/h)')\n",
    "        plt.ylabel('Acceleration (m/s²)')\n",
    "        plt.colorbar(scatter, label='Cluster')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 8. 时间序列加速度\n",
    "        ax8 = plt.subplot(3, 3, 8)\n",
    "        sample_size = min(200, len(data))\n",
    "        sample_data = data.head(sample_size)\n",
    "        sample_times = sample_data['relative_time_s'] / 60\n",
    "        \n",
    "        plt.plot(sample_times, sample_data['acceleration'], 'g-', alpha=0.7, linewidth=1)\n",
    "        plt.title(f'Acceleration Time Series\\n(First {sample_size} points)')\n",
    "        plt.xlabel('Time (minutes)')\n",
    "        plt.ylabel('Acceleration (m/s²)')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 9. 综合评分仪表盘\n",
    "        ax9 = plt.subplot(3, 3, 9)\n",
    "        \n",
    "        # 计算评分 - 适应起步阶段\n",
    "        total_events = len(hard_brake_events)\n",
    "        total_time_hours = data['relative_time_s'].max() / 3600\n",
    "        events_per_hour = total_events / max(total_time_hours, 0.1)\n",
    "        \n",
    "        avg_energy_eff = np.mean([p['energy_efficiency'] for p in cluster_profiles.values()])\n",
    "        \n",
    "        # 评分计算（针对起步阶段调整）\n",
    "        safety_score = max(0, 100 - events_per_hour * 15)  # 起步阶段降低惩罚\n",
    "        efficiency_score = max(0, 100 - max(0, avg_energy_eff - 25) * 2)  # 起步阶段能耗可能较高\n",
    "        smoothness_score = 100 - min(50, np.mean([abs(p['avg_jerk']) for p in cluster_profiles.values()]) * 2)\n",
    "        overall_score = (safety_score + efficiency_score + smoothness_score) / 3\n",
    "        \n",
    "        # 绘制仪表盘\n",
    "        scores = [safety_score, efficiency_score, smoothness_score, overall_score]\n",
    "        labels = ['Safety', 'Efficiency', 'Smoothness', 'Overall']\n",
    "        colors_gauge = ['red', 'green', 'blue', 'purple']\n",
    "        \n",
    "        bars = plt.bar(labels, scores, color=colors_gauge, alpha=0.7)\n",
    "        plt.ylim(0, 100)\n",
    "        plt.title('Eco-Driving Score Dashboard\\n(Startup Phase)')\n",
    "        plt.ylabel('Score (0-100)')\n",
    "        \n",
    "        for bar, score in zip(bars, scores):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2, \n",
    "                    f'{score:.0f}', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_plots:\n",
    "            plt.savefig('eco_driving_startup_analysis.png', dpi=300, bbox_inches='tight')\n",
    "            logger.info(\"Saved startup phase analysis plot\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def save_results(self, output_dir='eco_driving_results'):\n",
    "        \"\"\"保存分析结果\"\"\"\n",
    "        if not self.results:\n",
    "            logger.error(\"No results to save\")\n",
    "            return False\n",
    "        \n",
    "        # 创建输出目录\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            # 保存主要数据\n",
    "            self.results['data'].to_csv(f'{output_dir}/processed_data.csv', index=False)\n",
    "            \n",
    "            if not self.results['hard_brake_events'].empty:\n",
    "                self.results['hard_brake_events'].to_csv(f'{output_dir}/hard_brake_events.csv', index=False)\n",
    "            \n",
    "            # 保存JSON报告\n",
    "            with open(f'{output_dir}/analysis_report.json', 'w', encoding='utf-8') as f:\n",
    "                json.dump(self.results['report'], f, indent=2, ensure_ascii=False, default=str)\n",
    "            \n",
    "            # 保存文本报告\n",
    "            self._save_text_report(f'{output_dir}/eco_driving_report.txt')\n",
    "            \n",
    "            logger.info(f\"Results saved to {output_dir}/\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving results: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def _save_text_report(self, filepath):\n",
    "        \"\"\"保存详细文本报告\"\"\"\n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            report = self.results['report']\n",
    "            cluster_profiles = self.results['cluster_profiles']\n",
    "            hard_brake_events = self.results['hard_brake_events']\n",
    "            \n",
    "            f.write(\"=\" * 80 + \"\\n\")\n",
    "            f.write(\"ECO-DRIVING ANALYSIS REPORT - STARTUP PHASE\\n\")\n",
    "            f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "            \n",
    "            # 基本信息\n",
    "            f.write(f\"Analysis Date: {report['metadata']['analysis_date']}\\n\")\n",
    "            f.write(f\"System Version: {report['metadata']['version']} (Microsecond Precision)\\n\")\n",
    "            f.write(f\"Data Points: {report['metadata']['data_points']}\\n\")\n",
    "            f.write(f\"Duration: {report['metadata']['duration_minutes']:.1f} minutes\\n\")\n",
    "            f.write(f\"Total Distance: {report['metadata']['total_distance_km']:.3f} km\\n\\n\")\n",
    "            \n",
    "            # 驾驶摘要\n",
    "            f.write(\"DRIVING SUMMARY (STARTUP PHASE):\\n\")\n",
    "            f.write(\"-\" * 40 + \"\\n\")\n",
    "            f.write(f\"Maximum Speed: {report['driving_summary']['max_speed_kmh']:.1f} km/h\\n\")\n",
    "            f.write(f\"Average Speed: {report['driving_summary']['avg_speed_kmh']:.1f} km/h\\n\")\n",
    "            f.write(f\"Total Hard Brakes: {report['driving_summary']['total_hard_brakes']}\\n\")\n",
    "            f.write(f\"Hard Brakes per Hour: {report['driving_summary']['hard_brakes_per_hour']:.1f}\\n\\n\")\n",
    "            \n",
    "            # 聚类分析\n",
    "            f.write(\"DRIVER BEHAVIOR CLUSTERS (STARTUP PHASE):\\n\")\n",
    "            f.write(\"-\" * 40 + \"\\n\")\n",
    "            for cid, profile in cluster_profiles.items():\n",
    "                f.write(f\"\\nCluster {cid} - {profile['driver_type'].upper()}:\\n\")\n",
    "                f.write(f\"  Sample Size: {profile['size']} points\\n\")\n",
    "                f.write(f\"  Average Speed: {profile['avg_speed']*3.6:.1f} km/h\\n\")\n",
    "                f.write(f\"  Average Acceleration: {profile['avg_acceleration']:.3f} m/s²\\n\")\n",
    "                f.write(f\"  Average Jerk: {profile['avg_jerk']:.3f} m/s³ (instantaneous)\\n\")\n",
    "                f.write(f\"  Average Turning Rate: {profile['avg_turning_rate']:.3f} rad/s\\n\")\n",
    "                f.write(f\"  Energy Efficiency: {profile['energy_efficiency']:.2f} kWh/100km\\n\")\n",
    "                f.write(f\"  Total Distance: {profile['total_distance_km']:.4f} km\\n\")\n",
    "                f.write(f\"  Total Time: {profile['total_time_s']:.1f} seconds\\n\")\n",
    "            \n",
    "            # 急刹车详情\n",
    "            f.write(f\"\\nHARD BRAKE EVENTS DETAIL:\\n\")\n",
    "            f.write(\"-\" * 40 + \"\\n\")\n",
    "            if not hard_brake_events.empty:\n",
    "                for i, (idx, event) in enumerate(hard_brake_events.iterrows()):\n",
    "                    time_min = event['relative_time_s'] / 60\n",
    "                    f.write(f\"  Event {i+1}: {time_min:.1f} min - Speed: {event['speed_kmh']:.1f} km/h, \"\n",
    "                           f\"Acceleration: {event['acceleration']:.2f} m/s²\\n\")\n",
    "            else:\n",
    "                f.write(\"  No hard brake events detected - Excellent smooth driving!\\n\")\n",
    "            \n",
    "            # 建议\n",
    "            f.write(f\"\\nRECOMMENDATIONS:\\n\")\n",
    "            f.write(\"-\" * 40 + \"\\n\")\n",
    "            for i, rec in enumerate(report['recommendations']):\n",
    "                f.write(f\"{i+1}. [{rec['category']} - {rec['priority']}] {rec['message']}\\n\")\n",
    "                f.write(f\"   Impact: {rec['impact']}\\n\\n\")\n",
    "            \n",
    "            # 技术说明\n",
    "            f.write(\"TECHNICAL NOTES:\\n\")\n",
    "            f.write(\"-\" * 20 + \"\\n\")\n",
    "            f.write(\"• Timestamp precision: Microseconds\\n\")\n",
    "            f.write(\"• Analysis focus: Vehicle startup phase\\n\")\n",
    "            f.write(\"• Jerk calculation: Instantaneous values preserved\\n\")\n",
    "            f.write(\"• Acceleration: Real GPS-based calculation with synthetic backup\\n\")\n",
    "            f.write(\"• Energy model: Adapted for low-speed urban driving\\n\")\n",
    "\n",
    "# 主要使用接口\n",
    "def run_complete_eco_driving_analysis(data_file, config=None):\n",
    "    \"\"\"\n",
    "    运行完整的生态驾驶分析 - 微秒时间戳版本\n",
    "    \n",
    "    Args:\n",
    "        data_file: 传感器数据文件路径\n",
    "        config: 可选配置字典\n",
    "    \n",
    "    Returns:\n",
    "        EcoDrivingAnalyzer实例，包含所有分析结果\n",
    "    \"\"\"\n",
    "    print(\"🚗 Starting Complete Eco-Driving Analysis System v2.1\")\n",
    "    print(\"📍 Optimized for startup phase analysis with microsecond precision\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # 初始化分析器\n",
    "    analyzer = EcoDrivingAnalyzer(config)\n",
    "    \n",
    "    # 1. 解析数据\n",
    "    print(\"📊 Step 1: Parsing sensor data (microsecond timestamps)...\")\n",
    "    if not analyzer.parse_sensor_data(data_file):\n",
    "        print(\"❌ Failed to parse sensor data\")\n",
    "        return None\n",
    "    \n",
    "    # 2. 提取特征\n",
    "    print(\"🔍 Step 2: Extracting driving features...\")\n",
    "    if not analyzer.extract_driving_features():\n",
    "        print(\"❌ Failed to extract features\")\n",
    "        return None\n",
    "    \n",
    "    # 3. 数据同步和能耗建模\n",
    "    print(\"⚡ Step 3: Synchronizing data and modeling energy...\")\n",
    "    combined_data = analyzer.synchronize_and_model_energy()\n",
    "    if combined_data.empty:\n",
    "        print(\"❌ Failed to synchronize data\")\n",
    "        return None\n",
    "    \n",
    "    # 4. 生成综合报告\n",
    "    print(\"📋 Step 4: Generating comprehensive report...\")\n",
    "    report = analyzer.generate_comprehensive_report()\n",
    "    if not report:\n",
    "        print(\"❌ Failed to generate report\")\n",
    "        return None\n",
    "    \n",
    "    # 5. 可视化结果\n",
    "    print(\"📈 Step 5: Creating visualizations...\")\n",
    "    analyzer.visualize_results()\n",
    "    \n",
    "    # 6. 保存结果\n",
    "    print(\"💾 Step 6: Saving results...\")\n",
    "    analyzer.save_results()\n",
    "    \n",
    "    print(\"\\n✅ Analysis Complete!\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # 打印关键结果\n",
    "    print(f\"📊 Key Results (Startup Phase):\")\n",
    "    print(f\"  • Duration: {report['metadata']['duration_minutes']:.1f} minutes\")\n",
    "    print(f\"  • Max Speed: {report['driving_summary']['max_speed_kmh']:.1f} km/h\")\n",
    "    print(f\"  • Hard Brake Events: {len(analyzer.results['hard_brake_events'])}\")\n",
    "    print(f\"  • Driver Behavior Types: {len(set(p['driver_type'] for p in analyzer.results['cluster_profiles'].values()))}\")\n",
    "    print(f\"  • Average Energy Efficiency: {np.mean([p['energy_efficiency'] for p in analyzer.results['cluster_profiles'].values()]):.1f} kWh/100km\")\n",
    "    \n",
    "    return analyzer\n",
    "\n",
    "# 使用示例和测试代码\n",
    "if __name__ == \"__main__\":\n",
    "    # 针对起步阶段优化的配置\n",
    "    startup_config = {\n",
    "        'hard_brake_threshold': -2.0,  # 降低阈值适应起步\n",
    "        'speed_drop_threshold': 6,     # 降低速度下降阈值\n",
    "        'min_brake_speed': 8,          # 降低最小刹车速度\n",
    "        'energy_model': {\n",
    "            'vehicle_mass': 1600,      # 紧凑型轿车\n",
    "            'drag_coefficient': 0.26,  # 现代轿车优秀风阻\n",
    "            'frontal_area': 2.2,       # 紧凑型车迎风面积\n",
    "            'rolling_resistance': 0.010 # 优质轮胎\n",
    "        },\n",
    "        'clustering': {\n",
    "            'n_clusters': 3,\n",
    "            'features': ['speed', 'acceleration', 'jerk', 'turning_rate']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 运行分析\n",
    "    data_file = \"ts_1747221572.csv\"  # 你的数据文件\n",
    "    \n",
    "    print(\"🚀 Running Eco-Driving Analysis - Startup Phase Optimized\")\n",
    "    print(f\"📁 Data file: {data_file}\")\n",
    "    print(\"🔧 Configuration: Optimized for startup phase with microsecond precision\")\n",
    "    print(\"⏱️  Expected analysis time: 30-60 seconds\")\n",
    "    print()\n",
    "    \n",
    "    # 执行完整分析\n",
    "    analyzer = run_complete_eco_driving_analysis(data_file, startup_config)\n",
    "    \n",
    "    if analyzer:\n",
    "        print(\"\\n🎉 Analysis completed successfully!\")\n",
    "        print(\"📁 Check 'eco_driving_results' folder for detailed outputs:\")\n",
    "        print(\"   • processed_data.csv - Complete processed dataset\")\n",
    "        print(\"   • hard_brake_events.csv - Hard brake event details\") \n",
    "        print(\"   • analysis_report.json - Structured analysis results\")\n",
    "        print(\"   • eco_driving_report.txt - Human-readable report\")\n",
    "        print(\"   • eco_driving_startup_analysis.png - Comprehensive visualization\")\n",
    "        \n",
    "        # 显示快速摘要\n",
    "        print(f\"\\n🔍 Quick Analysis Summary:\")\n",
    "        report = analyzer.results['report']\n",
    "        print(f\"  ⏱️  Duration: {report['metadata']['duration_minutes']:.1f} minutes\")\n",
    "        print(f\"  🚗 Max Speed: {report['driving_summary']['max_speed_kmh']:.1f} km/h\")\n",
    "        print(f\"  🚨 Hard Brakes: {report['driving_summary']['total_hard_brakes']}\")\n",
    "        \n",
    "        # 显示驾驶类型分布\n",
    "        cluster_types = [p['driver_type'] for p in analyzer.results['cluster_profiles'].values()]\n",
    "        type_counts = {}\n",
    "        for dtype in cluster_types:\n",
    "            type_counts[dtype] = type_counts.get(dtype, 0) + 1\n",
    "        \n",
    "        print(f\"  🎯 Driving Types Found: {', '.join(type_counts.keys())}\")\n",
    "        \n",
    "        # 显示主要建议\n",
    "        print(f\"\\n💡 Top Recommendations:\")\n",
    "        for i, rec in enumerate(report['recommendations'][:2]):\n",
    "            print(f\"  {i+1}. [{rec['priority']}] {rec['message'][:80]}...\")\n",
    "        \n",
    "        # 数据质量报告\n",
    "        data = analyzer.results['data']\n",
    "        print(f\"\\n📊 Data Quality Summary:\")\n",
    "        print(f\"  • Total Data Points: {len(data):,}\")\n",
    "        print(f\"  • GPS-Accelerometer Sync: {(data['sync_error_us'] < 100000).sum()}/{len(data)} points < 100ms\")\n",
    "        print(f\"  • Acceleration Range: {data['acceleration'].min():.2f} to {data['acceleration'].max():.2f} m/s²\")\n",
    "        print(f\"  • Jerk Range: {data['jerk'].min():.2f} to {data['jerk'].max():.2f} m/s³\")\n",
    "        print(f\"  • Speed Range: {data['speed_kmh'].min():.1f} to {data['speed_kmh'].max():.1f} km/h\")\n",
    "        \n",
    "        # 性能评估\n",
    "        if 'hard_brake_events' in analyzer.results:\n",
    "            safety_rating = \"🟢 Excellent\" if len(analyzer.results['hard_brake_events']) == 0 else \\\n",
    "                           \"🟡 Good\" if len(analyzer.results['hard_brake_events']) <= 2 else \\\n",
    "                           \"🟠 Needs Improvement\"\n",
    "            print(f\"  • Safety Rating: {safety_rating}\")\n",
    "        \n",
    "        avg_energy = np.mean([p['energy_efficiency'] for p in analyzer.results['cluster_profiles'].values()])\n",
    "        efficiency_rating = \"🟢 Excellent\" if avg_energy < 20 else \\\n",
    "                           \"🟡 Good\" if avg_energy < 30 else \\\n",
    "                           \"🟠 Moderate\"\n",
    "        print(f\"  • Efficiency Rating: {efficiency_rating} ({avg_energy:.1f} kWh/100km)\")\n",
    "        \n",
    "        print(f\"\\n✨ Analysis Features Highlights:\")\n",
    "        print(f\"  ✅ Microsecond timestamp precision\")\n",
    "        print(f\"  ✅ Real GPS-based acceleration calculation\")\n",
    "        print(f\"  ✅ Instantaneous jerk values (not averaged)\")\n",
    "        print(f\"  ✅ Startup phase optimized thresholds\")\n",
    "        print(f\"  ✅ Intelligent hard brake detection\")\n",
    "        print(f\"  ✅ Multi-dimensional driver behavior clustering\")\n",
    "        print(f\"  ✅ Personalized driving recommendations\")\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ Analysis failed. Please check your data file and try again.\")\n",
    "        print(\"\\n🔧 Troubleshooting Tips:\")\n",
    "        print(\"  • Ensure your CSV file exists and is readable\")\n",
    "        print(\"  • Check that the data format matches the expected structure:\")\n",
    "        print(\"    - GPS: 0,timestamp,lat,lon,alt,speed_kmh,satellites\")\n",
    "        print(\"    - Accelerometer: 1,timestamp,timestamp_us,x,y,z\")\n",
    "        print(\"    - Gyroscope: 2,timestamp,timestamp_us,x,y,z\")\n",
    "        print(\"  • Verify that timestamps are in microseconds\")\n",
    "        print(\"  • Make sure the file contains sufficient data points\")\n",
    "\n",
    "# 辅助函数：数据格式验证\n",
    "def validate_data_format(file_path, sample_lines=10):\n",
    "    \"\"\"\n",
    "    验证数据文件格式\n",
    "    Args:\n",
    "        file_path: 数据文件路径\n",
    "        sample_lines: 检查的样本行数\n",
    "    \"\"\"\n",
    "    print(f\"🔍 Validating data format for {file_path}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = [f.readline().strip() for _ in range(sample_lines)]\n",
    "        \n",
    "        format_counts = {'gps': 0, 'acc': 0, 'gyro': 0, 'rot': 0, 'unknown': 0}\n",
    "        \n",
    "        print(\"Sample data lines:\")\n",
    "        for i, line in enumerate(lines):\n",
    "            if not line:\n",
    "                continue\n",
    "            values = line.split(',')\n",
    "            print(f\"  {i+1}: {line}\")\n",
    "            \n",
    "            if len(values) >= 2:\n",
    "                try:\n",
    "                    data_type = int(values[0])\n",
    "                    if data_type == 0:\n",
    "                        format_counts['gps'] += 1\n",
    "                        if len(values) < 6:\n",
    "                            print(f\"    ⚠️  GPS line has only {len(values)} columns, expected 6+\")\n",
    "                    elif data_type == 1:\n",
    "                        format_counts['acc'] += 1\n",
    "                        if len(values) < 5:\n",
    "                            print(f\"    ⚠️  Accelerometer line has only {len(values)} columns, expected 5+\")\n",
    "                    elif data_type == 2:\n",
    "                        format_counts['gyro'] += 1\n",
    "                        if len(values) < 5:\n",
    "                            print(f\"    ⚠️  Gyroscope line has only {len(values)} columns, expected 5+\")\n",
    "                    elif data_type == 3:\n",
    "                        format_counts['rot'] += 1\n",
    "                        if len(values) < 6:\n",
    "                            print(f\"    ⚠️  Rotation line has only {len(values)} columns, expected 6+\")\n",
    "                    else:\n",
    "                        format_counts['unknown'] += 1\n",
    "                        print(f\"    ⚠️  Unknown data type: {data_type}\")\n",
    "                except ValueError:\n",
    "                    format_counts['unknown'] += 1\n",
    "                    print(f\"    ❌ Invalid data type: {values[0]}\")\n",
    "        \n",
    "        print(f\"\\nData type distribution in sample:\")\n",
    "        for dtype, count in format_counts.items():\n",
    "            if count > 0:\n",
    "                print(f\"  {dtype}: {count} lines\")\n",
    "        \n",
    "        # 验证时间戳\n",
    "        if format_counts['gps'] > 0 or format_counts['acc'] > 0:\n",
    "            print(f\"\\nTimestamp validation:\")\n",
    "            for line in lines:\n",
    "                if not line:\n",
    "                    continue\n",
    "                values = line.split(',')\n",
    "                if len(values) >= 2:\n",
    "                    try:\n",
    "                        timestamp = int(values[1])\n",
    "                        if timestamp > 1000000000000:  # 微秒级时间戳\n",
    "                            print(f\"  ✅ Microsecond timestamp detected: {timestamp}\")\n",
    "                        elif timestamp > 1000000000:   # 毫秒级时间戳\n",
    "                            print(f\"  ⚠️  Millisecond timestamp detected: {timestamp}\")\n",
    "                        else:\n",
    "                            print(f\"  ❌ Unusual timestamp: {timestamp}\")\n",
    "                        break\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error validating file: {e}\")\n",
    "        return False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
